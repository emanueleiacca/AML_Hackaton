{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117959,"databundleVersionId":14220991,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport json, os, pathlib, subprocess, sys\n\n# --- 1. Load your secret (full JSON from kaggle.json) ---\nsecret_name = \"kaggle_json\"  # change if you used another name\nuser_secrets = UserSecretsClient()\nraw = user_secrets.get_secret(secret_name)\ncreds = json.loads(raw)\n\n# --- 2. Forcefully recreate ~/.kaggle/kaggle.json ---\nkaggle_dir = pathlib.Path.home() / \".kaggle\"\nkaggle_dir.mkdir(parents=True, exist_ok=True)\ncred_path = kaggle_dir / \"kaggle.json\"\ncred_path.write_text(json.dumps(creds))\nos.chmod(cred_path, 0o600)\n\n# --- 3. Double-check the file actually exists and is readable ---\nprint(\"✅ Credentials written to:\", cred_path)\n!ls -la ~/.kaggle/\n#!cat ~/.kaggle/kaggle.json | head -1\n\n# --- 4. Reinstall Kaggle CLI cleanly ---\n#!pip install --upgrade --force-reinstall kaggle --quiet\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T20:42:58.866928Z","iopub.execute_input":"2025-10-26T20:42:58.867685Z","iopub.status.idle":"2025-10-26T20:42:59.050861Z","shell.execute_reply.started":"2025-10-26T20:42:58.867655Z","shell.execute_reply":"2025-10-26T20:42:59.049839Z"}},"outputs":[{"name":"stdout","text":"✅ Credentials written to: /root/.kaggle/kaggle.json\ntotal 16\ndrwxr-xr-x 2 root root 4096 Oct 26 19:54 .\ndrwx------ 1 root root 4096 Oct 26 20:01 ..\n-rw------- 1 root root   72 Oct 26 20:42 kaggle.json\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"!kaggle competitions files -c aml-competition\n!kaggle competitions download -c aml-competition -p /kaggle/working --force\n!mkdir -p /kaggle/working/data\n!unzip -o /kaggle/working/aml-competition.zip -d /kaggle/working/data\n!ls -lah /kaggle/working/data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/Mamiglia/challenge.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T19:55:40.278208Z","iopub.execute_input":"2025-10-26T19:55:40.278539Z","iopub.status.idle":"2025-10-26T19:55:43.320740Z","shell.execute_reply.started":"2025-10-26T19:55:40.278517Z","shell.execute_reply":"2025-10-26T19:55:43.319784Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'challenge'...\nremote: Enumerating objects: 98, done.\u001b[K\nremote: Counting objects: 100% (98/98), done.\u001b[K\nremote: Compressing objects: 100% (69/69), done.\u001b[K\nremote: Total 98 (delta 39), reused 72 (delta 26), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (98/98), 21.03 MiB | 21.15 MiB/s, done.\nResolving deltas: 100% (39/39), done.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# runner.py\nimport json, random, re, time\nfrom pathlib import Path\nfrom os.path import basename\nfrom collections import defaultdict\n\nimport numpy as np\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom challenge.src.common import load_data, generate_submission\n\n# ---------- Paths ----------\nDATA_ROOT = Path(\"/kaggle/working/data\")\nTRAIN_DIR = DATA_ROOT / \"train\" / \"train\"\nTEST_DIR  = DATA_ROOT / \"test\"  / \"test\"\nTRAIN_NPZ = TRAIN_DIR / \"train.npz\"\nTEST_NPZ  = TEST_DIR / \"test.clean.npz\"\nTRAIN_CAPTIONS = TRAIN_DIR / \"captions.txt\"\nTEST_CAPTIONS  = TEST_DIR  / \"captions.txt\"\n\n# ---------- Utils ----------\ndef seed_all(s: int):\n    random.seed(s); np.random.seed(s)\n    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n    torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n\ndef _build_image_index(image_ids):\n    idx_exact = {}; idx_base={}; idx_stem={}\n    for i, v in enumerate(image_ids):\n        s = str(v); idx_exact[s]=i\n        b = basename(s); idx_base[b]=i\n        stem = b.rsplit(\".\",1)[0] if \".\" in b else b\n        idx_stem[stem]=i\n    return idx_exact, idx_base, idx_stem\n\ndef _iter_targets_from_captions(path: Path, n_text: int, idx_exact, idx_base, idx_stem):\n    targets=[]\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        for raw in f:\n            if len(targets)>=n_text: break\n            line=raw.strip()\n            if not line: continue\n            lower=line.lower()\n            if (\"image\" in lower or \"filename\" in lower) and (\",\" in line or \"|\" in line or \"\\t\" in line):\n                first=re.split(r'\\||\\t|,| {2,}', line)[0].strip().strip('\"').strip(\"'\")\n                if \".\" not in first: continue\n            parts=re.split(r'\\||\\t|,| {2,}', line)\n            if len(parts)==1: parts=line.split(\" \",1)\n            tok=parts[0].strip().strip('\"').strip(\"'\")\n            if not tok: continue\n            def _match(tok_):\n                if tok_ in idx_exact: return idx_exact[tok_]\n                b=basename(tok_)\n                if b in idx_base: return idx_base[b]\n                stem=b.rsplit(\".\",1)[0] if \".\" in b else b\n                if stem in idx_stem: return idx_stem[stem]\n                return None\n            idx=_match(tok)\n            if idx is None:\n                tok2=tok.replace(\"Images/\",\"\").replace(\"./\",\"\")\n                idx=_match(tok2)\n            if idx is None:\n                if \".\" not in tok: continue\n                raise AssertionError(f\"Could not match image token '{tok}'\")\n            targets.append(idx)\n    assert len(targets)==n_text, f\"matched {len(targets)} vs N_text {n_text}\"\n    return np.asarray(targets, dtype=np.int64)\n\ndef load_train(out_dir: Path):\n    d=np.load(TRAIN_NPZ, allow_pickle=True)\n    X=d[\"captions/embeddings\"].astype(np.float32)  # (N_text, 1024 or P*D)\n    I=d[\"images/embeddings\"].astype(np.float32)    # (N_img, 1536)\n    cap_ids=d.get(\"captions/ids\", np.arange(len(X)).astype(str))\n    img_names=d.get(\"images/names\", np.arange(len(I)).astype(str))\n\n    ex,ba,st=_build_image_index(img_names)\n    assert TRAIN_CAPTIONS.exists(), f\"Missing {TRAIN_CAPTIONS}\"\n    targets=_iter_targets_from_captions(TRAIN_CAPTIONS, len(X), ex,ba,st)\n\n    Y=I[targets]                       # (N_text, 1536) ground-truth\n    img_ids_row = img_names[targets]   # image id per row\n    meta={\"n_text\":int(len(X)),\"n_images\":int(len(I))}\n    (out_dir/\"train_detect.json\").write_text(json.dumps(meta, indent=2))\n    return X,Y,cap_ids,img_ids_row,I,img_names\n\ndef load_test():\n    d_test=np.load(TEST_NPZ, allow_pickle=True)\n    Q=d_test[\"captions/embeddings\"].astype(np.float32)\n    q_ids=d_test.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n    # gallery: prefer test's, else train's\n    if \"images/embeddings\" in d_test.files:\n        G=d_test[\"images/embeddings\"].astype(np.float32)\n        g_ids=d_test.get(\"images/names\", np.arange(len(G)).astype(str))\n    else:\n        d_tr=np.load(TRAIN_NPZ, allow_pickle=True)\n        G=d_tr[\"images/embeddings\"].astype(np.float32)\n        g_ids=d_tr.get(\"images/names\", np.arange(len(G)).astype(str))\n    return Q,G,q_ids,g_ids\n\ndef infer_arch_from_state_dict(sd):\n    ks = set(sd.keys())\n    if {\"fc.weight\",\"fc.bias\"} <= ks: return \"linear\"\n    if {\"fc1.weight\",\"fc1.bias\",\"fc2.weight\",\"fc2.bias\"} <= ks: return \"mlp1\"\n    if any(k.startswith(\"net.\") for k in ks): return \"mlp2\"\n    raise ValueError(\"Unrecognized checkpoint layout.\")\n\n# ---------- Dataset ----------\nclass PairDS(Dataset):\n    def __init__(self, X, Y): self.X=torch.from_numpy(X); self.Y=torch.from_numpy(Y)\n    def __len__(self): return self.X.shape[0]\n    def __getitem__(self, i): return self.X[i], self.Y[i]\n\n# ---------- Pooling ----------\ndef apply_pooling(x: torch.Tensor, mode: str, n_patches: int|None):\n    if mode.lower()==\"cls\":            # identity\n        return x\n    if mode.lower().startswith(\"mean\"):\n        if x.ndim==3: return x.mean(1)\n        if n_patches and x.shape[1]%n_patches==0:\n            P=n_patches; D=x.shape[1]//P\n            return x.view(x.shape[0], P, D).mean(1)\n        return x                       # fallback\n    return x\n\n# ---------- Models ----------\nclass LinearProj(nn.Module):\n    def __init__(self, din, dout):\n        super().__init__()\n        self.fc=nn.Linear(din,dout)\n        nn.init.xavier_normal_(self.fc.weight); nn.init.zeros_(self.fc.bias)\n    def forward(self,x): return self.fc(x)\n\nclass MLP1(nn.Module):\n    def __init__(self, din, dout, hidden=512, pdrop=0.0):\n        super().__init__()\n        self.net=nn.Sequential(\n            nn.Linear(din,hidden), nn.ReLU(), nn.Dropout(pdrop),\n            nn.Linear(hidden,dout)\n        )\n        for m in self.net:\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n    def forward(self,x): return self.net(x)\n\nclass MLP2(nn.Module):\n    def __init__(self, din, dout, h1=1024, h2=512, pdrop=0.0):\n        super().__init__()\n        self.net=nn.Sequential(\n            nn.Linear(din,h1), nn.ReLU(), nn.Dropout(pdrop),\n            nn.Linear(h1,h2), nn.ReLU(), nn.Dropout(pdrop),\n            nn.Linear(h2,dout)\n        )\n        for m in self.net:\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n    def forward(self,x): return self.net(x)\n\ndef make_model(arch:str, din:int, dout:int):\n    arch=arch.lower()\n    if arch==\"linear\": return LinearProj(din,dout)\n    if arch==\"mlp1\":   return MLP1(din,dout,hidden=512)\n    if arch==\"mlp2\":   return MLP2(din,dout,h1=1024,h2=512)\n    raise ValueError(f\"Unknown arch {arch}\")\n\n# ---------- Loss pieces ----------\ndef loss_align(pred, tgt, kind:str):\n    if kind==\"none\": return pred.new_tensor(0.0)\n    if kind==\"moment\":\n        # match batch mean and std (channel-wise)\n        mu_p, mu_t = pred.mean(0), tgt.mean(0)\n        sd_p, sd_t = pred.std(0, unbiased=False), tgt.std(0, unbiased=False)\n        return F.mse_loss(mu_p, mu_t) + F.mse_loss(sd_p, sd_t)\n    if kind==\"normcal\":\n        # calibrate L2 norm distribution\n        np_ = pred.norm(dim=-1).mean()\n        nt_ = tgt.norm(dim=-1).mean()\n        return F.mse_loss(np_, nt_)\n    raise ValueError(kind)\n\ndef info_nce(pred, tgt):\n    # in-batch InfoNCE with cosine sim\n    p = F.normalize(pred, dim=-1)\n    t = F.normalize(tgt, dim=-1)\n    logits = p @ t.t()                      # (B,B)\n    labels = torch.arange(pred.size(0), device=pred.device)\n    return F.cross_entropy(logits, labels)\n\n# ---------- Metrics ----------\n@torch.no_grad()\ndef validate_retrieval(model, Xv, Yv, pooling, n_patches, bs=1024):\n    device=next(model.parameters()).device\n    # gallery = unique images in val\n    Yv_np = Yv.copy()\n    # build unique gallery\n    _, uniq_idx = np.unique(Yv_np, axis=0, return_index=True)  # cheap, works since Yv rows are copies from I\n    Gi = torch.from_numpy(Yv_np[sorted(uniq_idx)]).to(device)\n    Gi = F.normalize(Gi, dim=-1)\n\n    ranks=[]\n    for i in range(0, len(Xv), bs):\n        xb=torch.from_numpy(Xv[i:i+bs]).to(device)\n        xb=apply_pooling(xb, pooling, n_patches)\n        pred=model(xb)\n        pred=F.normalize(pred, dim=-1)\n        sims=pred @ Gi.t()                 # (b, M)\n        # compute rank of the matching Y row within Gi\n        for j in range(sims.size(0)):\n            # find index in Gi that matches Yv row\n            y = torch.from_numpy(Yv_np[i+j]).to(device)\n            y = F.normalize(y, dim=-1)\n            # true index = argmax sim with Gi\n            true_idx = torch.argmax(Gi @ y, dim=0).item()\n            order = torch.argsort(sims[j], descending=True)\n            rank = (order==true_idx).nonzero(as_tuple=False).item() + 1\n            ranks.append(rank)\n\n    ranks = np.array(ranks)\n    mrr = np.mean(1.0 / ranks)\n    r1  = np.mean(ranks<=1)\n    r5  = np.mean(ranks<=5)\n    r10 = np.mean(ranks<=10)\n    return dict(MRR=float(mrr), R1=float(r1), R5=float(r5), R10=float(r10),\n                median=int(np.median(ranks)), p75=int(np.percentile(ranks,75)))\n\ndef count_params_mb(model):\n    params=sum(p.numel() for p in model.parameters())\n    mb = params * 4 / (1024**2)\n    return params, mb\n\ndef time_ms_per_query(model, din, pooling, n_patches):\n    device=next(model.parameters()).device\n    x=torch.randn(2048, din, device=device)\n    x=apply_pooling(x, pooling, n_patches)\n    torch.cuda.synchronize(device) if device.type==\"cuda\" else None\n    t0=time.time()\n    with torch.no_grad(): _=model(x)\n    torch.cuda.synchronize(device) if device.type==\"cuda\" else None\n    ms = (time.time()-t0)*1000/len(x)\n    # cpu timing\n    mcpu=model.to(\"cpu\")\n    xcpu=x.to(\"cpu\")\n    t1=time.time()\n    with torch.no_grad(): _=mcpu(xcpu)\n    ms_cpu=(time.time()-t1)*1000/len(xcpu)\n    model.to(device)\n    return ms, ms_cpu\n\n# ---------- Training ----------\ndef train_one(model, loader, opt, alpha, beta, gamma, align_kind, pooling, n_patches, device):\n    model.train(); total=0.0\n    for xb,yb in loader:\n        xb,yb=xb.to(device), yb.to(device)\n        xb=apply_pooling(xb, pooling, n_patches)\n        opt.zero_grad(set_to_none=True)\n        pred=model(xb)\n        cos = 1 - F.cosine_similarity(pred, yb, dim=-1).mean()\n        mse = F.mse_loss(pred, yb)\n        a_loss = loss_align(pred, yb, align_kind)\n        ce = info_nce(pred, yb) if gamma>0 else pred.new_tensor(0.0)\n        loss = alpha*cos + beta*mse + gamma*ce + a_loss\n        loss.backward(); opt.step()\n        total += loss.item()*xb.size(0)\n    return total/len(loader.dataset)\n\n# ---------- Main ----------\ndef main(\n    out_dir=\"baseline_ref\", seed=42, epochs=20, batch=512, lr=1e-4, wd=1e-4,\n    pooling=\"CLS\", n_patches=None, alpha=1.0, beta=1.0, gamma=0.0,\n    align_loss=\"none\", arch=\"auto\", train=True, val_ratio=0.1\n):\n    seed_all(seed)\n    OUT = Path(f\"/kaggle/working/outputs/{out_dir}\"); OUT.mkdir(parents=True, exist_ok=True)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # --- data\n    X,Y,cap_ids,img_ids_row,full_img,all_img_ids = load_train(OUT)\n    uniq = np.unique(img_ids_row); rng = np.random.default_rng(seed); rng.shuffle(uniq)\n    n_val = max(1, int(len(uniq)*val_ratio)); valset = set(uniq[:n_val])\n    m = np.array([iid in valset for iid in img_ids_row])\n    Xtr,Ytr,Xva,Yva = X[~m],Y[~m],X[m],Y[m]\n\n    din, dout = X.shape[1], Y.shape[1]\n\n    # --- build/load model\n    if train:\n        eff_arch = arch if arch != \"auto\" else \"linear\"  # default for fresh training\n        model = make_model(eff_arch, din, dout).to(device)\n    else:\n        ckpt = torch.load(OUT/\"best.pt\", map_location=\"cpu\")\n        eff_arch = arch if arch != \"auto\" else infer_arch_from_state_dict(ckpt[\"model\"])\n        print(f\"[ckpt] detected arch = {eff_arch}\")\n        model = make_model(eff_arch, din, dout).to(device)\n        model.load_state_dict(ckpt[\"model\"])\n\n    params, mb = count_params_mb(model)\n    print(f\"[model] {eff_arch} | params={params:,} (~{mb:.2f} MB) | pooling={pooling} | align={align_loss} | α={alpha} β={beta} γ={gamma}\")\n\n    # --- train (if requested)\n    if train:\n        dl = DataLoader(PairDS(Xtr,Ytr), batch_size=batch, shuffle=True, num_workers=2, pin_memory=True)\n        opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n        best = -1.0; best_ep = 0; best_stats = None\n        for ep in range(1, epochs+1):\n            tr = train_one(model, dl, opt, alpha,beta,gamma,align_loss, pooling, n_patches, device)\n            stats = validate_retrieval(model, Xva, Yva, pooling, n_patches)\n            print(f\"[{ep:02d}] train_loss={tr:.6f} | val_MRR={stats['MRR']:.4f} | R@1={stats['R1']:.3f} R@5={stats['R5']:.3f}\")\n            if stats[\"MRR\"] > best:\n                best, best_ep, best_stats = stats[\"MRR\"], ep, stats\n                torch.save({\"model\":model.state_dict(),\"epoch\":ep,\"val\":stats}, OUT/\"best.pt\")\n        print(f\"[best] MRR={best:.4f} @ epoch {best_ep}\")\n        (OUT/\"val_metrics.json\").write_text(json.dumps(dict(best_epoch=best_ep, **best_stats), indent=2))\n    else:\n        # already loaded weights above\n        ckpt = torch.load(OUT/\"best.pt\", map_location=\"cpu\")\n        print(f\"[resume] loaded epoch={ckpt.get('epoch','?')} MRR={ckpt.get('val',{}).get('MRR','?')}\")\n\n    # --- efficiency\n    ms_gpu, ms_cpu = time_ms_per_query(model, din, pooling, n_patches)\n    (OUT/\"efficiency.json\").write_text(json.dumps(\n        {\"params\":params,\"mb_fp32\":mb,\"ms_per_query_gpu\":ms_gpu,\"ms_per_query_cpu\":ms_cpu}, indent=2\n    ))\n\n    # --- submission (official helper)\n    TEST_NPZ = (TEST_DIR / \"test.clean.npz\")\n    test_data = load_data(TEST_NPZ)\n    Q   = test_data[\"captions/embeddings\"].astype(np.float32)\n    ids = test_data.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n\n    model.eval()\n    BS = 1024\n    outs = []\n    with torch.no_grad():\n        for i in range(0, len(Q), BS):\n            q = torch.from_numpy(Q[i:i+BS]).to(device)\n            q = apply_pooling(q, pooling, n_patches)\n            z = model(q)\n            z = F.normalize(z, dim=-1)\n            outs.append(z.detach().cpu().numpy())\n    pred_embds = np.concatenate(outs, axis=0)\n\n    sub = OUT / \"submission.csv\"\n    generate_submission(ids, pred_embds, str(sub))\n    print(f\"[ok] submission written → {sub}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T20:44:01.857460Z","iopub.execute_input":"2025-10-26T20:44:01.858081Z","iopub.status.idle":"2025-10-26T20:44:01.905012Z","shell.execute_reply.started":"2025-10-26T20:44:01.858049Z","shell.execute_reply":"2025-10-26T20:44:01.904178Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"if __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"baseline_ref\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1.0)\n    p.add_argument(\"--beta\", type=float, default=1.0)\n    p.add_argument(\"--gamma\", type=float, default=0.0)\n    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"auto\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T20:44:07.502848Z","iopub.execute_input":"2025-10-26T20:44:07.503606Z","iopub.status.idle":"2025-10-26T20:47:46.587152Z","shell.execute_reply.started":"2025-10-26T20:44:07.503582Z","shell.execute_reply":"2025-10-26T20:47:46.586311Z"}},"outputs":[{"name":"stdout","text":"[model] linear | params=1,574,400 (~6.01 MB) | pooling=CLS | align=none | α=1.0 β=1.0 γ=0.0\n[01] train_loss=0.954751 | val_MRR=0.1206 | R@1=0.057 R@5=0.170\n[02] train_loss=0.507948 | val_MRR=0.1398 | R@1=0.070 R@5=0.194\n[03] train_loss=0.432700 | val_MRR=0.1506 | R@1=0.077 R@5=0.212\n[04] train_loss=0.401670 | val_MRR=0.1607 | R@1=0.083 R@5=0.226\n[05] train_loss=0.383644 | val_MRR=0.1665 | R@1=0.087 R@5=0.234\n[06] train_loss=0.371423 | val_MRR=0.1701 | R@1=0.088 R@5=0.242\n[07] train_loss=0.362467 | val_MRR=0.1754 | R@1=0.094 R@5=0.248\n[08] train_loss=0.355643 | val_MRR=0.1786 | R@1=0.095 R@5=0.252\n[09] train_loss=0.350284 | val_MRR=0.1810 | R@1=0.096 R@5=0.258\n[10] train_loss=0.346007 | val_MRR=0.1829 | R@1=0.097 R@5=0.261\n[11] train_loss=0.342501 | val_MRR=0.1846 | R@1=0.099 R@5=0.262\n[12] train_loss=0.339609 | val_MRR=0.1882 | R@1=0.102 R@5=0.267\n[13] train_loss=0.337181 | val_MRR=0.1888 | R@1=0.101 R@5=0.269\n[14] train_loss=0.335115 | val_MRR=0.1915 | R@1=0.104 R@5=0.271\n[15] train_loss=0.333372 | val_MRR=0.1914 | R@1=0.104 R@5=0.273\n[16] train_loss=0.331857 | val_MRR=0.1941 | R@1=0.107 R@5=0.275\n[17] train_loss=0.330544 | val_MRR=0.1954 | R@1=0.107 R@5=0.278\n[18] train_loss=0.329416 | val_MRR=0.1957 | R@1=0.107 R@5=0.278\n[19] train_loss=0.328411 | val_MRR=0.1964 | R@1=0.107 R@5=0.281\n[20] train_loss=0.327532 | val_MRR=0.1972 | R@1=0.108 R@5=0.282\n[21] train_loss=0.326740 | val_MRR=0.1993 | R@1=0.111 R@5=0.285\n[22] train_loss=0.326060 | val_MRR=0.1996 | R@1=0.110 R@5=0.284\n[23] train_loss=0.325418 | val_MRR=0.1987 | R@1=0.109 R@5=0.285\n[24] train_loss=0.324864 | val_MRR=0.2002 | R@1=0.110 R@5=0.286\n[25] train_loss=0.324370 | val_MRR=0.1998 | R@1=0.110 R@5=0.287\n[26] train_loss=0.323910 | val_MRR=0.1997 | R@1=0.109 R@5=0.287\n[27] train_loss=0.323486 | val_MRR=0.2007 | R@1=0.111 R@5=0.286\n[28] train_loss=0.323121 | val_MRR=0.2021 | R@1=0.112 R@5=0.289\n[29] train_loss=0.322772 | val_MRR=0.2015 | R@1=0.111 R@5=0.289\n[30] train_loss=0.322453 | val_MRR=0.2030 | R@1=0.113 R@5=0.288\n[best] MRR=0.2030 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/baseline_ref/submission.csv\n[ok] submission written → /kaggle/working/outputs/baseline_ref/submission.csv\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# !python runner.py --out_dir mlp1_cls_cos_mse --train 1 --arch mlp1 --pooling CLS --alpha 1 --beta 1 --gamma 0 --align_loss none\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos_mse\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1.0)\n    p.add_argument(\"--beta\", type=float, default=1.0)\n    p.add_argument(\"--gamma\", type=float, default=0.0)\n    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T20:28:39.492598Z","iopub.execute_input":"2025-10-26T20:28:39.493465Z","iopub.status.idle":"2025-10-26T20:32:28.017604Z","shell.execute_reply.started":"2025-10-26T20:28:39.493433Z","shell.execute_reply":"2025-10-26T20:32:28.016678Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=none | α=1.0 β=1.0 γ=0.0\n[01] train_loss=0.660932 | val_MRR=0.0333 | R@1=0.009 R@5=0.043\n[02] train_loss=0.412790 | val_MRR=0.0618 | R@1=0.024 R@5=0.082\n[03] train_loss=0.380159 | val_MRR=0.0828 | R@1=0.035 R@5=0.111\n[04] train_loss=0.363856 | val_MRR=0.0970 | R@1=0.042 R@5=0.132\n[05] train_loss=0.353517 | val_MRR=0.1121 | R@1=0.052 R@5=0.156\n[06] train_loss=0.346098 | val_MRR=0.1212 | R@1=0.055 R@5=0.173\n[07] train_loss=0.340426 | val_MRR=0.1313 | R@1=0.061 R@5=0.186\n[08] train_loss=0.335868 | val_MRR=0.1379 | R@1=0.064 R@5=0.199\n[09] train_loss=0.332036 | val_MRR=0.1467 | R@1=0.069 R@5=0.213\n[10] train_loss=0.328716 | val_MRR=0.1541 | R@1=0.074 R@5=0.223\n[11] train_loss=0.325812 | val_MRR=0.1613 | R@1=0.080 R@5=0.232\n[12] train_loss=0.323231 | val_MRR=0.1674 | R@1=0.085 R@5=0.240\n[13] train_loss=0.320927 | val_MRR=0.1739 | R@1=0.089 R@5=0.251\n[14] train_loss=0.318824 | val_MRR=0.1789 | R@1=0.093 R@5=0.256\n[15] train_loss=0.316905 | val_MRR=0.1819 | R@1=0.095 R@5=0.261\n[16] train_loss=0.315126 | val_MRR=0.1881 | R@1=0.099 R@5=0.272\n[17] train_loss=0.313457 | val_MRR=0.1906 | R@1=0.100 R@5=0.275\n[18] train_loss=0.311929 | val_MRR=0.1947 | R@1=0.103 R@5=0.280\n[19] train_loss=0.310463 | val_MRR=0.1984 | R@1=0.106 R@5=0.285\n[20] train_loss=0.309080 | val_MRR=0.2029 | R@1=0.110 R@5=0.291\n[21] train_loss=0.307751 | val_MRR=0.2070 | R@1=0.113 R@5=0.299\n[22] train_loss=0.306502 | val_MRR=0.2098 | R@1=0.114 R@5=0.302\n[23] train_loss=0.305328 | val_MRR=0.2132 | R@1=0.117 R@5=0.306\n[24] train_loss=0.304184 | val_MRR=0.2171 | R@1=0.122 R@5=0.311\n[25] train_loss=0.303101 | val_MRR=0.2181 | R@1=0.121 R@5=0.313\n[26] train_loss=0.302055 | val_MRR=0.2224 | R@1=0.125 R@5=0.320\n[27] train_loss=0.301057 | val_MRR=0.2246 | R@1=0.126 R@5=0.322\n[28] train_loss=0.300115 | val_MRR=0.2271 | R@1=0.129 R@5=0.324\n[29] train_loss=0.299189 | val_MRR=0.2284 | R@1=0.130 R@5=0.324\n[30] train_loss=0.298328 | val_MRR=0.2290 | R@1=0.131 R@5=0.327\n[best] MRR=0.2290 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos_mse/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos_mse/submission.csv\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# python runner.py --out_dir mlp1_patch_cos_mse --pooling mean-patch --n_patches None --alpha 1 --beta 1 --gamma 0 --align_loss none --arch mlp1\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_patch_cos_mse\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"mean-patch\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1.0)\n    p.add_argument(\"--beta\", type=float, default=1.0)\n    p.add_argument(\"--gamma\", type=float, default=0.0)\n    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T20:33:27.043205Z","iopub.execute_input":"2025-10-26T20:33:27.043885Z","iopub.status.idle":"2025-10-26T20:37:11.256209Z","shell.execute_reply.started":"2025-10-26T20:33:27.043859Z","shell.execute_reply":"2025-10-26T20:37:11.255462Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=mean-patch | align=none | α=1.0 β=1.0 γ=0.0\n[01] train_loss=0.660932 | val_MRR=0.0333 | R@1=0.009 R@5=0.043\n[02] train_loss=0.412790 | val_MRR=0.0618 | R@1=0.024 R@5=0.082\n[03] train_loss=0.380159 | val_MRR=0.0828 | R@1=0.035 R@5=0.111\n[04] train_loss=0.363856 | val_MRR=0.0970 | R@1=0.042 R@5=0.132\n[05] train_loss=0.353517 | val_MRR=0.1121 | R@1=0.052 R@5=0.156\n[06] train_loss=0.346098 | val_MRR=0.1212 | R@1=0.055 R@5=0.173\n[07] train_loss=0.340426 | val_MRR=0.1313 | R@1=0.061 R@5=0.186\n[08] train_loss=0.335868 | val_MRR=0.1379 | R@1=0.064 R@5=0.199\n[09] train_loss=0.332036 | val_MRR=0.1467 | R@1=0.069 R@5=0.213\n[10] train_loss=0.328716 | val_MRR=0.1541 | R@1=0.074 R@5=0.223\n[11] train_loss=0.325812 | val_MRR=0.1613 | R@1=0.080 R@5=0.232\n[12] train_loss=0.323231 | val_MRR=0.1674 | R@1=0.085 R@5=0.240\n[13] train_loss=0.320927 | val_MRR=0.1739 | R@1=0.089 R@5=0.251\n[14] train_loss=0.318824 | val_MRR=0.1789 | R@1=0.093 R@5=0.256\n[15] train_loss=0.316905 | val_MRR=0.1819 | R@1=0.095 R@5=0.261\n[16] train_loss=0.315126 | val_MRR=0.1881 | R@1=0.099 R@5=0.272\n[17] train_loss=0.313457 | val_MRR=0.1906 | R@1=0.100 R@5=0.275\n[18] train_loss=0.311929 | val_MRR=0.1947 | R@1=0.103 R@5=0.280\n[19] train_loss=0.310463 | val_MRR=0.1984 | R@1=0.106 R@5=0.285\n[20] train_loss=0.309080 | val_MRR=0.2029 | R@1=0.110 R@5=0.291\n[21] train_loss=0.307751 | val_MRR=0.2070 | R@1=0.113 R@5=0.299\n[22] train_loss=0.306502 | val_MRR=0.2098 | R@1=0.114 R@5=0.302\n[23] train_loss=0.305328 | val_MRR=0.2132 | R@1=0.117 R@5=0.306\n[24] train_loss=0.304184 | val_MRR=0.2171 | R@1=0.122 R@5=0.311\n[25] train_loss=0.303101 | val_MRR=0.2181 | R@1=0.121 R@5=0.313\n[26] train_loss=0.302055 | val_MRR=0.2224 | R@1=0.125 R@5=0.320\n[27] train_loss=0.301057 | val_MRR=0.2246 | R@1=0.126 R@5=0.322\n[28] train_loss=0.300115 | val_MRR=0.2271 | R@1=0.129 R@5=0.324\n[29] train_loss=0.299189 | val_MRR=0.2284 | R@1=0.130 R@5=0.324\n[30] train_loss=0.298328 | val_MRR=0.2290 | R@1=0.131 R@5=0.327\n[best] MRR=0.2290 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_patch_cos_mse/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_patch_cos_mse/submission.csv\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"#!/usr/bin/env python3\nimport argparse, json, re, time\nfrom pathlib import Path\nfrom os.path import basename\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\n# --------------------------\n# I/O helpers\n# --------------------------\ndef load_npz(path: Path):\n    d = np.load(path, allow_pickle=True)\n    return d\n\ndef assert_dims(d, expect_text=1024, expect_img=1536):\n    md = {k: d[k][0] for k in d.files if k.startswith(\"metadata/\")}\n    tdim = md.get(\"metadata/embedding_dim_text\", None)\n    idim = md.get(\"metadata/embedding_dim_image\", None)\n    print(f\"[meta] text_dim={tdim} | image_dim={idim}\")\n    ok = (tdim == expect_text) and (idim == expect_img)\n    if not ok:\n        print(\"[WARN] Metadata dims differ from expected fixed encoders \"\n              f\"(expected text={expect_text}, image={expect_img}). \"\n              \"Absolute metrics may shift; re-generate .npz with the official encoders.\")\n    return ok\n\ndef _build_image_index(image_ids):\n    idx_exact = {}; idx_base={}; idx_stem={}\n    for i, v in enumerate(image_ids):\n        s = str(v); idx_exact[s]=i\n        b = basename(s); idx_base[b]=i\n        stem = b.rsplit(\".\",1)[0] if \".\" in b else b\n        idx_stem[stem]=i\n    return idx_exact, idx_base, idx_stem\n\ndef _iter_targets_from_captions(path: Path, n_text: int, idx_exact, idx_base, idx_stem):\n    targets=[]\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        for raw in f:\n            if len(targets)>=n_text: break\n            line=raw.strip()\n            if not line: continue\n            parts=re.split(r'\\||\\t|,| {2,}', line)\n            if len(parts)==1: parts=line.split(\" \",1)\n            tok=parts[0].strip().strip('\"').strip(\"'\")\n            if not tok: continue\n            def _match(tok_):\n                if tok_ in idx_exact: return idx_exact[tok_]\n                b=basename(tok_)\n                if b in idx_base: return idx_base[b]\n                stem=b.rsplit(\".\",1)[0] if \".\" in b else b\n                if stem in idx_stem: return idx_stem[stem]\n                return None\n            idx=_match(tok)\n            if idx is None:\n                tok2=tok.replace(\"Images/\",\"\").replace(\"./\",\"\")\n                idx=_match(tok2)\n            if idx is None:\n                if \".\" not in tok: continue\n                raise AssertionError(f\"Could not match image token '{tok}'\")\n            targets.append(idx)\n    assert len(targets)==n_text, f\"matched {len(targets)} vs N_text {n_text}\"\n    return np.asarray(targets, dtype=np.int64)\n\n# --------------------------\n# Val split by image id\n# --------------------------\ndef make_image_id_split(train_npz: Path, captions_txt: Path, seed=42, val_ratio=0.1):\n    d = load_npz(train_npz)\n    X = d[\"captions/embeddings\"].astype(np.float32)          # (N_text, 1024)\n    I = d[\"images/embeddings\"].astype(np.float32)            # (N_img, 1536)\n    img_names = d[\"images/names\"]\n    ex,ba,st = _build_image_index(img_names)\n    targets = _iter_targets_from_captions(captions_txt, len(X), ex,ba,st)  # image index per caption\n    img_id_per_row = img_names[targets]\n\n    uniq = np.unique(img_id_per_row)\n    rng = np.random.default_rng(seed); rng.shuffle(uniq)\n    n_val = max(1, int(len(uniq)*val_ratio))\n    val_set = set(uniq[:n_val])\n\n    mask_val = np.array([iid in val_set for iid in img_id_per_row])\n    mask_trn = ~mask_val\n\n    # (sanity) no leakage:\n    trn_imgs = set(np.unique(img_id_per_row[mask_trn]).tolist())\n    val_imgs = set(np.unique(img_id_per_row[mask_val]).tolist())\n    leakage = len(trn_imgs.intersection(val_imgs))!=0\n\n    print(f\"[split] captions: train={mask_trn.sum()} | val={mask_val.sum()} | \"\n          f\"unique images: train={len(trn_imgs)} | val={len(val_imgs)} | leakage={leakage}\")\n\n    # build gallery for val = unique val images (rows from I)\n    val_img_indices = np.array(sorted({ex.get(str(x), None) or ba.get(basename(str(x)), None)\n                                       for x in val_imgs if x is not None}))\n    G_val = I[val_img_indices]\n    # map each val caption to its true gallery index\n    # (true image index within G_val)\n    map_global_to_local = {gi:i for i,gi in enumerate(val_img_indices)}\n    y_val_local = np.array([map_global_to_local[t] for t in targets[mask_val]], dtype=np.int64)\n\n    return (X[mask_trn], targets[mask_trn]), (X[mask_val], y_val_local, G_val), (mask_trn, mask_val)\n\n# --------------------------\n# Retrieval metrics\n# --------------------------\ndef compute_mrr(topk_idx: np.ndarray, gt: np.ndarray) -> float:\n    rr=[]\n    for i in range(len(gt)):\n        pos = np.where(topk_idx[i]==gt[i])[0]\n        rr.append(1.0/(pos[0]+1) if len(pos)>0 else 0.0)\n    return float(np.mean(rr))\n\ndef recall_at_k(topk_idx: np.ndarray, gt: np.ndarray, k: int) -> float:\n    return float(np.mean([gt[i] in topk_idx[i,:k] for i in range(len(gt))]))\n\n@torch.no_grad()\ndef eval_full_gallery(pred: torch.Tensor, G: torch.Tensor, y_true_local: np.ndarray, k: int = 100):\n    # Ensure both tensors live on the same device\n    if G.device != pred.device:\n        G = G.to(pred.device)\n\n    # cosine on L2-normalized vectors (validation protocol)\n    pred_n = F.normalize(pred, dim=-1)\n    G_n    = F.normalize(G, dim=-1)\n    sims   = pred_n @ G_n.t()                         # (Nq, Ng)\n    topk   = min(k, G_n.size(0))\n    idx    = sims.topk(k=topk, dim=1, largest=True, sorted=True).indices.cpu().numpy()\n\n    # metrics\n    def _mrr(topk_idx, gt):\n        rr=[]\n        for i in range(len(gt)):\n            pos = np.where(topk_idx[i]==gt[i])[0]\n            rr.append(1.0/(pos[0]+1) if len(pos)>0 else 0.0)\n        return float(np.mean(rr))\n\n    def _recall_k(topk_idx, gt, K):\n        K = min(K, topk_idx.shape[1])\n        return float(np.mean([gt[i] in topk_idx[i,:K] for i in range(len(gt))]))\n\n    return {\n        \"MRR\": _mrr(idx, y_true_local),\n        \"R1\":  _recall_k(idx, y_true_local, 1),\n        \"R5\":  _recall_k(idx, y_true_local, 5),\n        \"R10\": _recall_k(idx, y_true_local, 10),\n    }\n\n# --------------------------\n# Pooling no-op check (on text)\n# --------------------------\ndef pooling_noop_check(X_val: np.ndarray):\n    # Your text embeddings are already pooled (single vector).\n    # Any \"CLS vs mean-patch\" toggle on text should do nothing.\n    x = torch.from_numpy(X_val[:2048]).float()\n    x_cls  = x.clone()\n    # \"mean\" pretend: average over fake patches (not applicable)\n    x_mean = x.mean(dim=1, keepdim=True) if x.ndim==3 else x  # will equal x if ndims==2\n    diff = (x_cls - x_mean).abs().max().item()\n    if x.ndim == 2 and diff == 0.0:\n        print(\"[pooling] Text CLS vs mean is a NO-OP (identical). This explains equal MRR for CLS/mean in your logs.\")\n    else:\n        print(f\"[pooling] Text tensor ndim={x.ndim}; max|CLS-mean|={diff:.3e} (should be ~0 for your case).\")\n\n# --------------------------\n# Write submissions A/B (normalized vs raw)\n# --------------------------\ndef write_submission(ids, Z: np.ndarray, out_csv: Path):\n    import pandas as pd\n    df = pd.DataFrame({\"id\": ids, \"embedding\": Z.tolist()})\n    df.to_csv(out_csv, index=False, float_format=\"%.17g\")\n    print(f\"[submission] wrote {out_csv}\")\n\n# --------------------------\n# Dummy model interface (plug your model here)\n# --------------------------\nclass IdentityHead(torch.nn.Module):\n    \"\"\"Use this if you already have translated predictions saved externally.\n       Otherwise replace this with your loaded MLP and correct dims.\n    \"\"\"\n    def __init__(self, d): super().__init__(); self.d=d\n    def forward(self, x): return x\n\n\ndef fit_linear_map_ridge(X_tr: np.ndarray, Y_tr: np.ndarray, l2: float = 1e-2, device=None):\n    \"\"\"\n    Learn A s.t. X @ A ≈ Y (ridge-regularized least squares).\n    X_tr: (N, dx) text; Y_tr: (N, dy) image\n    Returns torch.Tensor A: (dx, dy) on `device`.\n    \"\"\"\n    if device is None:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    X = torch.from_numpy(X_tr).to(device)          # (N, dx)\n    Y = torch.from_numpy(Y_tr).to(device)          # (N, dy)\n    dx = X.shape[1]\n    # Normal equations: A = (XᵀX + λI)⁻¹ Xᵀ Y\n    Xt = X.transpose(0,1)                           # (dx, N)\n    G  = Xt @ X                                     # (dx, dx)\n    G = G + l2 * torch.eye(dx, device=device)\n    A  = torch.linalg.solve(G, Xt @ Y)              # (dx, dy)\n    return A\n\ndef run(args):\n    train_npz = Path(args.train_npz)\n    test_npz  = Path(args.test_npz)\n    train_caps= Path(args.train_captions)\n    out_dir   = Path(args.out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n\n    dtr = load_npz(train_npz)\n    ok_dims = assert_dims(dtr, expect_text=1024, expect_img=1536)\n\n    # Split by image id (no leakage)\n    (Xtr,_), (Xv, yv_local, Gv_np), _ = make_image_id_split(train_npz, train_caps, seed=args.seed, val_ratio=args.val_ratio)\n\n    # --- after: (Xtr,_), (Xv, yv_local, Gv_np), ...\n    # Build Ytr from training rows (true image embeddings per caption)\n    D = np.load(args.train_npz, allow_pickle=True)\n    img_names = D[\"images/names\"]\n    I_all     = D[\"images/embeddings\"].astype(np.float32)\n    # Recompute train targets like we did for the split:\n    ex,ba,st  = _build_image_index(img_names)\n    targets_all = _iter_targets_from_captions(Path(args.train_captions), len(D[\"captions/embeddings\"]), ex,ba,st)\n    mask_trn = _[0]  # (mask_trn, mask_val) returned earlier; we kept it as \"_\"\n    Ytr = I_all[targets_all[mask_trn]]               # (N_train_caps, 1536)\n    \n    # If your translator is identity or dims don't match, use the closed-form A\n    use_ridge = True  # set False if you will load your MLP\n    if use_ridge:\n        print(\"[ridge] fitting closed-form linear map X→Y on train split...\")\n        A = fit_linear_map_ridge(Xtr, Ytr, l2=1e-2, device=device)   # (1024,1536)\n    \n        # VAL preds\n        BS=2048\n        preds_val=[]\n        with torch.no_grad():\n            for i in range(0, len(Xv), BS):\n                q = torch.from_numpy(Xv[i:i+BS]).float().to(device)   # (b,1024)\n                z = q @ A                                             # (b,1536)\n                preds_val.append(z)\n        preds_val = torch.cat(preds_val, dim=0)                       # torch\n    \n        Gv = torch.from_numpy(Gv_np).float().to(device)\n        stats = eval_full_gallery(preds_val, Gv, yv_local, k=100)\n        print(\"[val] full-gallery retrieval:\", json.dumps(stats, indent=2))\n    \n        # TEST preds + A/B submissions\n        dtst = load_npz(Path(args.test_npz))\n        Q = dtst[\"captions/embeddings\"].astype(np.float32)\n        ids = dtst.get(\"captions/ids\", np.arange(len(Q)))\n        outs=[]\n        with torch.no_grad():\n            for i in range(0, len(Q), BS):\n                q = torch.from_numpy(Q[i:i+BS]).float().to(device)\n                z = q @ A\n                outs.append(z)\n        preds_test = torch.cat(outs, dim=0)\n    \n        Z_norm = F.normalize(preds_test, dim=-1).cpu().numpy()\n        write_submission(ids, Z_norm, Path(args.out_dir)/\"submission_norm.csv\")\n        Z_raw  = preds_test.cpu().numpy()\n        write_submission(ids, Z_raw,  Path(args.out_dir)/\"submission_raw.csv\")\n        return\n\n    # quick magnitude diagnostics\n    norms_pred = preds_test.norm(dim=-1).mean().item()\n    norms_G    = torch.from_numpy(load_npz(train_npz)[\"images/embeddings\"]).float().norm(dim=-1).mean().item()\n    print(f\"[diag] mean||pred||={norms_pred:.3f} vs mean||image||={norms_G:.3f} (useful if raw dot vs cosine matters)\")\n\n    report = {\n        \"dims_ok\": ok_dims,\n        \"val_MRR\": stats[\"MRR\"],\n        \"val_R@1\": stats[\"R1\"],\n        \"val_R@5\": stats[\"R5\"],\n        \"val_R@10\": stats[\"R10\"],\n        \"notes\": [\n            \"Text pooling toggle is a no-op (CLS vs mean identical) — expected.\",\n            \"Use submission_norm.csv vs submission_raw.csv A/B to see leaderboard scorer’s sensitivity to normalization.\",\n            \"Val split built by image id; metrics reflect official retrieval protocol (captions→val gallery).\"\n        ]\n    }\n    (out_dir/\"sanity_report.json\").write_text(json.dumps(report, indent=2))\n    print(f\"[ok] wrote {out_dir/'sanity_report.json'}\")\n    \nif __name__ == \"__main__\":\n    import sys\n    # ignore unwanted Jupyter args like \"-f ...\"\n    argv = [a for a in sys.argv if not a.startswith(\"-f\")]\n    p = argparse.ArgumentParser()\n    p.add_argument(\"--train_npz\", type=str, default=\"/kaggle/working/data/train/train/train.npz\")\n    p.add_argument(\"--test_npz\",  type=str, default=\"/kaggle/working/data/test/test/test.clean.npz\")\n    p.add_argument(\"--train_captions\", type=str, default=\"/kaggle/working/data/train/train/captions.txt\")\n    p.add_argument(\"--out_dir\", type=str, default=\"checks_out\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    run(args)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T23:56:25.010838Z","iopub.execute_input":"2025-10-26T23:56:25.011153Z","iopub.status.idle":"2025-10-26T23:56:35.235208Z","shell.execute_reply.started":"2025-10-26T23:56:25.011134Z","shell.execute_reply":"2025-10-26T23:56:35.234204Z"}},"outputs":[{"name":"stdout","text":"[meta] text_dim=1024 | image_dim=1536\n[split] captions: train=112500 | val=12500 | unique images: train=22500 | val=2500 | leakage=False\n[ridge] fitting closed-form linear map X→Y on train split...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/3818885625.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--val_ratio\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_37/3818885625.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_ridge\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[ridge] fitting closed-form linear map X→Y on train split...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_linear_map_ridge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# (1024,1536)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# VAL preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"],"ename":"NameError","evalue":"name 'device' is not defined","output_type":"error"}],"execution_count":58},{"cell_type":"code","source":"#!/usr/bin/env python3\nimport argparse, json, re, time\nfrom pathlib import Path\nfrom os.path import basename\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\n# --------------------------\n# Simple MLP Translator\n# --------------------------\nclass MLPTranslator(torch.nn.Module):\n    def __init__(self, text_dim=1024, img_dim=1536, hidden_dim=2048):\n        super().__init__()\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(text_dim, hidden_dim),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(0.1),\n            torch.nn.Linear(hidden_dim, img_dim)\n        )\n    \n    def forward(self, x):\n        return self.mlp(x)\n\n# --------------------------\n# I/O helpers\n# --------------------------\ndef load_npz(path: Path):\n    d = np.load(path, allow_pickle=True)\n    return d\n\ndef assert_dims(d, expect_text=1024, expect_img=1536):\n    md = {k: d[k][0] for k in d.files if k.startswith(\"metadata/\")}\n    tdim = md.get(\"metadata/embedding_dim_text\", None)\n    idim = md.get(\"metadata/embedding_dim_image\", None)\n    print(f\"[meta] text_dim={tdim} | image_dim={idim}\")\n    ok = (tdim == expect_text) and (idim == expect_img)\n    if not ok:\n        print(\"[WARN] Metadata dims differ from expected fixed encoders \"\n              f\"(expected text={expect_text}, image={expect_img}). \"\n              \"Absolute metrics may shift; re-generate .npz with the official encoders.\")\n    return ok\n\ndef _build_image_index(image_ids):\n    idx_exact = {}; idx_base={}; idx_stem={}\n    for i, v in enumerate(image_ids):\n        s = str(v); idx_exact[s]=i\n        b = basename(s); idx_base[b]=i\n        stem = b.rsplit(\".\",1)[0] if \".\" in b else b\n        idx_stem[stem]=i\n    return idx_exact, idx_base, idx_stem\n\ndef _iter_targets_from_captions(path: Path, n_text: int, idx_exact, idx_base, idx_stem):\n    targets=[]\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        for raw in f:\n            if len(targets)>=n_text: break\n            line=raw.strip()\n            if not line: continue\n            parts=re.split(r'\\||\\t|,| {2,}', line)\n            if len(parts)==1: parts=line.split(\" \",1)\n            tok=parts[0].strip().strip('\"').strip(\"'\")\n            if not tok: continue\n            def _match(tok_):\n                if tok_ in idx_exact: return idx_exact[tok_]\n                b=basename(tok_)\n                if b in idx_base: return idx_base[b]\n                stem=b.rsplit(\".\",1)[0] if \".\" in b else b\n                if stem in idx_stem: return idx_stem[stem]\n                return None\n            idx=_match(tok)\n            if idx is None:\n                tok2=tok.replace(\"Images/\",\"\").replace(\"./\",\"\")\n                idx=_match(tok2)\n            if idx is None:\n                if \".\" not in tok: continue\n                raise AssertionError(f\"Could not match image token '{tok}'\")\n            targets.append(idx)\n    assert len(targets)==n_text, f\"matched {len(targets)} vs N_text {n_text}\"\n    return np.asarray(targets, dtype=np.int64)\n\ndef eval_full_gallery(pred: torch.Tensor, G: torch.Tensor, y_true_local: np.ndarray, k: int = 100):\n    # Ensure both tensors live on the same device\n    device = pred.device\n    if G.device != device:\n        G = G.to(device)\n\n    # cosine on L2-normalized vectors (validation protocol)\n    pred_n = F.normalize(pred, dim=-1)    # (Nq, 1536)\n    G_n = F.normalize(G, dim=-1)          # (Ng, 1536)\n    sims = torch.mm(pred_n, G_n.t())      # (Nq, Ng)\n    topk = min(k, G_n.size(0))\n    idx = sims.topk(k=topk, dim=1, largest=True, sorted=True).indices.cpu().numpy()\n\n    # metrics\n    def _mrr(topk_idx, gt):\n        rr = []\n        for i in range(len(gt)):\n            pos = np.where(topk_idx[i]==gt[i])[0]\n            rr.append(1.0/(pos[0]+1) if len(pos)>0 else 0.0)\n        return float(np.mean(rr))\n\n    def _recall_k(topk_idx, gt, K):\n        K = min(K, topk_idx.shape[1])\n        return float(np.mean([gt[i] in topk_idx[i,:K] for i in range(len(gt))]))\n\n    return {\n        \"MRR\": _mrr(idx, y_true_local),\n        \"R1\":  _recall_k(idx, y_true_local, 1),\n        \"R5\":  _recall_k(idx, y_true_local, 5),\n        \"R10\": _recall_k(idx, y_true_local, 10),\n    }\n\ndef run(args):\n    # Set device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    train_npz = Path(args.train_npz)\n    test_npz = Path(args.test_npz)\n    train_caps = Path(args.train_captions)\n    out_dir = Path(args.out_dir)\n    out_dir.mkdir(parents=True, exist_ok=True)\n\n    dtr = load_npz(train_npz)\n    ok_dims = assert_dims(dtr, expect_text=1024, expect_img=1536)\n\n    # Split by image id (no leakage)\n    (Xtr, ytr), (Xv, yv_local, Gv_np), _ = make_image_id_split(\n        train_npz, train_caps, seed=args.seed, val_ratio=args.val_ratio\n    )\n\n    # Pooling no-op sanity on text\n    pooling_noop_check(Xv)\n\n    # Create and move model to GPU\n    model = MLPTranslator(text_dim=1024, img_dim=1536).to(device)\n    model.train()\n\n    # Quick training loop (you might want to expand this)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    batch_size = 512\n    n_epochs = 5\n\n    for epoch in range(n_epochs):\n        total_loss = 0\n        n_batches = 0\n        \n        # Training loop\n        for i in range(0, len(Xtr), batch_size):\n            batch_x = torch.from_numpy(Xtr[i:i+batch_size]).float().to(device)\n            batch_y = torch.from_numpy(dtr['images/embeddings'][ytr[i:i+batch_size]]).float().to(device)\n            \n            optimizer.zero_grad()\n            pred = model(batch_x)\n            loss = F.mse_loss(pred, batch_y)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            n_batches += 1\n        \n        print(f\"Epoch {epoch+1}/{n_epochs}, Avg Loss: {total_loss/n_batches:.6f}\")\n\n    # Evaluation mode\n    model.eval()\n\n    # Eval on VAL\n    BS = 1024\n    preds_val = []\n    with torch.no_grad():\n        for i in range(0, len(Xv), BS):\n            q = torch.from_numpy(Xv[i:i+BS]).float().to(device)\n            z = model(q)  # Now translates to image space (1536d)\n            preds_val.append(z)\n    preds_val = torch.cat(preds_val, dim=0)\n\n    Gv = torch.from_numpy(Gv_np).float().to(device)\n    stats = eval_full_gallery(preds_val, Gv, yv_local, k=100)\n    print(\"[val] full-gallery retrieval:\", json.dumps(stats, indent=2))\n\n    # Test predictions\n    dtst = load_npz(test_npz)\n    Q = dtst[\"captions/embeddings\"].astype(np.float32)\n    ids = dtst.get(\"captions/ids\", np.arange(len(Q)))\n\n    preds_test = []\n    with torch.no_grad():\n        for i in range(0, len(Q), BS):\n            q = torch.from_numpy(Q[i:i+BS]).float().to(device)\n            z = model(q)\n            preds_test.append(z)\n    preds_test = torch.cat(preds_test, dim=0)\n\n    # Normalized submission\n    Z_norm = F.normalize(preds_test, dim=-1).cpu().numpy()\n    write_submission(ids, Z_norm, out_dir/\"submission_norm.csv\")\n\n    # Raw submission\n    Z_raw = preds_test.cpu().numpy()\n    write_submission(ids, Z_raw, out_dir/\"submission_raw.csv\")\n\n    # Diagnostics\n    norms_pred = preds_test.norm(dim=-1).mean().item()\n    norms_G = torch.from_numpy(dtr[\"images/embeddings\"]).float().norm(dim=-1).mean().item()\n    print(f\"[diag] mean||pred||={norms_pred:.3f} vs mean||image||={norms_G:.3f}\")\n\n    # Convert NumPy types to Python native types for JSON serialization\n    report = {\n        \"dims_ok\": bool(ok_dims),  # Convert np.bool_ to Python bool\n        \"val_MRR\": float(stats[\"MRR\"]),  # Convert np.float to Python float\n        \"val_R@1\": float(stats[\"R1\"]),\n        \"val_R@5\": float(stats[\"R5\"]),\n        \"val_R@10\": float(stats[\"R10\"]),\n        \"notes\": [\n            \"Text pooling toggle is a no-op (CLS vs mean identical) — expected.\",\n            \"Using MLP translator from text (1024d) to image space (1536d)\",\n            \"Val split built by image id; metrics reflect official retrieval protocol.\"\n        ]\n    }\n    \n    # Write the report\n    (out_dir/\"sanity_report.json\").write_text(json.dumps(report, indent=2))\n    print(f\"[ok] wrote {out_dir/'sanity_report.json'}\")\n\nif __name__ == \"__main__\":\n    p = argparse.ArgumentParser()\n    p.add_argument(\"--train_npz\", type=str, default=\"/kaggle/working/data/train/train/train.npz\")\n    p.add_argument(\"--test_npz\", type=str, default=\"/kaggle/working/data/test/test/test.clean.npz\")\n    p.add_argument(\"--train_captions\", type=str, default=\"/kaggle/working/data/train/train/captions.txt\")\n    p.add_argument(\"--out_dir\", type=str, default=\"checks_out\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    run(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T23:56:40.402891Z","iopub.execute_input":"2025-10-26T23:56:40.403640Z","iopub.status.idle":"2025-10-27T00:13:38.988231Z","shell.execute_reply.started":"2025-10-26T23:56:40.403612Z","shell.execute_reply":"2025-10-27T00:13:38.987144Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n[meta] text_dim=1024 | image_dim=1536\n[split] captions: train=112500 | val=12500 | unique images: train=22500 | val=2500 | leakage=False\n[pooling] Text CLS vs mean is a NO-OP (identical). This explains equal MRR for CLS/mean in your logs.\nEpoch 1/5, Avg Loss: 0.198158\nEpoch 2/5, Avg Loss: 0.159567\nEpoch 3/5, Avg Loss: 0.152692\nEpoch 4/5, Avg Loss: 0.148695\nEpoch 5/5, Avg Loss: 0.145914\n[val] full-gallery retrieval: {\n  \"MRR\": 0.17877673524057414,\n  \"R1\": 0.0916,\n  \"R5\": 0.2632,\n  \"R10\": 0.36432\n}\n[submission] wrote checks_out/submission_norm.csv\n[submission] wrote checks_out/submission_raw.csv\n[diag] mean||pred||=21.213 vs mean||image||=25.939\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/1571074265.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--val_ratio\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_37/1571074265.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    166\u001b[0m         ]\n\u001b[1;32m    167\u001b[0m     }\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"sanity_report.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[ok] wrote {out_dir/'sanity_report.json'}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[0;32m--> 180\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    181\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Object of type bool_ is not JSON serializable"],"ename":"TypeError","evalue":"Object of type bool_ is not JSON serializable","output_type":"error"}],"execution_count":59},{"cell_type":"markdown","source":"What we learned:\n\n- text_dim=1024 | image_dim=1536 we using the fixed encoders (roberta-large-nli-stsb-mean-tokens and dinov2-giant).\n-  leakage=False, val split by image id → new validation pipeline is officially aligned with the challenge spec.\n- Cosine retrieval (F.normalize, dot product) matches the public LB similarity.\n\nThe LB expects already-normalized embeddings.\n\n- Raw outputs distort similarity magnitudes (pred norms ≈ 21 vs image norms ≈ 26 → biased dot products).\n-  Always normalize before writing the submission.\n\nmean||pred|| = 21.213 and mean||image|| = 25.939\nhe LB similarity is cosine on normalized vectors, i.e. sim = (z_pred / ||z_pred||) @ (z_img / ||z_img||).T","metadata":{}},{"cell_type":"code","source":"# python runner.py --out_dir mlp1_cls_cos0.5_mse1.5 --pooling CLS --alpha 0.5 --beta 1.5 --gamma 0 --align_loss none --arch mlp1\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos0.5_mse1.5\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=0.5)\n    p.add_argument(\"--beta\", type=float, default=1.5)\n    p.add_argument(\"--gamma\", type=float, default=0.0)\n    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T20:37:29.657124Z","iopub.execute_input":"2025-10-26T20:37:29.657685Z","iopub.status.idle":"2025-10-26T20:41:08.103017Z","shell.execute_reply.started":"2025-10-26T20:37:29.657656Z","shell.execute_reply":"2025-10-26T20:41:08.102080Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=none | α=0.5 β=1.5 γ=0.0\n[01] train_loss=0.609829 | val_MRR=0.0321 | R@1=0.009 R@5=0.040\n[02] train_loss=0.387240 | val_MRR=0.0599 | R@1=0.023 R@5=0.079\n[03] train_loss=0.357811 | val_MRR=0.0814 | R@1=0.035 R@5=0.110\n[04] train_loss=0.342970 | val_MRR=0.0957 | R@1=0.041 R@5=0.131\n[05] train_loss=0.333531 | val_MRR=0.1105 | R@1=0.050 R@5=0.155\n[06] train_loss=0.326755 | val_MRR=0.1204 | R@1=0.054 R@5=0.172\n[07] train_loss=0.321568 | val_MRR=0.1302 | R@1=0.059 R@5=0.186\n[08] train_loss=0.317397 | val_MRR=0.1376 | R@1=0.064 R@5=0.196\n[09] train_loss=0.313890 | val_MRR=0.1463 | R@1=0.070 R@5=0.211\n[10] train_loss=0.310848 | val_MRR=0.1538 | R@1=0.075 R@5=0.221\n[11] train_loss=0.308186 | val_MRR=0.1608 | R@1=0.079 R@5=0.231\n[12] train_loss=0.305821 | val_MRR=0.1665 | R@1=0.083 R@5=0.240\n[13] train_loss=0.303701 | val_MRR=0.1734 | R@1=0.088 R@5=0.249\n[14] train_loss=0.301760 | val_MRR=0.1781 | R@1=0.092 R@5=0.258\n[15] train_loss=0.299996 | val_MRR=0.1822 | R@1=0.095 R@5=0.262\n[16] train_loss=0.298357 | val_MRR=0.1878 | R@1=0.099 R@5=0.272\n[17] train_loss=0.296822 | val_MRR=0.1916 | R@1=0.102 R@5=0.277\n[18] train_loss=0.295417 | val_MRR=0.1954 | R@1=0.104 R@5=0.282\n[19] train_loss=0.294070 | val_MRR=0.1981 | R@1=0.105 R@5=0.284\n[20] train_loss=0.292797 | val_MRR=0.2026 | R@1=0.109 R@5=0.291\n[21] train_loss=0.291578 | val_MRR=0.2068 | R@1=0.113 R@5=0.297\n[22] train_loss=0.290410 | val_MRR=0.2094 | R@1=0.114 R@5=0.301\n[23] train_loss=0.289296 | val_MRR=0.2126 | R@1=0.117 R@5=0.306\n[24] train_loss=0.288204 | val_MRR=0.2175 | R@1=0.122 R@5=0.311\n[25] train_loss=0.287174 | val_MRR=0.2179 | R@1=0.120 R@5=0.313\n[26] train_loss=0.286177 | val_MRR=0.2229 | R@1=0.125 R@5=0.318\n[27] train_loss=0.285224 | val_MRR=0.2243 | R@1=0.126 R@5=0.322\n[28] train_loss=0.284333 | val_MRR=0.2267 | R@1=0.128 R@5=0.325\n[29] train_loss=0.283455 | val_MRR=0.2284 | R@1=0.129 R@5=0.328\n[30] train_loss=0.282638 | val_MRR=0.2287 | R@1=0.129 R@5=0.328\n[best] MRR=0.2287 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos0.5_mse1.5/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos0.5_mse1.5/submission.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# python runner.py --out_dir mlp1_cls_cos1.5_mse0.5 --pooling CLS --alpha 1.5 --beta 0.5 --gamma 0 --align_loss none --arch mlp1\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos1.5_mse0.5\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1.5)\n    p.add_argument(\"--beta\", type=float, default=0.5)\n    p.add_argument(\"--gamma\", type=float, default=0.0)\n    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T20:48:25.977054Z","iopub.execute_input":"2025-10-26T20:48:25.977835Z","iopub.status.idle":"2025-10-26T20:52:04.527243Z","shell.execute_reply.started":"2025-10-26T20:48:25.977805Z","shell.execute_reply":"2025-10-26T20:52:04.526264Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=none | α=1.5 β=0.5 γ=0.0\n[01] train_loss=0.712952 | val_MRR=0.0363 | R@1=0.010 R@5=0.046\n[02] train_loss=0.438971 | val_MRR=0.0648 | R@1=0.025 R@5=0.088\n[03] train_loss=0.403020 | val_MRR=0.0858 | R@1=0.037 R@5=0.114\n[04] train_loss=0.385062 | val_MRR=0.0999 | R@1=0.044 R@5=0.136\n[05] train_loss=0.373677 | val_MRR=0.1140 | R@1=0.052 R@5=0.158\n[06] train_loss=0.365519 | val_MRR=0.1241 | R@1=0.058 R@5=0.175\n[07] train_loss=0.359262 | val_MRR=0.1334 | R@1=0.063 R@5=0.189\n[08] train_loss=0.354221 | val_MRR=0.1402 | R@1=0.066 R@5=0.201\n[09] train_loss=0.349983 | val_MRR=0.1489 | R@1=0.072 R@5=0.214\n[10] train_loss=0.346339 | val_MRR=0.1560 | R@1=0.077 R@5=0.225\n[11] train_loss=0.343170 | val_MRR=0.1631 | R@1=0.081 R@5=0.233\n[12] train_loss=0.340354 | val_MRR=0.1674 | R@1=0.083 R@5=0.241\n[13] train_loss=0.337847 | val_MRR=0.1748 | R@1=0.089 R@5=0.252\n[14] train_loss=0.335557 | val_MRR=0.1789 | R@1=0.091 R@5=0.259\n[15] train_loss=0.333478 | val_MRR=0.1818 | R@1=0.092 R@5=0.264\n[16] train_loss=0.331553 | val_MRR=0.1880 | R@1=0.097 R@5=0.273\n[17] train_loss=0.329760 | val_MRR=0.1917 | R@1=0.100 R@5=0.278\n[18] train_loss=0.328116 | val_MRR=0.1961 | R@1=0.104 R@5=0.284\n[19] train_loss=0.326539 | val_MRR=0.1991 | R@1=0.106 R@5=0.287\n[20] train_loss=0.325058 | val_MRR=0.2038 | R@1=0.110 R@5=0.295\n[21] train_loss=0.323631 | val_MRR=0.2081 | R@1=0.113 R@5=0.300\n[22] train_loss=0.322302 | val_MRR=0.2106 | R@1=0.114 R@5=0.305\n[23] train_loss=0.321045 | val_MRR=0.2138 | R@1=0.118 R@5=0.308\n[24] train_loss=0.319827 | val_MRR=0.2172 | R@1=0.120 R@5=0.312\n[25] train_loss=0.318679 | val_MRR=0.2185 | R@1=0.121 R@5=0.313\n[26] train_loss=0.317569 | val_MRR=0.2231 | R@1=0.125 R@5=0.319\n[27] train_loss=0.316524 | val_MRR=0.2259 | R@1=0.128 R@5=0.323\n[28] train_loss=0.315534 | val_MRR=0.2274 | R@1=0.129 R@5=0.325\n[29] train_loss=0.314565 | val_MRR=0.2283 | R@1=0.129 R@5=0.325\n[30] train_loss=0.313665 | val_MRR=0.2287 | R@1=0.130 R@5=0.326\n[best] MRR=0.2287 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos1.5_mse0.5/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos1.5_mse0.5/submission.csv\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# python runner.py --out_dir mlp1_cls_cos+mse+moments --pooling CLS --alpha 1 --beta 1 --gamma 0 --align_loss moment --arch mlp1\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos+mse+moments\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1)\n    p.add_argument(\"--beta\", type=float, default=1)\n    p.add_argument(\"--gamma\", type=float, default=0.0)\n    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T20:53:16.142479Z","iopub.execute_input":"2025-10-26T20:53:16.143281Z","iopub.status.idle":"2025-10-26T20:56:54.695153Z","shell.execute_reply.started":"2025-10-26T20:53:16.143249Z","shell.execute_reply":"2025-10-26T20:56:54.694202Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.0\n[01] train_loss=0.740650 | val_MRR=0.0504 | R@1=0.017 R@5=0.067\n[02] train_loss=0.465031 | val_MRR=0.0868 | R@1=0.038 R@5=0.116\n[03] train_loss=0.426755 | val_MRR=0.1102 | R@1=0.050 R@5=0.150\n[04] train_loss=0.407163 | val_MRR=0.1248 | R@1=0.057 R@5=0.176\n[05] train_loss=0.394496 | val_MRR=0.1385 | R@1=0.064 R@5=0.197\n[06] train_loss=0.385237 | val_MRR=0.1488 | R@1=0.070 R@5=0.211\n[07] train_loss=0.378039 | val_MRR=0.1587 | R@1=0.075 R@5=0.228\n[08] train_loss=0.372214 | val_MRR=0.1672 | R@1=0.081 R@5=0.240\n[09] train_loss=0.367317 | val_MRR=0.1747 | R@1=0.086 R@5=0.252\n[10] train_loss=0.363102 | val_MRR=0.1818 | R@1=0.092 R@5=0.263\n[11] train_loss=0.359437 | val_MRR=0.1892 | R@1=0.097 R@5=0.272\n[12] train_loss=0.356184 | val_MRR=0.1951 | R@1=0.102 R@5=0.282\n[13] train_loss=0.353258 | val_MRR=0.2016 | R@1=0.107 R@5=0.290\n[14] train_loss=0.350566 | val_MRR=0.2067 | R@1=0.111 R@5=0.297\n[15] train_loss=0.348106 | val_MRR=0.2092 | R@1=0.112 R@5=0.300\n[16] train_loss=0.345823 | val_MRR=0.2156 | R@1=0.117 R@5=0.309\n[17] train_loss=0.343689 | val_MRR=0.2191 | R@1=0.120 R@5=0.313\n[18] train_loss=0.341751 | val_MRR=0.2238 | R@1=0.123 R@5=0.319\n[19] train_loss=0.339929 | val_MRR=0.2277 | R@1=0.126 R@5=0.323\n[20] train_loss=0.338219 | val_MRR=0.2303 | R@1=0.129 R@5=0.327\n[21] train_loss=0.336597 | val_MRR=0.2341 | R@1=0.132 R@5=0.333\n[22] train_loss=0.335087 | val_MRR=0.2367 | R@1=0.133 R@5=0.338\n[23] train_loss=0.333671 | val_MRR=0.2403 | R@1=0.137 R@5=0.344\n[24] train_loss=0.332315 | val_MRR=0.2432 | R@1=0.139 R@5=0.347\n[25] train_loss=0.331034 | val_MRR=0.2448 | R@1=0.140 R@5=0.348\n[26] train_loss=0.329796 | val_MRR=0.2483 | R@1=0.144 R@5=0.354\n[27] train_loss=0.328640 | val_MRR=0.2510 | R@1=0.146 R@5=0.356\n[28] train_loss=0.327536 | val_MRR=0.2532 | R@1=0.148 R@5=0.361\n[29] train_loss=0.326480 | val_MRR=0.2526 | R@1=0.146 R@5=0.358\n[30] train_loss=0.325500 | val_MRR=0.2541 | R@1=0.148 R@5=0.361\n[best] MRR=0.2541 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos+mse+moments/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos+mse+moments/submission.csv\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# python runner.py --out_dir mlp1_cls_cos+mse+normcal --pooling CLS --alpha 1 --beta 1 --gamma 0 --align_loss normcal --arch mlp1\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos+mse+normcal\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1)\n    p.add_argument(\"--beta\", type=float, default=1)\n    p.add_argument(\"--gamma\", type=float, default=0.0)\n    p.add_argument(\"--align_loss\", type=str, default=\"normcal\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T20:57:52.862678Z","iopub.execute_input":"2025-10-26T20:57:52.863257Z","iopub.status.idle":"2025-10-26T21:01:32.588592Z","shell.execute_reply.started":"2025-10-26T20:57:52.863229Z","shell.execute_reply":"2025-10-26T21:01:32.587854Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=normcal | α=1 β=1 γ=0.0\n[01] train_loss=2.795950 | val_MRR=0.0046 | R@1=0.001 R@5=0.003\n[02] train_loss=1.281909 | val_MRR=0.0047 | R@1=0.000 R@5=0.004\n[03] train_loss=0.996945 | val_MRR=0.0055 | R@1=0.001 R@5=0.004\n[04] train_loss=0.828152 | val_MRR=0.0065 | R@1=0.001 R@5=0.005\n[05] train_loss=0.748381 | val_MRR=0.0079 | R@1=0.001 R@5=0.006\n[06] train_loss=0.703146 | val_MRR=0.0096 | R@1=0.002 R@5=0.009\n[07] train_loss=0.661552 | val_MRR=0.0113 | R@1=0.002 R@5=0.011\n[08] train_loss=0.625856 | val_MRR=0.0132 | R@1=0.003 R@5=0.014\n[09] train_loss=0.631494 | val_MRR=0.0155 | R@1=0.004 R@5=0.017\n[10] train_loss=0.596262 | val_MRR=0.0179 | R@1=0.004 R@5=0.020\n[11] train_loss=0.585320 | val_MRR=0.0202 | R@1=0.005 R@5=0.023\n[12] train_loss=0.573368 | val_MRR=0.0227 | R@1=0.006 R@5=0.026\n[13] train_loss=0.557340 | val_MRR=0.0255 | R@1=0.008 R@5=0.030\n[14] train_loss=0.541786 | val_MRR=0.0278 | R@1=0.008 R@5=0.033\n[15] train_loss=0.541319 | val_MRR=0.0314 | R@1=0.010 R@5=0.038\n[16] train_loss=0.541412 | val_MRR=0.0338 | R@1=0.010 R@5=0.042\n[17] train_loss=0.529126 | val_MRR=0.0366 | R@1=0.012 R@5=0.046\n[18] train_loss=0.530570 | val_MRR=0.0395 | R@1=0.013 R@5=0.050\n[19] train_loss=0.517997 | val_MRR=0.0420 | R@1=0.015 R@5=0.053\n[20] train_loss=0.504706 | val_MRR=0.0444 | R@1=0.016 R@5=0.056\n[21] train_loss=0.504576 | val_MRR=0.0482 | R@1=0.018 R@5=0.061\n[22] train_loss=0.499347 | val_MRR=0.0503 | R@1=0.019 R@5=0.063\n[23] train_loss=0.494783 | val_MRR=0.0527 | R@1=0.020 R@5=0.066\n[24] train_loss=0.476123 | val_MRR=0.0549 | R@1=0.022 R@5=0.068\n[25] train_loss=0.479874 | val_MRR=0.0575 | R@1=0.023 R@5=0.072\n[26] train_loss=0.467404 | val_MRR=0.0595 | R@1=0.024 R@5=0.075\n[27] train_loss=0.469203 | val_MRR=0.0617 | R@1=0.025 R@5=0.079\n[28] train_loss=0.466118 | val_MRR=0.0636 | R@1=0.026 R@5=0.081\n[29] train_loss=0.467986 | val_MRR=0.0658 | R@1=0.027 R@5=0.084\n[30] train_loss=0.467743 | val_MRR=0.0682 | R@1=0.029 R@5=0.090\n[best] MRR=0.0682 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos+mse+normcal/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos+mse+normcal/submission.csv\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# python runner.py --out_dir mlp2_cls_cos+mse --pooling CLS --alpha 1 --beta 1 --gamma 0 --align_loss none --arch mlp2\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp2_cls_cos+mse\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1)\n    p.add_argument(\"--beta\", type=float, default=1)\n    p.add_argument(\"--gamma\", type=float, default=0.0)\n    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp2\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T21:03:05.614241Z","iopub.execute_input":"2025-10-26T21:03:05.615080Z","iopub.status.idle":"2025-10-26T21:06:40.038429Z","shell.execute_reply.started":"2025-10-26T21:03:05.615047Z","shell.execute_reply":"2025-10-26T21:06:40.037630Z"}},"outputs":[{"name":"stdout","text":"[model] mlp2 | params=2,362,368 (~9.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.0\n[01] train_loss=0.636256 | val_MRR=0.0449 | R@1=0.014 R@5=0.057\n[02] train_loss=0.438947 | val_MRR=0.0828 | R@1=0.032 R@5=0.115\n[03] train_loss=0.406235 | val_MRR=0.1096 | R@1=0.046 R@5=0.154\n[04] train_loss=0.389227 | val_MRR=0.1285 | R@1=0.056 R@5=0.181\n[05] train_loss=0.377987 | val_MRR=0.1440 | R@1=0.066 R@5=0.207\n[06] train_loss=0.369644 | val_MRR=0.1560 | R@1=0.073 R@5=0.229\n[07] train_loss=0.363055 | val_MRR=0.1688 | R@1=0.081 R@5=0.247\n[08] train_loss=0.357602 | val_MRR=0.1773 | R@1=0.087 R@5=0.259\n[09] train_loss=0.353023 | val_MRR=0.1858 | R@1=0.092 R@5=0.273\n[10] train_loss=0.348982 | val_MRR=0.1918 | R@1=0.096 R@5=0.281\n[11] train_loss=0.345339 | val_MRR=0.1993 | R@1=0.103 R@5=0.291\n[12] train_loss=0.341988 | val_MRR=0.2051 | R@1=0.108 R@5=0.296\n[13] train_loss=0.338930 | val_MRR=0.2127 | R@1=0.113 R@5=0.310\n[14] train_loss=0.336059 | val_MRR=0.2169 | R@1=0.116 R@5=0.317\n[15] train_loss=0.333389 | val_MRR=0.2221 | R@1=0.122 R@5=0.320\n[16] train_loss=0.330802 | val_MRR=0.2255 | R@1=0.124 R@5=0.324\n[17] train_loss=0.328334 | val_MRR=0.2307 | R@1=0.128 R@5=0.330\n[18] train_loss=0.326082 | val_MRR=0.2337 | R@1=0.131 R@5=0.335\n[19] train_loss=0.323883 | val_MRR=0.2359 | R@1=0.133 R@5=0.338\n[20] train_loss=0.321776 | val_MRR=0.2434 | R@1=0.140 R@5=0.347\n[21] train_loss=0.319802 | val_MRR=0.2426 | R@1=0.138 R@5=0.346\n[22] train_loss=0.317865 | val_MRR=0.2467 | R@1=0.142 R@5=0.352\n[23] train_loss=0.316039 | val_MRR=0.2486 | R@1=0.144 R@5=0.353\n[24] train_loss=0.314229 | val_MRR=0.2496 | R@1=0.146 R@5=0.354\n[25] train_loss=0.312527 | val_MRR=0.2533 | R@1=0.149 R@5=0.356\n[26] train_loss=0.310822 | val_MRR=0.2538 | R@1=0.150 R@5=0.359\n[27] train_loss=0.309195 | val_MRR=0.2552 | R@1=0.151 R@5=0.360\n[28] train_loss=0.307605 | val_MRR=0.2555 | R@1=0.151 R@5=0.358\n[29] train_loss=0.306055 | val_MRR=0.2591 | R@1=0.153 R@5=0.367\n[30] train_loss=0.304544 | val_MRR=0.2612 | R@1=0.155 R@5=0.369\n[best] MRR=0.2612 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp2_cls_cos+mse/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp2_cls_cos+mse/submission.csv\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# python runner.py --out_dir mlp1_cls_cos+mse+infoNCE --pooling CLS --alpha 1 --beta 1 --gamma 0.1 --align_loss none --arch mlp1\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos+mse+infoNCE\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1)\n    p.add_argument(\"--beta\", type=float, default=1)\n    p.add_argument(\"--gamma\", type=float, default=0.1)\n    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T23:14:57.655797Z","iopub.execute_input":"2025-10-26T23:14:57.656371Z","iopub.status.idle":"2025-10-26T23:18:38.723945Z","shell.execute_reply.started":"2025-10-26T23:14:57.656341Z","shell.execute_reply":"2025-10-26T23:18:38.722997Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=none | α=1 β=1 γ=0.1\n[01] train_loss=1.280466 | val_MRR=0.0384 | R@1=0.012 R@5=0.049\n[02] train_loss=1.027822 | val_MRR=0.0682 | R@1=0.028 R@5=0.092\n[03] train_loss=0.993354 | val_MRR=0.0901 | R@1=0.039 R@5=0.122\n[04] train_loss=0.976056 | val_MRR=0.1044 | R@1=0.046 R@5=0.143\n[05] train_loss=0.965049 | val_MRR=0.1202 | R@1=0.056 R@5=0.169\n[06] train_loss=0.957130 | val_MRR=0.1304 | R@1=0.061 R@5=0.185\n[07] train_loss=0.951046 | val_MRR=0.1404 | R@1=0.066 R@5=0.200\n[08] train_loss=0.946120 | val_MRR=0.1482 | R@1=0.071 R@5=0.214\n[09] train_loss=0.941967 | val_MRR=0.1561 | R@1=0.075 R@5=0.226\n[10] train_loss=0.938371 | val_MRR=0.1637 | R@1=0.081 R@5=0.235\n[11] train_loss=0.935229 | val_MRR=0.1720 | R@1=0.087 R@5=0.247\n[12] train_loss=0.932428 | val_MRR=0.1769 | R@1=0.091 R@5=0.254\n[13] train_loss=0.929919 | val_MRR=0.1842 | R@1=0.096 R@5=0.265\n[14] train_loss=0.927631 | val_MRR=0.1885 | R@1=0.099 R@5=0.272\n[15] train_loss=0.925544 | val_MRR=0.1910 | R@1=0.099 R@5=0.277\n[16] train_loss=0.923608 | val_MRR=0.1980 | R@1=0.106 R@5=0.285\n[17] train_loss=0.921790 | val_MRR=0.2007 | R@1=0.108 R@5=0.289\n[18] train_loss=0.920116 | val_MRR=0.2045 | R@1=0.110 R@5=0.295\n[19] train_loss=0.918501 | val_MRR=0.2098 | R@1=0.115 R@5=0.301\n[20] train_loss=0.916963 | val_MRR=0.2137 | R@1=0.118 R@5=0.308\n[21] train_loss=0.915489 | val_MRR=0.2177 | R@1=0.122 R@5=0.314\n[22] train_loss=0.914110 | val_MRR=0.2202 | R@1=0.122 R@5=0.316\n[23] train_loss=0.912819 | val_MRR=0.2231 | R@1=0.124 R@5=0.322\n[24] train_loss=0.911572 | val_MRR=0.2278 | R@1=0.129 R@5=0.325\n[25] train_loss=0.910402 | val_MRR=0.2294 | R@1=0.131 R@5=0.327\n[26] train_loss=0.909284 | val_MRR=0.2336 | R@1=0.133 R@5=0.333\n[27] train_loss=0.908220 | val_MRR=0.2355 | R@1=0.135 R@5=0.335\n[28] train_loss=0.907224 | val_MRR=0.2382 | R@1=0.138 R@5=0.338\n[29] train_loss=0.906249 | val_MRR=0.2385 | R@1=0.138 R@5=0.337\n[30] train_loss=0.905338 | val_MRR=0.2388 | R@1=0.137 R@5=0.340\n[best] MRR=0.2388 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos+mse+infoNCE/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos+mse+infoNCE/submission.csv\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# python runner.py --out_dir mlp1_cls_cos+mse+infoNCE --pooling CLS --lr 5e-5 --alpha 1 --beta 1 --gamma 0.1 --align_loss moment --arch mlp1\n\n# smaller LR stabilizes combo losses\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_lr5e5_moment01\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=5e-5)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1)\n    p.add_argument(\"--beta\", type=float, default=1)\n    p.add_argument(\"--gamma\", type=float, default=0.1)\n    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T21:52:39.542638Z","iopub.execute_input":"2025-10-26T21:52:39.543423Z","iopub.status.idle":"2025-10-26T21:56:12.933536Z","shell.execute_reply.started":"2025-10-26T21:52:39.543396Z","shell.execute_reply":"2025-10-26T21:56:12.932719Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n[01] train_loss=1.554588 | val_MRR=0.0285 | R@1=0.008 R@5=0.034\n[02] train_loss=1.149325 | val_MRR=0.0571 | R@1=0.021 R@5=0.075\n[03] train_loss=1.089582 | val_MRR=0.0791 | R@1=0.033 R@5=0.105\n[04] train_loss=1.059996 | val_MRR=0.0957 | R@1=0.042 R@5=0.130\n[05] train_loss=1.041193 | val_MRR=0.1090 | R@1=0.050 R@5=0.148\n[06] train_loss=1.027914 | val_MRR=0.1190 | R@1=0.054 R@5=0.163\n[07] train_loss=1.017830 | val_MRR=0.1276 | R@1=0.058 R@5=0.178\n[08] train_loss=1.009741 | val_MRR=0.1349 | R@1=0.062 R@5=0.191\n[09] train_loss=1.003019 | val_MRR=0.1420 | R@1=0.066 R@5=0.200\n[10] train_loss=0.997265 | val_MRR=0.1487 | R@1=0.070 R@5=0.210\n[11] train_loss=0.992285 | val_MRR=0.1552 | R@1=0.074 R@5=0.222\n[12] train_loss=0.987915 | val_MRR=0.1594 | R@1=0.075 R@5=0.230\n[13] train_loss=0.984024 | val_MRR=0.1658 | R@1=0.080 R@5=0.239\n[14] train_loss=0.980513 | val_MRR=0.1707 | R@1=0.084 R@5=0.247\n[15] train_loss=0.977328 | val_MRR=0.1748 | R@1=0.086 R@5=0.254\n[16] train_loss=0.974423 | val_MRR=0.1802 | R@1=0.090 R@5=0.262\n[17] train_loss=0.971703 | val_MRR=0.1843 | R@1=0.093 R@5=0.267\n[18] train_loss=0.969221 | val_MRR=0.1891 | R@1=0.097 R@5=0.274\n[19] train_loss=0.966895 | val_MRR=0.1933 | R@1=0.100 R@5=0.281\n[20] train_loss=0.964707 | val_MRR=0.1967 | R@1=0.103 R@5=0.284\n[21] train_loss=0.962656 | val_MRR=0.2011 | R@1=0.107 R@5=0.290\n[22] train_loss=0.960720 | val_MRR=0.2044 | R@1=0.109 R@5=0.294\n[23] train_loss=0.958913 | val_MRR=0.2083 | R@1=0.112 R@5=0.300\n[24] train_loss=0.957193 | val_MRR=0.2118 | R@1=0.114 R@5=0.304\n[25] train_loss=0.955552 | val_MRR=0.2133 | R@1=0.115 R@5=0.309\n[26] train_loss=0.953995 | val_MRR=0.2170 | R@1=0.118 R@5=0.312\n[27] train_loss=0.952523 | val_MRR=0.2198 | R@1=0.120 R@5=0.316\n[28] train_loss=0.951132 | val_MRR=0.2221 | R@1=0.122 R@5=0.320\n[29] train_loss=0.949784 | val_MRR=0.2240 | R@1=0.123 R@5=0.321\n[30] train_loss=0.948511 | val_MRR=0.2257 | R@1=0.125 R@5=0.324\n[best] MRR=0.2257 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_lr5e5_moment01/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_lr5e5_moment01/submission.csv\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# python runner.py --out_dir mlp2_moment_infonce01 --arch mlp2 --gamma 0.1 --align_loss moment --lr 2e-4\n# If underfitting, higher LR helps\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_lr2e4_moment01\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=2e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1)\n    p.add_argument(\"--beta\", type=float, default=1)\n    p.add_argument(\"--gamma\", type=float, default=0.1)\n    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T22:50:39.312033Z","iopub.execute_input":"2025-10-26T22:50:39.312745Z","iopub.status.idle":"2025-10-26T22:54:15.976023Z","shell.execute_reply.started":"2025-10-26T22:50:39.312714Z","shell.execute_reply":"2025-10-26T22:54:15.975110Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n[01] train_loss=1.227705 | val_MRR=0.0838 | R@1=0.035 R@5=0.113\n[02] train_loss=1.030644 | val_MRR=0.1229 | R@1=0.056 R@5=0.171\n[03] train_loss=1.001965 | val_MRR=0.1477 | R@1=0.069 R@5=0.211\n[04] train_loss=0.986564 | val_MRR=0.1646 | R@1=0.079 R@5=0.237\n[05] train_loss=0.976255 | val_MRR=0.1809 | R@1=0.090 R@5=0.261\n[06] train_loss=0.968573 | val_MRR=0.1918 | R@1=0.099 R@5=0.276\n[07] train_loss=0.962537 | val_MRR=0.2036 | R@1=0.107 R@5=0.295\n[08] train_loss=0.957577 | val_MRR=0.2120 | R@1=0.115 R@5=0.304\n[09] train_loss=0.953321 | val_MRR=0.2189 | R@1=0.120 R@5=0.313\n[10] train_loss=0.949557 | val_MRR=0.2258 | R@1=0.125 R@5=0.324\n[11] train_loss=0.946282 | val_MRR=0.2343 | R@1=0.133 R@5=0.335\n[12] train_loss=0.943318 | val_MRR=0.2376 | R@1=0.134 R@5=0.338\n[13] train_loss=0.940671 | val_MRR=0.2444 | R@1=0.141 R@5=0.347\n[14] train_loss=0.938257 | val_MRR=0.2475 | R@1=0.142 R@5=0.352\n[15] train_loss=0.936025 | val_MRR=0.2490 | R@1=0.144 R@5=0.351\n[16] train_loss=0.933938 | val_MRR=0.2548 | R@1=0.149 R@5=0.361\n[17] train_loss=0.931984 | val_MRR=0.2595 | R@1=0.153 R@5=0.364\n[18] train_loss=0.930230 | val_MRR=0.2613 | R@1=0.153 R@5=0.370\n[19] train_loss=0.928557 | val_MRR=0.2639 | R@1=0.157 R@5=0.373\n[20] train_loss=0.927021 | val_MRR=0.2644 | R@1=0.157 R@5=0.372\n[21] train_loss=0.925553 | val_MRR=0.2683 | R@1=0.160 R@5=0.377\n[22] train_loss=0.924201 | val_MRR=0.2701 | R@1=0.161 R@5=0.380\n[23] train_loss=0.922936 | val_MRR=0.2716 | R@1=0.162 R@5=0.386\n[24] train_loss=0.921727 | val_MRR=0.2747 | R@1=0.165 R@5=0.386\n[25] train_loss=0.920625 | val_MRR=0.2738 | R@1=0.165 R@5=0.386\n[26] train_loss=0.919546 | val_MRR=0.2750 | R@1=0.165 R@5=0.388\n[27] train_loss=0.918536 | val_MRR=0.2775 | R@1=0.167 R@5=0.390\n[28] train_loss=0.917578 | val_MRR=0.2783 | R@1=0.168 R@5=0.390\n[29] train_loss=0.916662 | val_MRR=0.2758 | R@1=0.165 R@5=0.391\n[30] train_loss=0.915806 | val_MRR=0.2778 | R@1=0.168 R@5=0.390\n[best] MRR=0.2783 @ epoch 28\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_lr2e4_moment01/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_lr2e4_moment01/submission.csv\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# python runner.py --out_dir mlp2_wd5e4_moment01 --arch mlp2 --wd 1e-5 --gamma 0.1 --align_loss moment\n\n# too much WD can hurt alignment; so we relax it\nif __name__==\"__main__\": \n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_wd5e4_moment01\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-5)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1)\n    p.add_argument(\"--beta\", type=float, default=1)\n    p.add_argument(\"--gamma\", type=float, default=0.1)\n    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T22:30:27.450538Z","iopub.execute_input":"2025-10-26T22:30:27.450875Z","iopub.status.idle":"2025-10-26T22:34:08.170362Z","shell.execute_reply.started":"2025-10-26T22:30:27.450848Z","shell.execute_reply":"2025-10-26T22:34:08.169323Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n[01] train_loss=1.358940 | val_MRR=0.0541 | R@1=0.019 R@5=0.072\n[02] train_loss=1.077363 | val_MRR=0.0915 | R@1=0.040 R@5=0.123\n[03] train_loss=1.037254 | val_MRR=0.1146 | R@1=0.052 R@5=0.158\n[04] train_loss=1.016725 | val_MRR=0.1294 | R@1=0.059 R@5=0.181\n[05] train_loss=1.003400 | val_MRR=0.1438 | R@1=0.067 R@5=0.204\n[06] train_loss=0.993644 | val_MRR=0.1539 | R@1=0.072 R@5=0.222\n[07] train_loss=0.986059 | val_MRR=0.1641 | R@1=0.079 R@5=0.238\n[08] train_loss=0.979914 | val_MRR=0.1723 | R@1=0.084 R@5=0.249\n[09] train_loss=0.974755 | val_MRR=0.1802 | R@1=0.089 R@5=0.262\n[10] train_loss=0.970305 | val_MRR=0.1876 | R@1=0.096 R@5=0.270\n[11] train_loss=0.966435 | val_MRR=0.1949 | R@1=0.102 R@5=0.281\n[12] train_loss=0.962991 | val_MRR=0.2001 | R@1=0.105 R@5=0.289\n[13] train_loss=0.959890 | val_MRR=0.2073 | R@1=0.110 R@5=0.299\n[14] train_loss=0.957038 | val_MRR=0.2125 | R@1=0.115 R@5=0.304\n[15] train_loss=0.954436 | val_MRR=0.2151 | R@1=0.116 R@5=0.308\n[16] train_loss=0.952024 | val_MRR=0.2208 | R@1=0.120 R@5=0.317\n[17] train_loss=0.949761 | val_MRR=0.2245 | R@1=0.124 R@5=0.320\n[18] train_loss=0.947707 | val_MRR=0.2287 | R@1=0.127 R@5=0.328\n[19] train_loss=0.945776 | val_MRR=0.2334 | R@1=0.131 R@5=0.333\n[20] train_loss=0.943962 | val_MRR=0.2357 | R@1=0.133 R@5=0.335\n[21] train_loss=0.942242 | val_MRR=0.2400 | R@1=0.137 R@5=0.342\n[22] train_loss=0.940637 | val_MRR=0.2429 | R@1=0.139 R@5=0.346\n[23] train_loss=0.939130 | val_MRR=0.2461 | R@1=0.142 R@5=0.351\n[24] train_loss=0.937686 | val_MRR=0.2493 | R@1=0.144 R@5=0.354\n[25] train_loss=0.936323 | val_MRR=0.2512 | R@1=0.146 R@5=0.357\n[26] train_loss=0.935009 | val_MRR=0.2541 | R@1=0.149 R@5=0.360\n[27] train_loss=0.933780 | val_MRR=0.2567 | R@1=0.151 R@5=0.364\n[28] train_loss=0.932612 | val_MRR=0.2587 | R@1=0.152 R@5=0.368\n[29] train_loss=0.931497 | val_MRR=0.2587 | R@1=0.152 R@5=0.367\n[30] train_loss=0.930464 | val_MRR=0.2595 | R@1=0.152 R@5=0.368\n[best] MRR=0.2595 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_wd5e4_moment01/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_wd5e4_moment01/submission.csv\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# python runner.py --out_dir mlp2_wd5e4_moment01 --arch mlp2 --wd 5e-4 --gamma 0.1 --align_loss moment\n\n# if overfitting, stronger WD may help.\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_wd5e4_moment01_vero\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=5e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1)\n    p.add_argument(\"--beta\", type=float, default=1)\n    p.add_argument(\"--gamma\", type=float, default=0.1)\n    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T22:36:43.321938Z","iopub.execute_input":"2025-10-26T22:36:43.322546Z","iopub.status.idle":"2025-10-26T22:40:21.226272Z","shell.execute_reply.started":"2025-10-26T22:36:43.322522Z","shell.execute_reply":"2025-10-26T22:40:21.225325Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n[01] train_loss=1.358938 | val_MRR=0.0541 | R@1=0.019 R@5=0.072\n[02] train_loss=1.077359 | val_MRR=0.0915 | R@1=0.040 R@5=0.123\n[03] train_loss=1.037249 | val_MRR=0.1146 | R@1=0.052 R@5=0.158\n[04] train_loss=1.016719 | val_MRR=0.1294 | R@1=0.059 R@5=0.181\n[05] train_loss=1.003395 | val_MRR=0.1438 | R@1=0.067 R@5=0.204\n[06] train_loss=0.993638 | val_MRR=0.1540 | R@1=0.072 R@5=0.221\n[07] train_loss=0.986053 | val_MRR=0.1641 | R@1=0.079 R@5=0.238\n[08] train_loss=0.979908 | val_MRR=0.1724 | R@1=0.084 R@5=0.248\n[09] train_loss=0.974748 | val_MRR=0.1801 | R@1=0.089 R@5=0.262\n[10] train_loss=0.970300 | val_MRR=0.1875 | R@1=0.095 R@5=0.270\n[11] train_loss=0.966431 | val_MRR=0.1949 | R@1=0.102 R@5=0.281\n[12] train_loss=0.962989 | val_MRR=0.2002 | R@1=0.105 R@5=0.290\n[13] train_loss=0.959889 | val_MRR=0.2071 | R@1=0.110 R@5=0.299\n[14] train_loss=0.957037 | val_MRR=0.2125 | R@1=0.115 R@5=0.304\n[15] train_loss=0.954434 | val_MRR=0.2151 | R@1=0.116 R@5=0.308\n[16] train_loss=0.952022 | val_MRR=0.2209 | R@1=0.120 R@5=0.316\n[17] train_loss=0.949761 | val_MRR=0.2244 | R@1=0.124 R@5=0.320\n[18] train_loss=0.947708 | val_MRR=0.2287 | R@1=0.127 R@5=0.328\n[19] train_loss=0.945777 | val_MRR=0.2335 | R@1=0.131 R@5=0.333\n[20] train_loss=0.943963 | val_MRR=0.2357 | R@1=0.133 R@5=0.335\n[21] train_loss=0.942241 | val_MRR=0.2399 | R@1=0.137 R@5=0.343\n[22] train_loss=0.940635 | val_MRR=0.2426 | R@1=0.138 R@5=0.346\n[23] train_loss=0.939129 | val_MRR=0.2462 | R@1=0.142 R@5=0.351\n[24] train_loss=0.937685 | val_MRR=0.2493 | R@1=0.144 R@5=0.354\n[25] train_loss=0.936323 | val_MRR=0.2507 | R@1=0.145 R@5=0.357\n[26] train_loss=0.935009 | val_MRR=0.2538 | R@1=0.148 R@5=0.360\n[27] train_loss=0.933781 | val_MRR=0.2566 | R@1=0.151 R@5=0.364\n[28] train_loss=0.932614 | val_MRR=0.2587 | R@1=0.152 R@5=0.368\n[29] train_loss=0.931500 | val_MRR=0.2589 | R@1=0.152 R@5=0.367\n[30] train_loss=0.930469 | val_MRR=0.2594 | R@1=0.152 R@5=0.368\n[best] MRR=0.2594 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_wd5e4_moment01_vero/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_wd5e4_moment01_vero/submission.csv\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# python runner.py --out_dir mlp2_bs256_moment01 --arch mlp2 --batch 256 --gamma 0.1 --align_loss moment\n\n# more gradient noise can improve generalization\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_bs256_moment01\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=256)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1)\n    p.add_argument(\"--beta\", type=float, default=1)\n    p.add_argument(\"--gamma\", type=float, default=0.1)\n    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T22:44:42.032735Z","iopub.execute_input":"2025-10-26T22:44:42.033397Z","iopub.status.idle":"2025-10-26T22:48:47.397731Z","shell.execute_reply.started":"2025-10-26T22:44:42.033369Z","shell.execute_reply":"2025-10-26T22:48:47.396862Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n[01] train_loss=1.161027 | val_MRR=0.0819 | R@1=0.033 R@5=0.109\n[02] train_loss=0.967359 | val_MRR=0.1204 | R@1=0.055 R@5=0.166\n[03] train_loss=0.937974 | val_MRR=0.1434 | R@1=0.067 R@5=0.205\n[04] train_loss=0.921858 | val_MRR=0.1607 | R@1=0.077 R@5=0.230\n[05] train_loss=0.910998 | val_MRR=0.1756 | R@1=0.086 R@5=0.255\n[06] train_loss=0.902919 | val_MRR=0.1878 | R@1=0.096 R@5=0.273\n[07] train_loss=0.896514 | val_MRR=0.2001 | R@1=0.105 R@5=0.289\n[08] train_loss=0.891194 | val_MRR=0.2069 | R@1=0.109 R@5=0.299\n[09] train_loss=0.886670 | val_MRR=0.2169 | R@1=0.118 R@5=0.311\n[10] train_loss=0.882740 | val_MRR=0.2237 | R@1=0.123 R@5=0.320\n[11] train_loss=0.879313 | val_MRR=0.2327 | R@1=0.131 R@5=0.332\n[12] train_loss=0.876230 | val_MRR=0.2368 | R@1=0.134 R@5=0.337\n[13] train_loss=0.873493 | val_MRR=0.2432 | R@1=0.139 R@5=0.344\n[14] train_loss=0.871009 | val_MRR=0.2470 | R@1=0.142 R@5=0.351\n[15] train_loss=0.868734 | val_MRR=0.2487 | R@1=0.144 R@5=0.352\n[16] train_loss=0.866720 | val_MRR=0.2537 | R@1=0.149 R@5=0.358\n[17] train_loss=0.864882 | val_MRR=0.2586 | R@1=0.152 R@5=0.366\n[18] train_loss=0.863204 | val_MRR=0.2601 | R@1=0.152 R@5=0.371\n[19] train_loss=0.861694 | val_MRR=0.2623 | R@1=0.155 R@5=0.372\n[20] train_loss=0.860295 | val_MRR=0.2629 | R@1=0.156 R@5=0.372\n[21] train_loss=0.859007 | val_MRR=0.2663 | R@1=0.158 R@5=0.375\n[22] train_loss=0.857782 | val_MRR=0.2691 | R@1=0.161 R@5=0.380\n[23] train_loss=0.856671 | val_MRR=0.2690 | R@1=0.160 R@5=0.383\n[24] train_loss=0.855621 | val_MRR=0.2722 | R@1=0.163 R@5=0.384\n[25] train_loss=0.854643 | val_MRR=0.2721 | R@1=0.163 R@5=0.383\n[26] train_loss=0.853680 | val_MRR=0.2738 | R@1=0.164 R@5=0.385\n[27] train_loss=0.852790 | val_MRR=0.2749 | R@1=0.165 R@5=0.388\n[28] train_loss=0.851961 | val_MRR=0.2760 | R@1=0.167 R@5=0.390\n[29] train_loss=0.851154 | val_MRR=0.2750 | R@1=0.164 R@5=0.389\n[30] train_loss=0.850379 | val_MRR=0.2753 | R@1=0.165 R@5=0.387\n[best] MRR=0.2760 @ epoch 28\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_bs256_moment01/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_bs256_moment01/submission.csv\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# python runner.py --out_dir mlp2_bs1024_moment01 --arch mlp2 --batch 1024 --gamma 0.1 --align_loss moment\n\n# more gradient noise can improve generalization\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_bs1024_moment01\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=1024)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1)\n    p.add_argument(\"--beta\", type=float, default=1)\n    p.add_argument(\"--gamma\", type=float, default=0.1)\n    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T23:04:08.851416Z","iopub.execute_input":"2025-10-26T23:04:08.852287Z","iopub.status.idle":"2025-10-26T23:07:47.661947Z","shell.execute_reply.started":"2025-10-26T23:04:08.852256Z","shell.execute_reply":"2025-10-26T23:07:47.660960Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n[01] train_loss=1.625906 | val_MRR=0.0281 | R@1=0.008 R@5=0.033\n[02] train_loss=1.212432 | val_MRR=0.0584 | R@1=0.022 R@5=0.077\n[03] train_loss=1.153054 | val_MRR=0.0812 | R@1=0.034 R@5=0.108\n[04] train_loss=1.123816 | val_MRR=0.0984 | R@1=0.044 R@5=0.135\n[05] train_loss=1.105431 | val_MRR=0.1119 | R@1=0.051 R@5=0.153\n[06] train_loss=1.092532 | val_MRR=0.1224 | R@1=0.056 R@5=0.168\n[07] train_loss=1.082776 | val_MRR=0.1311 | R@1=0.060 R@5=0.183\n[08] train_loss=1.075003 | val_MRR=0.1383 | R@1=0.064 R@5=0.196\n[09] train_loss=1.068588 | val_MRR=0.1455 | R@1=0.068 R@5=0.206\n[10] train_loss=1.063140 | val_MRR=0.1517 | R@1=0.071 R@5=0.216\n[11] train_loss=1.058438 | val_MRR=0.1585 | R@1=0.076 R@5=0.227\n[12] train_loss=1.054333 | val_MRR=0.1637 | R@1=0.079 R@5=0.235\n[13] train_loss=1.050660 | val_MRR=0.1691 | R@1=0.083 R@5=0.243\n[14] train_loss=1.047374 | val_MRR=0.1744 | R@1=0.087 R@5=0.251\n[15] train_loss=1.044392 | val_MRR=0.1784 | R@1=0.089 R@5=0.257\n[16] train_loss=1.041662 | val_MRR=0.1826 | R@1=0.091 R@5=0.264\n[17] train_loss=1.039139 | val_MRR=0.1877 | R@1=0.096 R@5=0.271\n[18] train_loss=1.036833 | val_MRR=0.1916 | R@1=0.099 R@5=0.277\n[19] train_loss=1.034664 | val_MRR=0.1940 | R@1=0.100 R@5=0.281\n[20] train_loss=1.032639 | val_MRR=0.1979 | R@1=0.103 R@5=0.286\n[21] train_loss=1.030742 | val_MRR=0.2016 | R@1=0.107 R@5=0.291\n[22] train_loss=1.028955 | val_MRR=0.2050 | R@1=0.109 R@5=0.295\n[23] train_loss=1.027276 | val_MRR=0.2085 | R@1=0.112 R@5=0.299\n[24] train_loss=1.025668 | val_MRR=0.2118 | R@1=0.114 R@5=0.305\n[25] train_loss=1.024103 | val_MRR=0.2132 | R@1=0.115 R@5=0.306\n[26] train_loss=1.022632 | val_MRR=0.2175 | R@1=0.118 R@5=0.310\n[27] train_loss=1.021212 | val_MRR=0.2201 | R@1=0.121 R@5=0.313\n[28] train_loss=1.019893 | val_MRR=0.2217 | R@1=0.121 R@5=0.318\n[29] train_loss=1.018586 | val_MRR=0.2248 | R@1=0.125 R@5=0.319\n[30] train_loss=1.017337 | val_MRR=0.2259 | R@1=0.125 R@5=0.323\n[best] MRR=0.2259 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_bs1024_moment01/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_bs1024_moment01/submission.csv\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# python runner.py --out_dir mlp2__infonce02 --arch mlp2 --gamma 0.2 --align_loss none\n\nif __name__==\"__main__\":\n    import argparse\n    p=argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_moment02_loss_none\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=30)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=1e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n    p.add_argument(\"--n_patches\", type=int, default=None)\n    p.add_argument(\"--alpha\", type=float, default=1)\n    p.add_argument(\"--beta\", type=float, default=1)\n    p.add_argument(\"--gamma\", type=float, default=0.2)\n    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n    p.add_argument(\"--train\", type=int, default=1)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    args, _ = p.parse_known_args()\n    main(**vars(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T23:08:39.869660Z","iopub.execute_input":"2025-10-26T23:08:39.870116Z","iopub.status.idle":"2025-10-26T23:12:17.213795Z","shell.execute_reply.started":"2025-10-26T23:08:39.870095Z","shell.execute_reply":"2025-10-26T23:12:17.212863Z"}},"outputs":[{"name":"stdout","text":"[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=none | α=1 β=1 γ=0.2\n[01] train_loss=1.899691 | val_MRR=0.0433 | R@1=0.015 R@5=0.056\n[02] train_loss=1.642304 | val_MRR=0.0746 | R@1=0.031 R@5=0.101\n[03] train_loss=1.605984 | val_MRR=0.0969 | R@1=0.042 R@5=0.133\n[04] train_loss=1.587693 | val_MRR=0.1122 | R@1=0.050 R@5=0.156\n[05] train_loss=1.575995 | val_MRR=0.1278 | R@1=0.060 R@5=0.181\n[06] train_loss=1.567547 | val_MRR=0.1381 | R@1=0.065 R@5=0.198\n[07] train_loss=1.561022 | val_MRR=0.1484 | R@1=0.071 R@5=0.212\n[08] train_loss=1.555711 | val_MRR=0.1556 | R@1=0.075 R@5=0.225\n[09] train_loss=1.551231 | val_MRR=0.1649 | R@1=0.080 R@5=0.239\n[10] train_loss=1.547342 | val_MRR=0.1725 | R@1=0.086 R@5=0.250\n[11] train_loss=1.543942 | val_MRR=0.1813 | R@1=0.094 R@5=0.260\n[12] train_loss=1.540911 | val_MRR=0.1858 | R@1=0.096 R@5=0.270\n[13] train_loss=1.538198 | val_MRR=0.1929 | R@1=0.101 R@5=0.280\n[14] train_loss=1.535719 | val_MRR=0.1980 | R@1=0.105 R@5=0.285\n[15] train_loss=1.533460 | val_MRR=0.2002 | R@1=0.106 R@5=0.289\n[16] train_loss=1.531355 | val_MRR=0.2065 | R@1=0.111 R@5=0.300\n[17] train_loss=1.529380 | val_MRR=0.2090 | R@1=0.112 R@5=0.303\n[18] train_loss=1.527562 | val_MRR=0.2143 | R@1=0.116 R@5=0.310\n[19] train_loss=1.525814 | val_MRR=0.2184 | R@1=0.120 R@5=0.315\n[20] train_loss=1.524167 | val_MRR=0.2233 | R@1=0.125 R@5=0.320\n[21] train_loss=1.522602 | val_MRR=0.2264 | R@1=0.127 R@5=0.323\n[22] train_loss=1.521141 | val_MRR=0.2292 | R@1=0.129 R@5=0.328\n[23] train_loss=1.519771 | val_MRR=0.2325 | R@1=0.131 R@5=0.332\n[24] train_loss=1.518447 | val_MRR=0.2361 | R@1=0.135 R@5=0.335\n[25] train_loss=1.517208 | val_MRR=0.2373 | R@1=0.136 R@5=0.338\n[26] train_loss=1.516011 | val_MRR=0.2419 | R@1=0.140 R@5=0.343\n[27] train_loss=1.514874 | val_MRR=0.2433 | R@1=0.140 R@5=0.346\n[28] train_loss=1.513811 | val_MRR=0.2464 | R@1=0.144 R@5=0.350\n[29] train_loss=1.512773 | val_MRR=0.2470 | R@1=0.144 R@5=0.349\n[30] train_loss=1.511804 | val_MRR=0.2478 | R@1=0.146 R@5=0.352\n[best] MRR=0.2478 @ epoch 30\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mlp1_moment02_loss_none/submission.csv\n[ok] submission written → /kaggle/working/outputs/mlp1_moment02_loss_none/submission.csv\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# runner.py\nimport argparse, json, random, re, time\nfrom pathlib import Path\nfrom os.path import basename\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# Uses your existing helpers (do not change)\nfrom challenge.src.common import load_data, generate_submission\n\n# ---------- Paths ----------\nDATA_ROOT = Path(\"/kaggle/working/data\")\nTRAIN_DIR = DATA_ROOT / \"train\" / \"train\"\nTEST_DIR  = DATA_ROOT / \"test\"  / \"test\"\nTRAIN_NPZ = TRAIN_DIR / \"train.npz\"\nTEST_NPZ  = TEST_DIR  / \"test.clean.npz\"\nTRAIN_CAPTIONS = TRAIN_DIR / \"captions.txt\"\nTEST_CAPTIONS  = TEST_DIR  / \"captions.txt\"\n\n# ---------- Determinism ----------\ndef seed_all(s: int):\n    random.seed(s); np.random.seed(s)\n    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n    torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n\n# ---------- Metadata/safety ----------\ndef _assert_metadata_dims(npz_path: Path, expect_text=1024, expect_img=1536):\n    d = np.load(npz_path, allow_pickle=True)\n    md = {k: d[k][0] for k in d.files if k.startswith(\"metadata/\")}\n    tdim = md.get(\"metadata/embedding_dim_text\", None)\n    idim = md.get(\"metadata/embedding_dim_image\", None)\n    print(f\"[meta] text_dim={tdim} | image_dim={idim}\")\n    assert tdim == expect_text and idim == expect_img, (\n        f\"Encoder dims mismatch: expected text={expect_text}, image={expect_img} \"\n        f\"but got text={tdim}, image={idim}. Regenerate NPZ with the fixed encoders.\"\n    )\n\n# ---------- Caption→image matching from captions.txt ----------\ndef _build_image_index(image_ids):\n    idx_exact = {}; idx_base={}; idx_stem={}\n    for i, v in enumerate(image_ids):\n        s = str(v); idx_exact[s]=i\n        b = basename(s); idx_base[b]=i\n        stem = b.rsplit(\".\",1)[0] if \".\" in b else b\n        idx_stem[stem]=i\n    return idx_exact, idx_base, idx_stem\n\ndef _iter_targets_from_captions(path: Path, n_text: int, idx_exact, idx_base, idx_stem):\n    targets=[]\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        for raw in f:\n            if len(targets)>=n_text: break\n            line=raw.strip()\n            if not line: continue\n            # be robust to delimiters\n            parts=re.split(r'\\||\\t|,| {2,}', line)\n            if len(parts)==1: parts=line.split(\" \",1)\n            tok=parts[0].strip().strip('\"').strip(\"'\")\n            if not tok: continue\n            def _match(tok_):\n                if tok_ in idx_exact: return idx_exact[tok_]\n                b=basename(tok_)\n                if b in idx_base: return idx_base[b]\n                stem=b.rsplit(\".\",1)[0] if \".\" in b else b\n                if stem in idx_stem: return idx_stem[stem]\n                return None\n            idx=_match(tok)\n            if idx is None:\n                tok2=tok.replace(\"Images/\",\"\").replace(\"./\",\"\")\n                idx=_match(tok2)\n            if idx is None:\n                if \".\" not in tok: continue\n                raise AssertionError(f\"Could not match image token '{tok}'\")\n            targets.append(idx)\n    assert len(targets)==n_text, f\"matched {len(targets)} vs N_text {n_text}\"\n    return np.asarray(targets, dtype=np.int64)\n\n# ---------- Data loaders ----------\ndef load_train(out_dir: Path):\n    _assert_metadata_dims(TRAIN_NPZ, 1024, 1536)\n    d=np.load(TRAIN_NPZ, allow_pickle=True)\n    X=d[\"captions/embeddings\"].astype(np.float32)  # (N_text,1024)\n    I=d[\"images/embeddings\"].astype(np.float32)    # (N_img,1536)\n    cap_ids=d.get(\"captions/ids\", np.arange(len(X)).astype(str))\n    img_names=d.get(\"images/names\", np.arange(len(I)).astype(str))\n\n    ex,ba,st=_build_image_index(img_names)\n    assert TRAIN_CAPTIONS.exists(), f\"Missing {TRAIN_CAPTIONS}\"\n    targets=_iter_targets_from_captions(TRAIN_CAPTIONS, len(X), ex,ba,st)\n\n    Y=I[targets]                       # (N_text, 1536) GT image vec per caption\n    img_ids_row = img_names[targets]   # image name per caption row (for splitting)\n    meta={\"n_text\":int(len(X)),\"n_images\":int(len(I))}\n    (out_dir/\"train_detect.json\").write_text(json.dumps(meta, indent=2))\n    return X,Y,cap_ids,img_ids_row,I,img_names\n\ndef load_test_npz():\n    d_test=np.load(TEST_NPZ, allow_pickle=True)\n    Q=d_test[\"captions/embeddings\"].astype(np.float32)\n    q_ids=d_test.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n    if \"images/embeddings\" in d_test.files:\n        G=d_test[\"images/embeddings\"].astype(np.float32)\n        g_ids=d_test.get(\"images/names\", np.arange(len(G)).astype(str))\n    else:\n        d_tr=np.load(TRAIN_NPZ, allow_pickle=True)\n        G=d_tr[\"images/embeddings\"].astype(np.float32)\n        g_ids=d_tr.get(\"images/names\", np.arange(len(G)).astype(str))\n    return Q,G,q_ids,g_ids\n\n# ---------- Dataset ----------\nclass PairDS(Dataset):\n    def __init__(self, X, Y): self.X=torch.from_numpy(X); self.Y=torch.from_numpy(Y)\n    def __len__(self): return self.X.shape[0]\n    def __getitem__(self, i): return self.X[i], self.Y[i]\n\n# ---------- Pooling (no-op per spec) ----------\ndef apply_pooling(x: torch.Tensor, mode: str, n_patches=None):\n    return x\n\n# ---------- Models ----------\nclass LinearProj(nn.Module):\n    def __init__(self, din, dout):\n        super().__init__()\n        self.fc=nn.Linear(din,dout)\n        nn.init.xavier_normal_(self.fc.weight); nn.init.zeros_(self.fc.bias)\n    def forward(self,x): return self.fc(x)\n\nclass MLP1(nn.Module):\n    def __init__(self, din, dout, hidden=512, pdrop=0.0):\n        super().__init__()\n        self.net=nn.Sequential(\n            nn.Linear(din,hidden), nn.ReLU(), nn.Dropout(pdrop),\n            nn.Linear(hidden,dout)\n        )\n        for m in self.net:\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n    def forward(self,x): return self.net(x)\n\nclass MLP2(nn.Module):\n    # Spec: 1024→1024→512→1536, dropout=0.1 on hidden layers\n    def __init__(self, din, dout, h1=1024, h2=512, pdrop=0.1):\n        super().__init__()\n        self.net=nn.Sequential(\n            nn.Linear(din,h1), nn.ReLU(), nn.Dropout(pdrop),\n            nn.Linear(h1,h2), nn.ReLU(), nn.Dropout(pdrop),\n            nn.Linear(h2,dout)\n        )\n        for m in self.net:\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n    def forward(self,x): return self.net(x)\n\ndef make_model(arch:str, din:int, dout:int):\n    a=arch.lower()\n    if a==\"linear\": return LinearProj(din,dout)\n    if a==\"mlp1\":   return MLP1(din,dout,hidden=512, pdrop=0.1)\n    if a==\"mlp2\":   return MLP2(din,dout,h1=1024,h2=512,pdrop=0.1)\n    if a==\"auto\":   return MLP2(din,dout)\n    raise ValueError(f\"Unknown arch {arch}\")\n\n# ---------- Loss pieces ----------\ndef moment_align(pred, tgt):\n    # Match batch mean & std channel-wise\n    mu_p, mu_t = pred.mean(0), tgt.mean(0)\n    sd_p, sd_t = pred.std(0, unbiased=False), tgt.std(0, unbiased=False)\n    return F.mse_loss(mu_p, mu_t) + F.mse_loss(sd_p, sd_t)\n\ndef info_nce(pred, tgt):\n    p = F.normalize(pred, dim=-1)\n    t = F.normalize(tgt, dim=-1)\n    logits = p @ t.t()                      # (B,B)\n    labels = torch.arange(pred.size(0), device=pred.device)\n    return F.cross_entropy(logits, labels)\n\n# ---------- Split by image id & mapping ----------\ndef build_image_id_split(img_ids_row, all_img_names, full_img, X, Y, val_ratio, seed, out_dir: Path):\n    uniq_img_names = np.array(sorted(set(map(str, all_img_names))))\n    rng = np.random.default_rng(seed); rng.shuffle(uniq_img_names)\n    n_val = max(1, int(len(uniq_img_names) * val_ratio))\n    val_images = set(uniq_img_names[:n_val])\n    tr_images  = set(uniq_img_names[n_val:])\n    assert len(val_images & tr_images) == 0, \"Leakage in image id split!\"\n\n    # Caption masks\n    cap_is_val = np.array([str(iid) in val_images for iid in img_ids_row], dtype=bool)\n    cap_is_tr  = ~cap_is_val\n\n    # Build VAL gallery (unique images in VAL) as sorted names → local indices\n    val_img_names_sorted = np.array(sorted(val_images))\n    name2local = {name:i for i,name in enumerate(val_img_names_sorted)}\n    name2global = {str(n):i for i,n in enumerate(all_img_names)}\n    val_img_indices = np.array([name2global[n] for n in val_img_names_sorted], dtype=np.int64)\n    val_gallery = full_img[val_img_indices]  # (M,1536)\n\n    # For each VAL caption row, get local gallery index (no remap later)\n    cap2gal_local = np.array([name2local[str(n)] for n in img_ids_row[cap_is_val]], dtype=np.int64)\n\n    # Persist mapping for debugging/acceptance\n    (out_dir/\"val_indices.json\").write_text(json.dumps({\n        \"val_img_indices\": val_img_indices.tolist(),\n        \"val_caption_to_gallery_index\": cap2gal_local.tolist(),\n        \"n_val_captions\": int(cap_is_val.sum()),\n        \"n_val_unique_images\": int(len(val_images))\n    }, indent=2))\n\n    return cap_is_tr, cap_is_val, val_gallery, cap2gal_local, val_img_indices\n\n# ---------- Metrics / evaluator (full gallery, cosine on L2) ----------\n@torch.no_grad()\ndef validate_retrieval(model, Xv, val_gallery, cap2gal_local, pooling, n_patches, bs=1024):\n    device=next(model.parameters()).device\n    Gi = torch.from_numpy(val_gallery).to(device)\n    Gi = F.normalize(Gi, dim=-1)\n\n    ranks=[]\n    for i in range(0, len(Xv), bs):\n        xb=torch.from_numpy(Xv[i:i+bs]).to(device)\n        xb=apply_pooling(xb, pooling, n_patches)   # no-op\n        pred=model(xb)\n        pred=F.normalize(pred, dim=-1)\n        sims=pred @ Gi.t()                         # (b, M)\n        for j in range(sims.size(0)):\n            true_idx = int(cap2gal_local[i+j])     # local gallery index\n            order = torch.argsort(sims[j], descending=True)\n            rank = (order==true_idx).nonzero(as_tuple=False).item() + 1\n            ranks.append(rank)\n\n    ranks = np.array(ranks)\n    mrr = float(np.mean(1.0 / ranks))\n    r1  = float(np.mean(ranks<=1))\n    r5  = float(np.mean(ranks<=5))\n    r10 = float(np.mean(ranks<=10))\n    return {\n        \"MRR\": mrr,\n        \"R1\": r1,\n        \"R5\": r5,\n        \"R10\": r10,\n        \"rank_median\": int(np.median(ranks)),\n        \"rank_p75\": int(np.percentile(ranks, 75))\n    }\n\ndef count_params_mb(model):\n    params=sum(p.numel() for p in model.parameters())\n    mb = params * 4 / (1024**2)\n    return params, mb\n\ndef time_ms_per_query(model, din, pooling, n_patches):\n    device=next(model.parameters()).device\n    x=torch.randn(2048, din, device=device)\n    x=apply_pooling(x, pooling, n_patches)\n    if device.type==\"cuda\":\n        torch.cuda.synchronize()\n    t0=time.time()\n    with torch.no_grad(): _=model(x)\n    if device.type==\"cuda\":\n        torch.cuda.synchronize()\n    ms_gpu=(time.time()-t0)*1000/len(x)\n\n    # CPU timing\n    mcpu = model.to(\"cpu\")\n    xcpu = x.to(\"cpu\")\n    t1=time.time()\n    with torch.no_grad(): _=mcpu(xcpu)\n    ms_cpu=(time.time()-t1)*1000/len(xcpu)\n    model.to(device)\n    return ms_gpu, ms_cpu\n\n# ---------- Train loop ----------\ndef train_one(model, loader, opt, alpha, beta, gamma, moment_w, pooling, n_patches, device):\n    model.train(); total=0.0\n    for xb,yb in loader:\n        xb,yb=xb.to(device), yb.to(device)\n        xb=apply_pooling(xb, pooling, n_patches)\n        opt.zero_grad(set_to_none=True)\n        pred=model(xb)\n\n        # loss = α·(1 − cos) + β·MSE + λ·moment_align + γ·InfoNCE\n        cos = 1 - F.cosine_similarity(pred, yb, dim=-1).mean()\n        mse = F.mse_loss(pred, yb)\n        a_loss = moment_w * moment_align(pred, yb) if moment_w>0 else pred.new_tensor(0.0)\n        ce = info_nce(pred, yb) if gamma>0 else pred.new_tensor(0.0)\n        loss = alpha*cos + beta*mse + gamma*ce + a_loss\n\n        loss.backward(); opt.step()\n        total += loss.item()*xb.size(0)\n    return total/len(loader.dataset)\n\n# ---------- Main ----------\ndef main(args):\n    # Parse flags\n    out_dir=args.out_dir; seed=args.seed; epochs=args.epochs; batch=args.batch\n    lr=args.lr; wd=args.wd\n    pooling=args.pooling; n_patches=None\n    alpha=args.alpha; beta=args.beta; gamma=args.gamma; moment_w=args.moment\n    arch=args.arch; do_train=not args.eval_only; val_ratio=args.val_ratio\n\n    seed_all(seed)\n    OUT = Path(f\"/kaggle/working/outputs/{out_dir}\"); OUT.mkdir(parents=True, exist_ok=True)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # --- load data\n    X,Y,cap_ids,img_ids_row,full_img,all_img_ids = load_train(OUT)\n\n    # --- split by image id & mappings\n    cap_is_tr, cap_is_val, val_gallery, cap2gal_local, val_img_indices = build_image_id_split(\n        img_ids_row, all_img_ids, full_img, X, Y, val_ratio, seed, OUT\n    )\n    # Safety: no leakage\n    val_set = set(all_img_ids[val_img_indices])\n    train_set = set(all_img_ids) - val_set\n    assert val_set.isdisjoint(train_set), \"Leakage detected between TRAIN and VAL image sets!\"\n\n    # Propagate masks to captions\n    Xtr,Ytr = X[cap_is_tr], Y[cap_is_tr]\n    Xva     = X[cap_is_val]\n\n    din, dout = X.shape[1], Y.shape[1]\n    # Dim safety\n    assert din==1024 and dout==1536, f\"Dimension mismatch: text={din}, image={dout} (expected 1024→1536)\"\n\n    # --- model\n    eff_arch = arch if arch!=\"auto\" else \"mlp2\"  # default per spec\n    model = make_model(eff_arch, din, dout).to(device)\n\n    # Output-dim safety\n    with torch.no_grad():\n        _probe = model(torch.zeros(2,din,device=device))\n    assert _probe.shape[-1]==1536, f\"Translator output dim { _probe.shape[-1] } != 1536\"\n\n    params, mb = count_params_mb(model)\n    print(f\"[model] {eff_arch} | params={params:,} (~{mb:.2f} MB) | pooling={pooling} | α={alpha} β={beta} λ_moment={moment_w} γ={gamma}\")\n\n    # --- train (best.pt chosen by MRR)\n    best_stats=None; best=-1.0; best_ep=0\n    if do_train:\n        dl = DataLoader(PairDS(Xtr,Ytr), batch_size=batch, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n        opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n        for ep in range(1, epochs+1):\n            tr = train_one(model, dl, opt, alpha,beta,gamma,moment_w, pooling, n_patches, device)\n            stats = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n            print(f\"[{ep:02d}] train_loss={tr:.6f} | val_MRR={stats['MRR']:.4f} \"\n                  f\"| R@1={stats['R1']:.3f} R@5={stats['R5']:.3f} R@10={stats['R10']:.3f} \"\n                  f\"| median={stats['rank_median']} p75={stats['rank_p75']}\")\n            if stats[\"MRR\"] > best:\n                best, best_ep, best_stats = stats[\"MRR\"], ep, stats\n                torch.save({\"model\":model.state_dict(),\"epoch\":ep,\"val\":stats}, OUT/\"best.pt\")\n        print(f\"[best] MRR={best:.4f} @ epoch {best_ep}\")\n        (OUT/\"val_metrics.json\").write_text(json.dumps(dict(best_epoch=best_ep, **best_stats), indent=2))\n    else:\n        ckpt = torch.load(OUT/\"best.pt\", map_location=\"cpu\")\n        print(f\"[resume] loaded epoch={ckpt.get('epoch','?')} MRR={ckpt.get('val',{}).get('MRR','?')}\")\n        model.load_state_dict(ckpt[\"model\"])\n        best_stats = ckpt.get(\"val\", None)\n\n    # --- efficiency logging\n    ms_gpu, ms_cpu = time_ms_per_query(model, din, pooling, n_patches)\n    eff = {\"params\":params,\"mb_fp32\":mb,\"ms_per_query_gpu\":ms_gpu,\"ms_per_query_cpu\":ms_cpu}\n    (OUT/\"efficiency.json\").write_text(json.dumps(eff, indent=2))\n\n    # --- submission (normalized only; test captions → L2 outputs)\n    test_data = load_data(TEST_NPZ)\n    Q   = test_data[\"captions/embeddings\"].astype(np.float32)\n    ids = test_data.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n    model.eval()\n    BS = 1024\n    outs = []\n    with torch.no_grad():\n        for i in range(0, len(Q), BS):\n            q = torch.from_numpy(Q[i:i+BS]).to(device)\n            q = apply_pooling(q, pooling, n_patches)\n            z = model(q)\n            z = F.normalize(z, dim=-1)\n            outs.append(z.detach().cpu().numpy())\n    pred_embds = np.concatenate(outs, axis=0)\n    sub = OUT / \"submission.csv\"\n    generate_submission(ids, pred_embds, str(sub))\n    print(f\"[ok] submission written → {sub}\")\n\n    # --- one-file sanity printout\n    sanity = {\n        \"dims\": {\"text\": int(din), \"image\": int(dout)},\n        \"split\": {\n            \"train_captions\": int(cap_is_tr.sum()),\n            \"val_captions\": int(cap_is_val.sum()),\n            \"val_unique_images\": int(val_gallery.shape[0]),\n            \"leakage\": False\n        },\n        \"val_metrics\": best_stats if best_stats is not None else validate_retrieval(\n            model, Xva, val_gallery, cap2gal_local, pooling, n_patches\n        ),\n        \"efficiency\": eff\n    }\n    print(json.dumps(sanity, indent=2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T00:42:57.049615Z","iopub.execute_input":"2025-10-27T00:42:57.049897Z","iopub.status.idle":"2025-10-27T00:42:57.097387Z","shell.execute_reply.started":"2025-10-27T00:42:57.049876Z","shell.execute_reply":"2025-10-27T00:42:57.096680Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# ---------- CLI ----------\nif __name__ == \"__main__\":\n    p = argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"mrr_first\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=20)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=2e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\")  # no-op (kept for compatibility)\n    p.add_argument(\"--alpha\", type=float, default=1.0)\n    p.add_argument(\"--beta\", type=float, default=1.0)\n    p.add_argument(\"--moment\", type=float, default=0.05)  # λ_moment\n    p.add_argument(\"--gamma\", type=float, default=0.0)    # InfoNCE (optional, default off)\n    p.add_argument(\"--arch\", type=str, default=\"mlp2\", choices=[\"linear\",\"mlp1\",\"mlp2\",\"auto\"])\n    p.add_argument(\"--eval_only\", action=\"store_true\", help=\"Skip training; eval+submission using best.pt\")\n    args, _ = p.parse_known_args()  # notebook-friendly\n    main(args)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T00:42:59.535961Z","iopub.execute_input":"2025-10-27T00:42:59.536505Z","iopub.status.idle":"2025-10-27T00:44:15.645694Z","shell.execute_reply.started":"2025-10-27T00:42:59.536478Z","shell.execute_reply":"2025-10-27T00:44:15.644699Z"}},"outputs":[{"name":"stdout","text":"[meta] text_dim=1024 | image_dim=1536\n[model] mlp2 | params=2,362,368 (~9.01 MB) | pooling=CLS | α=1.0 β=1.0 λ_moment=0.05 γ=0.0\n[01] train_loss=0.538621 | val_MRR=0.0418 | R@1=0.014 R@5=0.052 R@10=0.087 | median=197 p75=621\n[02] train_loss=0.386475 | val_MRR=0.0807 | R@1=0.031 R@5=0.108 R@10=0.172 | median=79 p75=296\n[03] train_loss=0.358601 | val_MRR=0.1049 | R@1=0.045 R@5=0.146 R@10=0.226 | median=55 p75=220\n[04] train_loss=0.344627 | val_MRR=0.1249 | R@1=0.055 R@5=0.180 R@10=0.268 | median=41 p75=176\n[05] train_loss=0.335342 | val_MRR=0.1379 | R@1=0.062 R@5=0.200 R@10=0.300 | median=35 p75=155\n[06] train_loss=0.328462 | val_MRR=0.1502 | R@1=0.071 R@5=0.218 R@10=0.315 | median=31 p75=140\n[07] train_loss=0.323083 | val_MRR=0.1579 | R@1=0.076 R@5=0.228 R@10=0.331 | median=28 p75=127\n[08] train_loss=0.318563 | val_MRR=0.1677 | R@1=0.083 R@5=0.245 R@10=0.346 | median=26 p75=121\n[09] train_loss=0.314723 | val_MRR=0.1741 | R@1=0.086 R@5=0.255 R@10=0.358 | median=24 p75=113\n[10] train_loss=0.311319 | val_MRR=0.1840 | R@1=0.096 R@5=0.266 R@10=0.374 | median=22 p75=106\n[11] train_loss=0.308116 | val_MRR=0.1864 | R@1=0.097 R@5=0.271 R@10=0.378 | median=22 p75=103\n[12] train_loss=0.305296 | val_MRR=0.1907 | R@1=0.100 R@5=0.276 R@10=0.386 | median=21 p75=98\n[13] train_loss=0.302683 | val_MRR=0.1987 | R@1=0.105 R@5=0.290 R@10=0.396 | median=19 p75=95\n[14] train_loss=0.300208 | val_MRR=0.1996 | R@1=0.106 R@5=0.286 R@10=0.398 | median=19 p75=95\n[15] train_loss=0.297967 | val_MRR=0.2026 | R@1=0.107 R@5=0.297 R@10=0.404 | median=19 p75=93\n[16] train_loss=0.295821 | val_MRR=0.2074 | R@1=0.113 R@5=0.298 R@10=0.404 | median=18 p75=89\n[17] train_loss=0.293783 | val_MRR=0.2099 | R@1=0.115 R@5=0.302 R@10=0.409 | median=18 p75=89\n[18] train_loss=0.291889 | val_MRR=0.2101 | R@1=0.115 R@5=0.303 R@10=0.411 | median=18 p75=88\n[19] train_loss=0.290072 | val_MRR=0.2138 | R@1=0.119 R@5=0.309 R@10=0.413 | median=18 p75=88\n[20] train_loss=0.288361 | val_MRR=0.2154 | R@1=0.118 R@5=0.312 R@10=0.417 | median=17 p75=85\n[best] MRR=0.2154 @ epoch 20\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/mrr_first/submission.csv\n[ok] submission written → /kaggle/working/outputs/mrr_first/submission.csv\n{\n  \"dims\": {\n    \"text\": 1024,\n    \"image\": 1536\n  },\n  \"split\": {\n    \"train_captions\": 112500,\n    \"val_captions\": 12500,\n    \"val_unique_images\": 2500,\n    \"leakage\": false\n  },\n  \"val_metrics\": {\n    \"MRR\": 0.21537820478549563,\n    \"R1\": 0.11768,\n    \"R5\": 0.3116,\n    \"R10\": 0.41688,\n    \"rank_median\": 17,\n    \"rank_p75\": 85\n  },\n  \"efficiency\": {\n    \"params\": 2362368,\n    \"mb_fp32\": 9.01171875,\n    \"ms_per_query_gpu\": 0.0009597279131412506,\n    \"ms_per_query_cpu\": 0.06314401980489492\n  }\n}\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"# runner.py\nimport argparse, json, random, re, time\nfrom pathlib import Path\nfrom os.path import basename\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# Uses your existing helpers (do not change)\nfrom challenge.src.common import load_data, generate_submission\n\n# ---------- Paths ----------\nDATA_ROOT = Path(\"/kaggle/working/data\")\nTRAIN_DIR = DATA_ROOT / \"train\" / \"train\"\nTEST_DIR  = DATA_ROOT / \"test\"  / \"test\"\nTRAIN_NPZ = TRAIN_DIR / \"train.npz\"\nTEST_NPZ  = TEST_DIR  / \"test.clean.npz\"\nTRAIN_CAPTIONS = TRAIN_DIR / \"captions.txt\"\nTEST_CAPTIONS  = TEST_DIR  / \"captions.txt\"\n\n# ---------- Determinism ----------\ndef seed_all(s: int):\n    random.seed(s); np.random.seed(s)\n    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n    torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n\n# ---------- Metadata/safety ----------\ndef _assert_metadata_dims(npz_path: Path, expect_text=1024, expect_img=1536):\n    d = np.load(npz_path, allow_pickle=True)\n    md = {k: d[k][0] for k in d.files if k.startswith(\"metadata/\")}\n    tdim = md.get(\"metadata/embedding_dim_text\", None)\n    idim = md.get(\"metadata/embedding_dim_image\", None)\n    print(f\"[meta] text_dim={tdim} | image_dim={idim}\")\n    assert tdim == expect_text and idim == expect_img, (\n        f\"Encoder dims mismatch: expected text={expect_text}, image={expect_img} \"\n        f\"but got text={tdim}, image={idim}. Regenerate NPZ with the fixed encoders.\"\n    )\n\n# ---------- Caption→image matching from captions.txt ----------\ndef _build_image_index(image_ids):\n    idx_exact = {}; idx_base={}; idx_stem={}\n    for i, v in enumerate(image_ids):\n        s = str(v); idx_exact[s]=i\n        b = basename(s); idx_base[b]=i\n        stem = b.rsplit(\".\",1)[0] if \".\" in b else b\n        idx_stem[stem]=i\n    return idx_exact, idx_base, idx_stem\n\ndef _iter_targets_from_captions(path: Path, n_text: int, idx_exact, idx_base, idx_stem):\n    targets=[]\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        for raw in f:\n            if len(targets)>=n_text: break\n            line=raw.strip()\n            if not line: continue\n            # be robust to delimiters\n            parts=re.split(r'\\||\\t|,| {2,}', line)\n            if len(parts)==1: parts=line.split(\" \",1)\n            tok=parts[0].strip().strip('\"').strip(\"'\")\n            if not tok: continue\n            def _match(tok_):\n                if tok_ in idx_exact: return idx_exact[tok_]\n                b=basename(tok_)\n                if b in idx_base: return idx_base[b]\n                stem=b.rsplit(\".\",1)[0] if \".\" in b else b\n                if stem in idx_stem: return idx_stem[stem]\n                return None\n            idx=_match(tok)\n            if idx is None:\n                tok2=tok.replace(\"Images/\",\"\").replace(\"./\",\"\")\n                idx=_match(tok2)\n            if idx is None:\n                if \".\" not in tok: continue\n                raise AssertionError(f\"Could not match image token '{tok}'\")\n            targets.append(idx)\n    assert len(targets)==n_text, f\"matched {len(targets)} vs N_text {n_text}\"\n    return np.asarray(targets, dtype=np.int64)\n\n# ---------- Data loaders ----------\ndef load_train(out_dir: Path):\n    _assert_metadata_dims(TRAIN_NPZ, 1024, 1536)\n    d=np.load(TRAIN_NPZ, allow_pickle=True)\n    X=d[\"captions/embeddings\"].astype(np.float32)  # (N_text,1024)\n    I=d[\"images/embeddings\"].astype(np.float32)    # (N_img,1536)\n    cap_ids=d.get(\"captions/ids\", np.arange(len(X)).astype(str))\n    img_names=d.get(\"images/names\", np.arange(len(I)).astype(str))\n\n    ex,ba,st=_build_image_index(img_names)\n    assert TRAIN_CAPTIONS.exists(), f\"Missing {TRAIN_CAPTIONS}\"\n    targets=_iter_targets_from_captions(TRAIN_CAPTIONS, len(X), ex,ba,st)\n\n    Y=I[targets]                       # (N_text, 1536) GT image vec per caption\n    img_ids_row = img_names[targets]   # image name per caption row (for splitting)\n    meta={\"n_text\":int(len(X)),\"n_images\":int(len(I))}\n    (out_dir/\"train_detect.json\").write_text(json.dumps(meta, indent=2))\n    return X,Y,cap_ids,img_ids_row,I,img_names\n\ndef load_test_npz():\n    d_test=np.load(TEST_NPZ, allow_pickle=True)\n    Q=d_test[\"captions/embeddings\"].astype(np.float32)\n    q_ids=d_test.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n    if \"images/embeddings\" in d_test.files:\n        G=d_test[\"images/embeddings\"].astype(np.float32)\n        g_ids=d_test.get(\"images/names\", np.arange(len(G)).astype(str))\n    else:\n        d_tr=np.load(TRAIN_NPZ, allow_pickle=True)\n        G=d_tr[\"images/embeddings\"].astype(np.float32)\n        g_ids=d_tr.get(\"images/names\", np.arange(len(G)).astype(str))\n    return Q,G,q_ids,g_ids\n\n# ---------- Dataset ----------\nclass PairDS(Dataset):\n    def __init__(self, X, Y): self.X=torch.from_numpy(X); self.Y=torch.from_numpy(Y)\n    def __len__(self): return self.X.shape[0]\n    def __getitem__(self, i): return self.X[i], self.Y[i]\n\n# ---------- Pooling (no-op per spec) ----------\ndef apply_pooling(x: torch.Tensor, mode: str, n_patches=None):\n    return x\n\n# ---------- Base Models ----------\nclass LinearProj(nn.Module):\n    def __init__(self, din, dout):\n        super().__init__()\n        self.fc=nn.Linear(din,dout)\n        nn.init.xavier_normal_(self.fc.weight); nn.init.zeros_(self.fc.bias)\n    def forward(self,x): return self.fc(x)\n\nclass MLP1(nn.Module):\n    def __init__(self, din, dout, hidden=512, pdrop=0.1):\n        super().__init__()\n        self.net=nn.Sequential(\n            nn.Linear(din,hidden), nn.ReLU(), nn.Dropout(pdrop),\n            nn.Linear(hidden,dout)\n        )\n        for m in self.net:\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n    def forward(self,x): return self.net(x)\n\nclass MLP2(nn.Module):\n    # Spec: 1024→1024→512→1536, dropout=0.1 on hidden layers\n    def __init__(self, din, dout, h1=1024, h2=512, pdrop=0.1):\n        super().__init__()\n        self.net=nn.Sequential(\n            nn.Linear(din,h1), nn.ReLU(), nn.Dropout(pdrop),\n            nn.Linear(h1,h2), nn.ReLU(), nn.Dropout(pdrop),\n            nn.Linear(h2,dout)\n        )\n        for m in self.net:\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n    def forward(self,x): return self.net(x)\n\n# ---------- Geometry-Preserving Linear (Whiten → Procrustes → Re-color) ----------\ndef _cov_eigh(zc, eps):\n    # zc: (N,D), zero-mean\n    N = zc.shape[0]\n    C = (zc.T @ zc) / max(1, N)\n    # symmetric PSD\n    S, U = np.linalg.eigh(C)\n    S = np.clip(S, 0.0, None)\n    inv_sqrt = 1.0 / np.sqrt(S + eps)\n    sqrt = np.sqrt(S + eps)\n    C_mhalf = (U * inv_sqrt) @ U.T     # C^{-1/2}\n    C_phalf = (U * sqrt) @ U.T         # C^{ 1/2}\n    return C_mhalf.astype(np.float32), C_phalf.astype(np.float32)\n\ndef procrustes_closed_form(X, Y, eps=1e-5):\n    \"\"\"\n    X: (N, 1024) text, Y: (N, 1536) targets (per-caption image vectors)\n    Returns A (1536x1024), b (1536,) such that y_hat = A x + b\n    \"\"\"\n    # center\n    mu_x = X.mean(0, dtype=np.float64)\n    mu_y = Y.mean(0, dtype=np.float64)\n    Xc = X - mu_x\n    Yc = Y - mu_y\n\n    # whiten both\n    Cx_mh, _ = _cov_eigh(Xc, eps)      # 1024x1024\n    Cy_mh, Cy_ph = _cov_eigh(Yc, eps)  # 1536x1536 (only Cy_ph used)\n    Xw = Xc @ Cx_mh.T                  # (N,1024)\n    Yw = Yc @ Cy_mh.T                  # (N,1536)\n\n    # orthogonal Procrustes: maximize Tr(R^T Xw^T Yw)\n    M = Xw.T @ Yw                      # (1024,1536)\n    # SVD on M; for rectangular, do SVD and build R = U V^T in common subspace\n    U, _, Vt = np.linalg.svd(M, full_matrices=False)\n    R = U @ Vt                         # (1024,1536) @ (1536,1536) -> (1024,1536) OK since full_matrices=False\n    # we need R as (1536x1024) mapping whitened X to whitened Y; above is (1024x1536)\n    R = R.T                            # (1536,1024)\n\n    # re-color to Y space\n    A = (Cy_ph @ R @ Cx_mh).astype(np.float32)     # (1536,1536)*(1536,1024)*(1024,1024) = (1536,1024)\n    b = (mu_y - (A @ mu_x)).astype(np.float32)     # (1536,)\n    return A, b\n\nclass GeomLinear(nn.Module):\n    \"\"\"\n    Linear layer with weights initialized from closed-form geometry mapping.\n    Optionally fine-tunes with tiny LR.\n    \"\"\"\n    def __init__(self, A: np.ndarray, b: np.ndarray):\n        super().__init__()\n        D_in = A.shape[1]; D_out = A.shape[0]\n        self.fc = nn.Linear(D_in, D_out, bias=True)\n        with torch.no_grad():\n            self.fc.weight.copy_(torch.from_numpy(A))\n            self.fc.bias.copy_(torch.from_numpy(b))\n    def forward(self, x):\n        return self.fc(x)\n\n# ---------- Loss pieces (for optional fine-tune) ----------\ndef moment_align(pred, tgt):\n    mu_p, mu_t = pred.mean(0), tgt.mean(0)\n    sd_p, sd_t = pred.std(0, unbiased=False), tgt.std(0, unbiased=False)\n    return F.mse_loss(mu_p, mu_t) + F.mse_loss(sd_p, sd_t)\n\ndef info_nce(pred, tgt):\n    p = F.normalize(pred, dim=-1)\n    t = F.normalize(tgt, dim=-1)\n    logits = p @ t.t()\n    labels = torch.arange(pred.size(0), device=pred.device)\n    return F.cross_entropy(logits, labels)\n\n# ---------- Split by image id & mapping ----------\ndef build_image_id_split(img_ids_row, all_img_names, full_img, X, Y, val_ratio, seed, out_dir: Path):\n    uniq_img_names = np.array(sorted(set(map(str, all_img_names))))\n    rng = np.random.default_rng(seed); rng.shuffle(uniq_img_names)\n    n_val = max(1, int(len(uniq_img_names) * val_ratio))\n    val_images = set(uniq_img_names[:n_val])\n    tr_images  = set(uniq_img_names[n_val:])\n    assert len(val_images & tr_images) == 0, \"Leakage in image id split!\"\n\n    # Caption masks\n    cap_is_val = np.array([str(iid) in val_images for iid in img_ids_row], dtype=bool)\n    cap_is_tr  = ~cap_is_val\n\n    # Build VAL gallery (unique images in VAL) as sorted names → local indices\n    val_img_names_sorted = np.array(sorted(val_images))\n    name2local = {name:i for i,name in enumerate(val_img_names_sorted)}\n    name2global = {str(n):i for i,n in enumerate(all_img_names)}\n    val_img_indices = np.array([name2global[n] for n in val_img_names_sorted], dtype=np.int64)\n    val_gallery = full_img[val_img_indices]  # (M,1536)\n\n    # For each VAL caption row, get local gallery index (no remap later)\n    cap2gal_local = np.array([name2local[str(n)] for n in img_ids_row[cap_is_val]], dtype=np.int64)\n\n    # Persist mapping for debugging/acceptance\n    (out_dir/\"val_indices.json\").write_text(json.dumps({\n        \"val_img_indices\": val_img_indices.tolist(),\n        \"val_caption_to_gallery_index\": cap2gal_local.tolist(),\n        \"n_val_captions\": int(cap_is_val.sum()),\n        \"n_val_unique_images\": int(len(val_images))\n    }, indent=2))\n\n    return cap_is_tr, cap_is_val, val_gallery, cap2gal_local, val_img_indices\n\n# ---------- Metrics / evaluator (full gallery, cosine on L2) ----------\n@torch.no_grad()\ndef validate_retrieval(model, Xv, val_gallery, cap2gal_local, pooling, n_patches, bs=1024):\n    device=next(model.parameters()).device\n    Gi = torch.from_numpy(val_gallery).to(device)\n    Gi = F.normalize(Gi, dim=-1)\n\n    ranks=[]\n    for i in range(0, len(Xv), bs):\n        xb=torch.from_numpy(Xv[i:i+bs]).to(device)\n        xb=apply_pooling(xb, pooling, n_patches)   # no-op\n        pred=model(xb)\n        pred=F.normalize(pred, dim=-1)\n        sims=pred @ Gi.t()                         # (b, M)\n        for j in range(sims.size(0)):\n            true_idx = int(cap2gal_local[i+j])     # local gallery index\n            order = torch.argsort(sims[j], descending=True)\n            rank = (order==true_idx).nonzero(as_tuple=False).item() + 1\n            ranks.append(rank)\n\n    ranks = np.array(ranks)\n    mrr = float(np.mean(1.0 / ranks))\n    r1  = float(np.mean(ranks<=1))\n    r5  = float(np.mean(ranks<=5))\n    r10 = float(np.mean(ranks<=10))\n    return {\n        \"MRR\": mrr,\n        \"R1\": r1,\n        \"R5\": r5,\n        \"R10\": r10,\n        \"rank_median\": int(np.median(ranks)),\n        \"rank_p75\": int(np.percentile(ranks, 75))\n    }\n\ndef count_params_mb(model):\n    params=sum(p.numel() for p in model.parameters())\n    mb = params * 4 / (1024**2)\n    return params, mb\n\ndef time_ms_per_query(model, din, pooling, n_patches):\n    device=next(model.parameters()).device\n    x=torch.randn(2048, din, device=device)\n    x=apply_pooling(x, pooling, n_patches)\n    if device.type==\"cuda\":\n        torch.cuda.synchronize()\n    t0=time.time()\n    with torch.no_grad(): _=model(x)\n    if device.type==\"cuda\":\n        torch.cuda.synchronize()\n    ms_gpu=(time.time()-t0)*1000/len(x)\n    # CPU\n    mcpu=model.to(\"cpu\"); xcpu=x.to(\"cpu\")\n    t1=time.time()\n    with torch.no_grad(): _=mcpu(xcpu)\n    ms_cpu=(time.time()-t1)*1000/len(xcpu)\n    model.to(device)\n    return ms_gpu, ms_cpu\n\n# ---------- Train (for optional fine-tune) ----------\ndef train_one(model, loader, opt, alpha, beta, gamma, moment_w, pooling, n_patches, device):\n    model.train(); total=0.0\n    for xb,yb in loader:\n        xb,yb=xb.to(device), yb.to(device)\n        xb=apply_pooling(xb, pooling, n_patches)\n        opt.zero_grad(set_to_none=True)\n        pred=model(xb)\n        # α·(1−cos) + β·MSE + λ·moment_align + γ·InfoNCE\n        cos = 1 - F.cosine_similarity(pred, yb, dim=-1).mean()\n        mse = F.mse_loss(pred, yb)\n        a_loss = moment_w * moment_align(pred, yb) if moment_w>0 else pred.new_tensor(0.0)\n        ce = info_nce(pred, yb) if gamma>0 else pred.new_tensor(0.0)\n        loss = alpha*cos + beta*mse + gamma*ce + a_loss\n        loss.backward(); opt.step()\n        total += loss.item()*xb.size(0)\n    return total/len(loader.dataset)\n\n# ---------- Factory ----------\ndef make_model(arch:str, din:int, dout:int, geom_init_data=None):\n    a=arch.lower()\n    if a==\"linear\": return LinearProj(din,dout)\n    if a==\"mlp1\":   return MLP1(din,dout,hidden=512, pdrop=0.1)\n    if a==\"mlp2\":   return MLP2(din,dout,h1=1024,h2=512,pdrop=0.1)\n    if a==\"geom\":\n        assert geom_init_data is not None, \"geom requires (Xtr, Ytr, eps)\"\n        Xtr_np, Ytr_np, eps = geom_init_data\n        A,b = procrustes_closed_form(Xtr_np, Ytr_np, eps=eps)\n        return GeomLinear(A, b)\n    if a==\"auto\":   return MLP2(din,dout)\n    raise ValueError(f\"Unknown arch {arch}\")\n\n# ---------- Main ----------\ndef main(args):\n    # Parse flags\n    out_dir=args.out_dir; seed=args.seed; epochs=args.epochs; batch=args.batch\n    lr=args.lr; wd=args.wd\n    pooling=args.pooling; n_patches=None\n    alpha=args.alpha; beta=args.beta; gamma=args.gamma; moment_w=args.moment\n    arch=args.arch; do_train=not args.eval_only; val_ratio=args.val_ratio\n    geom_eps=args.geom_eps; geom_ft_epochs=args.geom_finetune_epochs; geom_ft_lr=args.geom_finetune_lr; geom_ft_wd=args.geom_finetune_wd\n\n    seed_all(seed)\n    OUT = Path(f\"/kaggle/working/outputs/{out_dir}\"); OUT.mkdir(parents=True, exist_ok=True)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # --- load data\n    X,Y,cap_ids,img_ids_row,full_img,all_img_ids = load_train(OUT)\n\n    # --- split by image id & mappings\n    cap_is_tr, cap_is_val, val_gallery, cap2gal_local, val_img_indices = build_image_id_split(\n        img_ids_row, all_img_ids, full_img, X, Y, val_ratio, seed, OUT\n    )\n    # Safety: no leakage\n    val_set = set(all_img_ids[val_img_indices])\n    train_set = set(all_img_ids) - val_set\n    assert val_set.isdisjoint(train_set), \"Leakage detected between TRAIN and VAL image sets!\"\n\n    # Propagate masks to captions\n    Xtr,Ytr = X[cap_is_tr], Y[cap_is_tr]\n    Xva     = X[cap_is_val]\n\n    din, dout = X.shape[1], Y.shape[1]\n    # Dim safety\n    assert din==1024 and dout==1536, f\"Dimension mismatch: text={din}, image={dout} (expected 1024→1536)\"\n\n    # --- model (geom has closed-form init)\n    geom_init = None\n    if arch.lower()==\"geom\":\n        geom_init = (Xtr.astype(np.float32), Ytr.astype(np.float32), float(geom_eps))\n    model = make_model(arch, din, dout, geom_init).to(device)\n\n    # Output-dim safety\n    with torch.no_grad():\n        _probe = model(torch.zeros(2,din,device=device))\n    assert _probe.shape[-1]==1536, f\"Translator output dim { _probe.shape[-1] } != 1536\"\n\n    params, mb = count_params_mb(model)\n    print(f\"[model] {arch} | params={params:,} (~{mb:.2f} MB) | pooling={pooling} | α={alpha} β={beta} λ_moment={moment_w} γ={gamma}\")\n\n    # --- training strategy\n    best_stats=None; best=-1.0; best_ep=0\n\n    if arch.lower()==\"geom\" and geom_ft_epochs>0 and do_train:\n        # tiny fine-tune on linear head\n        dl = DataLoader(PairDS(Xtr,Ytr), batch_size=batch, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n        opt = torch.optim.AdamW(model.parameters(), lr=geom_ft_lr, weight_decay=geom_ft_wd)\n        for ep in range(1, geom_ft_epochs+1):\n            tr = train_one(model, dl, opt, alpha,beta,gamma,moment_w, pooling, n_patches, device)\n            stats = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n            print(f\"[geom-ft {ep:02d}] train_loss={tr:.6f} | val_MRR={stats['MRR']:.4f} \"\n                  f\"| R@1={stats['R1']:.3f} R@5={stats['R5']:.3f} R@10={stats['R10']:.3f} \"\n                  f\"| median={stats['rank_median']} p75={stats['rank_p75']}\")\n            if stats[\"MRR\"] > best:\n                best, best_ep, best_stats = stats[\"MRR\"], ep, stats\n                torch.save({\"model\":model.state_dict(),\"epoch\":ep,\"val\":stats}, OUT/\"best.pt\")\n        if best_stats is None:\n            best_stats = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n            torch.save({\"model\":model.state_dict(),\"epoch\":0,\"val\":best_stats}, OUT/\"best.pt\")\n        (OUT/\"val_metrics.json\").write_text(json.dumps(dict(best_epoch=best_ep, **best_stats), indent=2))\n\n    elif do_train and arch.lower()!=\"geom\":\n        # normal training for linear/mlp1/mlp2\n        dl = DataLoader(PairDS(Xtr,Ytr), batch_size=batch, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n        opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n        for ep in range(1, epochs+1):\n            tr = train_one(model, dl, opt, alpha,beta,gamma,moment_w, pooling, n_patches, device)\n            stats = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n            print(f\"[{ep:02d}] train_loss={tr:.6f} | val_MRR={stats['MRR']:.4f} \"\n                  f\"| R@1={stats['R1']:.3f} R@5={stats['R5']:.3f} R@10={stats['R10']:.3f} \"\n                  f\"| median={stats['rank_median']} p75={stats['rank_p75']}\")\n            if stats[\"MRR\"] > best:\n                best, best_ep, best_stats = stats[\"MRR\"], ep, stats\n                torch.save({\"model\":model.state_dict(),\"epoch\":ep,\"val\":stats}, OUT/\"best.pt\")\n        if best_stats is None:\n            best_stats = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n            torch.save({\"model\":model.state_dict(),\"epoch\":0,\"val\":best_stats}, OUT/\"best.pt\")\n        (OUT/\"val_metrics.json\").write_text(json.dumps(dict(best_epoch=best_ep, **best_stats), indent=2))\n    else:\n        # eval-only: load best.pt if present, else just evaluate the freshly-built model\n        try:\n            ckpt = torch.load(OUT/\"best.pt\", map_location=\"cpu\")\n            print(f\"[resume] loaded epoch={ckpt.get('epoch','?')} MRR={ckpt.get('val',{}).get('MRR','?')}\")\n            model.load_state_dict(ckpt[\"model\"])\n            best_stats = ckpt.get(\"val\", None)\n        except FileNotFoundError:\n            best_stats = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n\n    # --- efficiency logging\n    ms_gpu, ms_cpu = time_ms_per_query(model, din, pooling, n_patches)\n    eff = {\"params\":params,\"mb_fp32\":mb,\"ms_per_query_gpu\":ms_gpu,\"ms_per_query_cpu\":ms_cpu}\n    (OUT/\"efficiency.json\").write_text(json.dumps(eff, indent=2))\n\n    # --- submission (normalized only; test captions → L2 outputs)\n    test_data = load_data(TEST_NPZ)\n    Q   = test_data[\"captions/embeddings\"].astype(np.float32)\n    ids = test_data.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n    model.eval()\n    BS = 1024\n    outs = []\n    with torch.no_grad():\n        for i in range(0, len(Q), BS):\n            q = torch.from_numpy(Q[i:i+BS]).to(device)\n            q = apply_pooling(q, pooling, n_patches)\n            z = model(q)\n            z = F.normalize(z, dim=-1)\n            outs.append(z.detach().cpu().numpy())\n    pred_embds = np.concatenate(outs, axis=0)\n    sub = OUT / \"submission.csv\"\n    generate_submission(ids, pred_embds, str(sub))\n    print(f\"[ok] submission written → {sub}\")\n\n    # --- one-file sanity printout\n    sanity = {\n        \"dims\": {\"text\": int(din), \"image\": int(dout)},\n        \"split\": {\n            \"train_captions\": int(cap_is_tr.sum()),\n            \"val_captions\": int(cap_is_val.sum()),\n            \"val_unique_images\": int(val_gallery.shape[0]),\n            \"leakage\": False\n        },\n        \"val_metrics\": best_stats if best_stats is not None else validate_retrieval(\n            model, Xva, val_gallery, cap2gal_local, pooling, n_patches\n        ),\n        \"efficiency\": eff\n    }\n    print(json.dumps(sanity, indent=2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T00:52:15.526128Z","iopub.execute_input":"2025-10-27T00:52:15.526485Z","iopub.status.idle":"2025-10-27T00:52:15.585698Z","shell.execute_reply.started":"2025-10-27T00:52:15.526453Z","shell.execute_reply":"2025-10-27T00:52:15.585028Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# ---------- CLI ----------\nif __name__ == \"__main__\":\n    p = argparse.ArgumentParser()\n    p.add_argument(\"--out_dir\", type=str, default=\"geom_mrr_first\")\n    p.add_argument(\"--seed\", type=int, default=42)\n    p.add_argument(\"--epochs\", type=int, default=20)\n    p.add_argument(\"--batch\", type=int, default=512)\n    p.add_argument(\"--lr\", type=float, default=2e-4)\n    p.add_argument(\"--wd\", type=float, default=1e-4)\n    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n    p.add_argument(\"--pooling\", type=str, default=\"CLS\")  # no-op (kept for compatibility)\n    p.add_argument(\"--alpha\", type=float, default=1.0)\n    p.add_argument(\"--beta\", type=float, default=1.0)\n    p.add_argument(\"--moment\", type=float, default=0.05)  # λ_moment\n    p.add_argument(\"--gamma\", type=float, default=0.0)    # InfoNCE (optional, default off)\n    p.add_argument(\"--arch\", type=str, default=\"geom\", choices=[\"geom\",\"linear\",\"mlp1\",\"mlp2\",\"auto\"])\n    # Geometry step knobs\n    p.add_argument(\"--geom_eps\", type=float, default=1e-5, help=\"Covariance epsilon for whitening\")\n    p.add_argument(\"--geom_finetune_epochs\", type=int, default=0, help=\"Tiny linear fine-tune epochs (0 = off)\")\n    p.add_argument(\"--geom_finetune_lr\", type=float, default=1e-4)\n    p.add_argument(\"--geom_finetune_wd\", type=float, default=1e-5)\n    p.add_argument(\"--eval_only\", action=\"store_true\", help=\"Skip training; eval+submission using best.pt or closed-form\")\n    args, _ = p.parse_known_args()  # notebook-friendly\n    main(args)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T01:01:23.404379Z","iopub.execute_input":"2025-10-27T01:01:23.405147Z","iopub.status.idle":"2025-10-27T01:02:01.581417Z","shell.execute_reply.started":"2025-10-27T01:01:23.405119Z","shell.execute_reply":"2025-10-27T01:02:01.580616Z"}},"outputs":[{"name":"stdout","text":"[meta] text_dim=1024 | image_dim=1536\n[model] geom | params=1,574,400 (~6.01 MB) | pooling=CLS | α=1.0 β=1.0 λ_moment=0.05 γ=0.0\nGenerating submission file...\n✓ Saved submission to /kaggle/working/outputs/geom_mrr_first/submission.csv\n[ok] submission written → /kaggle/working/outputs/geom_mrr_first/submission.csv\n{\n  \"dims\": {\n    \"text\": 1024,\n    \"image\": 1536\n  },\n  \"split\": {\n    \"train_captions\": 112500,\n    \"val_captions\": 12500,\n    \"val_unique_images\": 2500,\n    \"leakage\": false\n  },\n  \"val_metrics\": {\n    \"MRR\": 0.3191292292010856,\n    \"R1\": 0.20912,\n    \"R5\": 0.4364,\n    \"R10\": 0.54536,\n    \"rank_median\": 8,\n    \"rank_p75\": 40\n  },\n  \"efficiency\": {\n    \"params\": 1574400,\n    \"mb_fp32\": 6.005859375,\n    \"ms_per_query_gpu\": 0.00049639493227005,\n    \"ms_per_query_cpu\": 0.02339109778404236\n  }\n}\n","output_type":"stream"}],"execution_count":72}]}