{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:42:58.867685Z",
     "iopub.status.busy": "2025-10-26T20:42:58.866928Z",
     "iopub.status.idle": "2025-10-26T20:42:59.050861Z",
     "shell.execute_reply": "2025-10-26T20:42:59.049839Z",
     "shell.execute_reply.started": "2025-10-26T20:42:58.867655Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Credentials written to: /root/.kaggle/kaggle.json\n",
      "total 16\n",
      "drwxr-xr-x 2 root root 4096 Oct 26 19:54 .\n",
      "drwx------ 1 root root 4096 Oct 26 20:01 ..\n",
      "-rw------- 1 root root   72 Oct 26 20:42 kaggle.json\n"
     ]
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "import json, os, pathlib, subprocess, sys\n",
    "\n",
    "# --- 1. Load your secret (full JSON from kaggle.json) ---\n",
    "secret_name = \"kaggle_json\"  # change if you used another name\n",
    "user_secrets = UserSecretsClient()\n",
    "raw = user_secrets.get_secret(secret_name)\n",
    "creds = json.loads(raw)\n",
    "\n",
    "# --- 2. Forcefully recreate ~/.kaggle/kaggle.json ---\n",
    "kaggle_dir = pathlib.Path.home() / \".kaggle\"\n",
    "kaggle_dir.mkdir(parents=True, exist_ok=True)\n",
    "cred_path = kaggle_dir / \"kaggle.json\"\n",
    "cred_path.write_text(json.dumps(creds))\n",
    "os.chmod(cred_path, 0o600)\n",
    "\n",
    "# --- 3. Double-check the file actually exists and is readable ---\n",
    "print(\"✅ Credentials written to:\", cred_path)\n",
    "!ls -la ~/.kaggle/\n",
    "#!cat ~/.kaggle/kaggle.json | head -1\n",
    "\n",
    "# --- 4. Reinstall Kaggle CLI cleanly ---\n",
    "#!pip install --upgrade --force-reinstall kaggle --quiet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions files -c aml-competition\n",
    "!kaggle competitions download -c aml-competition -p /kaggle/working --force\n",
    "!mkdir -p /kaggle/working/data\n",
    "!unzip -o /kaggle/working/aml-competition.zip -d /kaggle/working/data\n",
    "!ls -lah /kaggle/working/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T19:55:40.278539Z",
     "iopub.status.busy": "2025-10-26T19:55:40.278208Z",
     "iopub.status.idle": "2025-10-26T19:55:43.320740Z",
     "shell.execute_reply": "2025-10-26T19:55:43.319784Z",
     "shell.execute_reply.started": "2025-10-26T19:55:40.278517Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'challenge'...\n",
      "remote: Enumerating objects: 98, done.\u001b[K\n",
      "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
      "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
      "remote: Total 98 (delta 39), reused 72 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (98/98), 21.03 MiB | 21.15 MiB/s, done.\n",
      "Resolving deltas: 100% (39/39), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Mamiglia/challenge.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:44:01.858081Z",
     "iopub.status.busy": "2025-10-26T20:44:01.857460Z",
     "iopub.status.idle": "2025-10-26T20:44:01.905012Z",
     "shell.execute_reply": "2025-10-26T20:44:01.904178Z",
     "shell.execute_reply.started": "2025-10-26T20:44:01.858049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# runner.py\n",
    "import json, random, re, time\n",
    "from pathlib import Path\n",
    "from os.path import basename\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from challenge.src.common import load_data, generate_submission\n",
    "\n",
    "# ---------- Paths ----------\n",
    "DATA_ROOT = Path(\"/kaggle/working/data\")\n",
    "TRAIN_DIR = DATA_ROOT / \"train\" / \"train\"\n",
    "TEST_DIR  = DATA_ROOT / \"test\"  / \"test\"\n",
    "TRAIN_NPZ = TRAIN_DIR / \"train.npz\"\n",
    "TEST_NPZ  = TEST_DIR / \"test.clean.npz\"\n",
    "TRAIN_CAPTIONS = TRAIN_DIR / \"captions.txt\"\n",
    "TEST_CAPTIONS  = TEST_DIR  / \"captions.txt\"\n",
    "\n",
    "# ---------- Utils ----------\n",
    "def seed_all(s: int):\n",
    "    random.seed(s); np.random.seed(s)\n",
    "    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
    "    torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "\n",
    "def _build_image_index(image_ids):\n",
    "    idx_exact = {}; idx_base={}; idx_stem={}\n",
    "    for i, v in enumerate(image_ids):\n",
    "        s = str(v); idx_exact[s]=i\n",
    "        b = basename(s); idx_base[b]=i\n",
    "        stem = b.rsplit(\".\",1)[0] if \".\" in b else b\n",
    "        idx_stem[stem]=i\n",
    "    return idx_exact, idx_base, idx_stem\n",
    "\n",
    "def _iter_targets_from_captions(path: Path, n_text: int, idx_exact, idx_base, idx_stem):\n",
    "    targets=[]\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for raw in f:\n",
    "            if len(targets)>=n_text: break\n",
    "            line=raw.strip()\n",
    "            if not line: continue\n",
    "            lower=line.lower()\n",
    "            if (\"image\" in lower or \"filename\" in lower) and (\",\" in line or \"|\" in line or \"\\t\" in line):\n",
    "                first=re.split(r'\\||\\t|,| {2,}', line)[0].strip().strip('\"').strip(\"'\")\n",
    "                if \".\" not in first: continue\n",
    "            parts=re.split(r'\\||\\t|,| {2,}', line)\n",
    "            if len(parts)==1: parts=line.split(\" \",1)\n",
    "            tok=parts[0].strip().strip('\"').strip(\"'\")\n",
    "            if not tok: continue\n",
    "            def _match(tok_):\n",
    "                if tok_ in idx_exact: return idx_exact[tok_]\n",
    "                b=basename(tok_)\n",
    "                if b in idx_base: return idx_base[b]\n",
    "                stem=b.rsplit(\".\",1)[0] if \".\" in b else b\n",
    "                if stem in idx_stem: return idx_stem[stem]\n",
    "                return None\n",
    "            idx=_match(tok)\n",
    "            if idx is None:\n",
    "                tok2=tok.replace(\"Images/\",\"\").replace(\"./\",\"\")\n",
    "                idx=_match(tok2)\n",
    "            if idx is None:\n",
    "                if \".\" not in tok: continue\n",
    "                raise AssertionError(f\"Could not match image token '{tok}'\")\n",
    "            targets.append(idx)\n",
    "    assert len(targets)==n_text, f\"matched {len(targets)} vs N_text {n_text}\"\n",
    "    return np.asarray(targets, dtype=np.int64)\n",
    "\n",
    "def load_train(out_dir: Path):\n",
    "    d=np.load(TRAIN_NPZ, allow_pickle=True)\n",
    "    X=d[\"captions/embeddings\"].astype(np.float32)  # (N_text, 1024 or P*D)\n",
    "    I=d[\"images/embeddings\"].astype(np.float32)    # (N_img, 1536)\n",
    "    cap_ids=d.get(\"captions/ids\", np.arange(len(X)).astype(str))\n",
    "    img_names=d.get(\"images/names\", np.arange(len(I)).astype(str))\n",
    "\n",
    "    ex,ba,st=_build_image_index(img_names)\n",
    "    assert TRAIN_CAPTIONS.exists(), f\"Missing {TRAIN_CAPTIONS}\"\n",
    "    targets=_iter_targets_from_captions(TRAIN_CAPTIONS, len(X), ex,ba,st)\n",
    "\n",
    "    Y=I[targets]                       # (N_text, 1536) ground-truth\n",
    "    img_ids_row = img_names[targets]   # image id per row\n",
    "    meta={\"n_text\":int(len(X)),\"n_images\":int(len(I))}\n",
    "    (out_dir/\"train_detect.json\").write_text(json.dumps(meta, indent=2))\n",
    "    return X,Y,cap_ids,img_ids_row,I,img_names\n",
    "\n",
    "def load_test():\n",
    "    d_test=np.load(TEST_NPZ, allow_pickle=True)\n",
    "    Q=d_test[\"captions/embeddings\"].astype(np.float32)\n",
    "    q_ids=d_test.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n",
    "    # gallery: prefer test's, else train's\n",
    "    if \"images/embeddings\" in d_test.files:\n",
    "        G=d_test[\"images/embeddings\"].astype(np.float32)\n",
    "        g_ids=d_test.get(\"images/names\", np.arange(len(G)).astype(str))\n",
    "    else:\n",
    "        d_tr=np.load(TRAIN_NPZ, allow_pickle=True)\n",
    "        G=d_tr[\"images/embeddings\"].astype(np.float32)\n",
    "        g_ids=d_tr.get(\"images/names\", np.arange(len(G)).astype(str))\n",
    "    return Q,G,q_ids,g_ids\n",
    "\n",
    "def infer_arch_from_state_dict(sd):\n",
    "    ks = set(sd.keys())\n",
    "    if {\"fc.weight\",\"fc.bias\"} <= ks: return \"linear\"\n",
    "    if {\"fc1.weight\",\"fc1.bias\",\"fc2.weight\",\"fc2.bias\"} <= ks: return \"mlp1\"\n",
    "    if any(k.startswith(\"net.\") for k in ks): return \"mlp2\"\n",
    "    raise ValueError(\"Unrecognized checkpoint layout.\")\n",
    "\n",
    "# ---------- Dataset ----------\n",
    "class PairDS(Dataset):\n",
    "    def __init__(self, X, Y): self.X=torch.from_numpy(X); self.Y=torch.from_numpy(Y)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, i): return self.X[i], self.Y[i]\n",
    "\n",
    "# ---------- Pooling ----------\n",
    "def apply_pooling(x: torch.Tensor, mode: str, n_patches: int|None):\n",
    "    if mode.lower()==\"cls\":            # identity\n",
    "        return x\n",
    "    if mode.lower().startswith(\"mean\"):\n",
    "        if x.ndim==3: return x.mean(1)\n",
    "        if n_patches and x.shape[1]%n_patches==0:\n",
    "            P=n_patches; D=x.shape[1]//P\n",
    "            return x.view(x.shape[0], P, D).mean(1)\n",
    "        return x                       # fallback\n",
    "    return x\n",
    "\n",
    "# ---------- Models ----------\n",
    "class LinearProj(nn.Module):\n",
    "    def __init__(self, din, dout):\n",
    "        super().__init__()\n",
    "        self.fc=nn.Linear(din,dout)\n",
    "        nn.init.xavier_normal_(self.fc.weight); nn.init.zeros_(self.fc.bias)\n",
    "    def forward(self,x): return self.fc(x)\n",
    "\n",
    "class MLP1(nn.Module):\n",
    "    def __init__(self, din, dout, hidden=512, pdrop=0.0):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(din,hidden), nn.ReLU(), nn.Dropout(pdrop),\n",
    "            nn.Linear(hidden,dout)\n",
    "        )\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class MLP2(nn.Module):\n",
    "    def __init__(self, din, dout, h1=1024, h2=512, pdrop=0.0):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(din,h1), nn.ReLU(), nn.Dropout(pdrop),\n",
    "            nn.Linear(h1,h2), nn.ReLU(), nn.Dropout(pdrop),\n",
    "            nn.Linear(h2,dout)\n",
    "        )\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "def make_model(arch:str, din:int, dout:int):\n",
    "    arch=arch.lower()\n",
    "    if arch==\"linear\": return LinearProj(din,dout)\n",
    "    if arch==\"mlp1\":   return MLP1(din,dout,hidden=512)\n",
    "    if arch==\"mlp2\":   return MLP2(din,dout,h1=1024,h2=512)\n",
    "    raise ValueError(f\"Unknown arch {arch}\")\n",
    "\n",
    "# ---------- Loss pieces ----------\n",
    "def loss_align(pred, tgt, kind:str):\n",
    "    if kind==\"none\": return pred.new_tensor(0.0)\n",
    "    if kind==\"moment\":\n",
    "        # match batch mean and std (channel-wise)\n",
    "        mu_p, mu_t = pred.mean(0), tgt.mean(0)\n",
    "        sd_p, sd_t = pred.std(0, unbiased=False), tgt.std(0, unbiased=False)\n",
    "        return F.mse_loss(mu_p, mu_t) + F.mse_loss(sd_p, sd_t)\n",
    "    if kind==\"normcal\":\n",
    "        # calibrate L2 norm distribution\n",
    "        np_ = pred.norm(dim=-1).mean()\n",
    "        nt_ = tgt.norm(dim=-1).mean()\n",
    "        return F.mse_loss(np_, nt_)\n",
    "    raise ValueError(kind)\n",
    "\n",
    "def info_nce(pred, tgt):\n",
    "    # in-batch InfoNCE with cosine sim\n",
    "    p = F.normalize(pred, dim=-1)\n",
    "    t = F.normalize(tgt, dim=-1)\n",
    "    logits = p @ t.t()                      # (B,B)\n",
    "    labels = torch.arange(pred.size(0), device=pred.device)\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "# ---------- Metrics ----------\n",
    "@torch.no_grad()\n",
    "def validate_retrieval(model, Xv, Yv, pooling, n_patches, bs=1024):\n",
    "    device=next(model.parameters()).device\n",
    "    # gallery = unique images in val\n",
    "    Yv_np = Yv.copy()\n",
    "    # build unique gallery\n",
    "    _, uniq_idx = np.unique(Yv_np, axis=0, return_index=True)  # cheap, works since Yv rows are copies from I\n",
    "    Gi = torch.from_numpy(Yv_np[sorted(uniq_idx)]).to(device)\n",
    "    Gi = F.normalize(Gi, dim=-1)\n",
    "\n",
    "    ranks=[]\n",
    "    for i in range(0, len(Xv), bs):\n",
    "        xb=torch.from_numpy(Xv[i:i+bs]).to(device)\n",
    "        xb=apply_pooling(xb, pooling, n_patches)\n",
    "        pred=model(xb)\n",
    "        pred=F.normalize(pred, dim=-1)\n",
    "        sims=pred @ Gi.t()                 # (b, M)\n",
    "        # compute rank of the matching Y row within Gi\n",
    "        for j in range(sims.size(0)):\n",
    "            # find index in Gi that matches Yv row\n",
    "            y = torch.from_numpy(Yv_np[i+j]).to(device)\n",
    "            y = F.normalize(y, dim=-1)\n",
    "            # true index = argmax sim with Gi\n",
    "            true_idx = torch.argmax(Gi @ y, dim=0).item()\n",
    "            order = torch.argsort(sims[j], descending=True)\n",
    "            rank = (order==true_idx).nonzero(as_tuple=False).item() + 1\n",
    "            ranks.append(rank)\n",
    "\n",
    "    ranks = np.array(ranks)\n",
    "    mrr = np.mean(1.0 / ranks)\n",
    "    r1  = np.mean(ranks<=1)\n",
    "    r5  = np.mean(ranks<=5)\n",
    "    r10 = np.mean(ranks<=10)\n",
    "    return dict(MRR=float(mrr), R1=float(r1), R5=float(r5), R10=float(r10),\n",
    "                median=int(np.median(ranks)), p75=int(np.percentile(ranks,75)))\n",
    "\n",
    "def count_params_mb(model):\n",
    "    params=sum(p.numel() for p in model.parameters())\n",
    "    mb = params * 4 / (1024**2)\n",
    "    return params, mb\n",
    "\n",
    "def time_ms_per_query(model, din, pooling, n_patches):\n",
    "    device=next(model.parameters()).device\n",
    "    x=torch.randn(2048, din, device=device)\n",
    "    x=apply_pooling(x, pooling, n_patches)\n",
    "    torch.cuda.synchronize(device) if device.type==\"cuda\" else None\n",
    "    t0=time.time()\n",
    "    with torch.no_grad(): _=model(x)\n",
    "    torch.cuda.synchronize(device) if device.type==\"cuda\" else None\n",
    "    ms = (time.time()-t0)*1000/len(x)\n",
    "    # cpu timing\n",
    "    mcpu=model.to(\"cpu\")\n",
    "    xcpu=x.to(\"cpu\")\n",
    "    t1=time.time()\n",
    "    with torch.no_grad(): _=mcpu(xcpu)\n",
    "    ms_cpu=(time.time()-t1)*1000/len(xcpu)\n",
    "    model.to(device)\n",
    "    return ms, ms_cpu\n",
    "\n",
    "# ---------- Training ----------\n",
    "def train_one(model, loader, opt, alpha, beta, gamma, align_kind, pooling, n_patches, device):\n",
    "    model.train(); total=0.0\n",
    "    for xb,yb in loader:\n",
    "        xb,yb=xb.to(device), yb.to(device)\n",
    "        xb=apply_pooling(xb, pooling, n_patches)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        pred=model(xb)\n",
    "        cos = 1 - F.cosine_similarity(pred, yb, dim=-1).mean()\n",
    "        mse = F.mse_loss(pred, yb)\n",
    "        a_loss = loss_align(pred, yb, align_kind)\n",
    "        ce = info_nce(pred, yb) if gamma>0 else pred.new_tensor(0.0)\n",
    "        loss = alpha*cos + beta*mse + gamma*ce + a_loss\n",
    "        loss.backward(); opt.step()\n",
    "        total += loss.item()*xb.size(0)\n",
    "    return total/len(loader.dataset)\n",
    "\n",
    "# ---------- Main ----------\n",
    "def main(\n",
    "    out_dir=\"baseline_ref\", seed=42, epochs=20, batch=512, lr=1e-4, wd=1e-4,\n",
    "    pooling=\"CLS\", n_patches=None, alpha=1.0, beta=1.0, gamma=0.0,\n",
    "    align_loss=\"none\", arch=\"auto\", train=True, val_ratio=0.1\n",
    "):\n",
    "    seed_all(seed)\n",
    "    OUT = Path(f\"/kaggle/working/outputs/{out_dir}\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # --- data\n",
    "    X,Y,cap_ids,img_ids_row,full_img,all_img_ids = load_train(OUT)\n",
    "    uniq = np.unique(img_ids_row); rng = np.random.default_rng(seed); rng.shuffle(uniq)\n",
    "    n_val = max(1, int(len(uniq)*val_ratio)); valset = set(uniq[:n_val])\n",
    "    m = np.array([iid in valset for iid in img_ids_row])\n",
    "    Xtr,Ytr,Xva,Yva = X[~m],Y[~m],X[m],Y[m]\n",
    "\n",
    "    din, dout = X.shape[1], Y.shape[1]\n",
    "\n",
    "    # --- build/load model\n",
    "    if train:\n",
    "        eff_arch = arch if arch != \"auto\" else \"linear\"  # default for fresh training\n",
    "        model = make_model(eff_arch, din, dout).to(device)\n",
    "    else:\n",
    "        ckpt = torch.load(OUT/\"best.pt\", map_location=\"cpu\")\n",
    "        eff_arch = arch if arch != \"auto\" else infer_arch_from_state_dict(ckpt[\"model\"])\n",
    "        print(f\"[ckpt] detected arch = {eff_arch}\")\n",
    "        model = make_model(eff_arch, din, dout).to(device)\n",
    "        model.load_state_dict(ckpt[\"model\"])\n",
    "\n",
    "    params, mb = count_params_mb(model)\n",
    "    print(f\"[model] {eff_arch} | params={params:,} (~{mb:.2f} MB) | pooling={pooling} | align={align_loss} | α={alpha} β={beta} γ={gamma}\")\n",
    "\n",
    "    # --- train (if requested)\n",
    "    if train:\n",
    "        dl = DataLoader(PairDS(Xtr,Ytr), batch_size=batch, shuffle=True, num_workers=2, pin_memory=True)\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        best = -1.0; best_ep = 0; best_stats = None\n",
    "        for ep in range(1, epochs+1):\n",
    "            tr = train_one(model, dl, opt, alpha,beta,gamma,align_loss, pooling, n_patches, device)\n",
    "            stats = validate_retrieval(model, Xva, Yva, pooling, n_patches)\n",
    "            print(f\"[{ep:02d}] train_loss={tr:.6f} | val_MRR={stats['MRR']:.4f} | R@1={stats['R1']:.3f} R@5={stats['R5']:.3f}\")\n",
    "            if stats[\"MRR\"] > best:\n",
    "                best, best_ep, best_stats = stats[\"MRR\"], ep, stats\n",
    "                torch.save({\"model\":model.state_dict(),\"epoch\":ep,\"val\":stats}, OUT/\"best.pt\")\n",
    "        print(f\"[best] MRR={best:.4f} @ epoch {best_ep}\")\n",
    "        (OUT/\"val_metrics.json\").write_text(json.dumps(dict(best_epoch=best_ep, **best_stats), indent=2))\n",
    "    else:\n",
    "        # already loaded weights above\n",
    "        ckpt = torch.load(OUT/\"best.pt\", map_location=\"cpu\")\n",
    "        print(f\"[resume] loaded epoch={ckpt.get('epoch','?')} MRR={ckpt.get('val',{}).get('MRR','?')}\")\n",
    "\n",
    "    # --- efficiency\n",
    "    ms_gpu, ms_cpu = time_ms_per_query(model, din, pooling, n_patches)\n",
    "    (OUT/\"efficiency.json\").write_text(json.dumps(\n",
    "        {\"params\":params,\"mb_fp32\":mb,\"ms_per_query_gpu\":ms_gpu,\"ms_per_query_cpu\":ms_cpu}, indent=2\n",
    "    ))\n",
    "\n",
    "    # --- submission (official helper)\n",
    "    TEST_NPZ = (TEST_DIR / \"test.clean.npz\")\n",
    "    test_data = load_data(TEST_NPZ)\n",
    "    Q   = test_data[\"captions/embeddings\"].astype(np.float32)\n",
    "    ids = test_data.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n",
    "\n",
    "    model.eval()\n",
    "    BS = 1024\n",
    "    outs = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(Q), BS):\n",
    "            q = torch.from_numpy(Q[i:i+BS]).to(device)\n",
    "            q = apply_pooling(q, pooling, n_patches)\n",
    "            z = model(q)\n",
    "            z = F.normalize(z, dim=-1)\n",
    "            outs.append(z.detach().cpu().numpy())\n",
    "    pred_embds = np.concatenate(outs, axis=0)\n",
    "\n",
    "    sub = OUT / \"submission.csv\"\n",
    "    generate_submission(ids, pred_embds, str(sub))\n",
    "    print(f\"[ok] submission written → {sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:44:07.503606Z",
     "iopub.status.busy": "2025-10-26T20:44:07.502848Z",
     "iopub.status.idle": "2025-10-26T20:47:46.587152Z",
     "shell.execute_reply": "2025-10-26T20:47:46.586311Z",
     "shell.execute_reply.started": "2025-10-26T20:44:07.503582Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] linear | params=1,574,400 (~6.01 MB) | pooling=CLS | align=none | α=1.0 β=1.0 γ=0.0\n",
      "[01] train_loss=0.954751 | val_MRR=0.1206 | R@1=0.057 R@5=0.170\n",
      "[02] train_loss=0.507948 | val_MRR=0.1398 | R@1=0.070 R@5=0.194\n",
      "[03] train_loss=0.432700 | val_MRR=0.1506 | R@1=0.077 R@5=0.212\n",
      "[04] train_loss=0.401670 | val_MRR=0.1607 | R@1=0.083 R@5=0.226\n",
      "[05] train_loss=0.383644 | val_MRR=0.1665 | R@1=0.087 R@5=0.234\n",
      "[06] train_loss=0.371423 | val_MRR=0.1701 | R@1=0.088 R@5=0.242\n",
      "[07] train_loss=0.362467 | val_MRR=0.1754 | R@1=0.094 R@5=0.248\n",
      "[08] train_loss=0.355643 | val_MRR=0.1786 | R@1=0.095 R@5=0.252\n",
      "[09] train_loss=0.350284 | val_MRR=0.1810 | R@1=0.096 R@5=0.258\n",
      "[10] train_loss=0.346007 | val_MRR=0.1829 | R@1=0.097 R@5=0.261\n",
      "[11] train_loss=0.342501 | val_MRR=0.1846 | R@1=0.099 R@5=0.262\n",
      "[12] train_loss=0.339609 | val_MRR=0.1882 | R@1=0.102 R@5=0.267\n",
      "[13] train_loss=0.337181 | val_MRR=0.1888 | R@1=0.101 R@5=0.269\n",
      "[14] train_loss=0.335115 | val_MRR=0.1915 | R@1=0.104 R@5=0.271\n",
      "[15] train_loss=0.333372 | val_MRR=0.1914 | R@1=0.104 R@5=0.273\n",
      "[16] train_loss=0.331857 | val_MRR=0.1941 | R@1=0.107 R@5=0.275\n",
      "[17] train_loss=0.330544 | val_MRR=0.1954 | R@1=0.107 R@5=0.278\n",
      "[18] train_loss=0.329416 | val_MRR=0.1957 | R@1=0.107 R@5=0.278\n",
      "[19] train_loss=0.328411 | val_MRR=0.1964 | R@1=0.107 R@5=0.281\n",
      "[20] train_loss=0.327532 | val_MRR=0.1972 | R@1=0.108 R@5=0.282\n",
      "[21] train_loss=0.326740 | val_MRR=0.1993 | R@1=0.111 R@5=0.285\n",
      "[22] train_loss=0.326060 | val_MRR=0.1996 | R@1=0.110 R@5=0.284\n",
      "[23] train_loss=0.325418 | val_MRR=0.1987 | R@1=0.109 R@5=0.285\n",
      "[24] train_loss=0.324864 | val_MRR=0.2002 | R@1=0.110 R@5=0.286\n",
      "[25] train_loss=0.324370 | val_MRR=0.1998 | R@1=0.110 R@5=0.287\n",
      "[26] train_loss=0.323910 | val_MRR=0.1997 | R@1=0.109 R@5=0.287\n",
      "[27] train_loss=0.323486 | val_MRR=0.2007 | R@1=0.111 R@5=0.286\n",
      "[28] train_loss=0.323121 | val_MRR=0.2021 | R@1=0.112 R@5=0.289\n",
      "[29] train_loss=0.322772 | val_MRR=0.2015 | R@1=0.111 R@5=0.289\n",
      "[30] train_loss=0.322453 | val_MRR=0.2030 | R@1=0.113 R@5=0.288\n",
      "[best] MRR=0.2030 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/baseline_ref/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/baseline_ref/submission.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"baseline_ref\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1.0)\n",
    "    p.add_argument(\"--beta\", type=float, default=1.0)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.0)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"auto\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:28:39.493465Z",
     "iopub.status.busy": "2025-10-26T20:28:39.492598Z",
     "iopub.status.idle": "2025-10-26T20:32:28.017604Z",
     "shell.execute_reply": "2025-10-26T20:32:28.016678Z",
     "shell.execute_reply.started": "2025-10-26T20:28:39.493433Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=none | α=1.0 β=1.0 γ=0.0\n",
      "[01] train_loss=0.660932 | val_MRR=0.0333 | R@1=0.009 R@5=0.043\n",
      "[02] train_loss=0.412790 | val_MRR=0.0618 | R@1=0.024 R@5=0.082\n",
      "[03] train_loss=0.380159 | val_MRR=0.0828 | R@1=0.035 R@5=0.111\n",
      "[04] train_loss=0.363856 | val_MRR=0.0970 | R@1=0.042 R@5=0.132\n",
      "[05] train_loss=0.353517 | val_MRR=0.1121 | R@1=0.052 R@5=0.156\n",
      "[06] train_loss=0.346098 | val_MRR=0.1212 | R@1=0.055 R@5=0.173\n",
      "[07] train_loss=0.340426 | val_MRR=0.1313 | R@1=0.061 R@5=0.186\n",
      "[08] train_loss=0.335868 | val_MRR=0.1379 | R@1=0.064 R@5=0.199\n",
      "[09] train_loss=0.332036 | val_MRR=0.1467 | R@1=0.069 R@5=0.213\n",
      "[10] train_loss=0.328716 | val_MRR=0.1541 | R@1=0.074 R@5=0.223\n",
      "[11] train_loss=0.325812 | val_MRR=0.1613 | R@1=0.080 R@5=0.232\n",
      "[12] train_loss=0.323231 | val_MRR=0.1674 | R@1=0.085 R@5=0.240\n",
      "[13] train_loss=0.320927 | val_MRR=0.1739 | R@1=0.089 R@5=0.251\n",
      "[14] train_loss=0.318824 | val_MRR=0.1789 | R@1=0.093 R@5=0.256\n",
      "[15] train_loss=0.316905 | val_MRR=0.1819 | R@1=0.095 R@5=0.261\n",
      "[16] train_loss=0.315126 | val_MRR=0.1881 | R@1=0.099 R@5=0.272\n",
      "[17] train_loss=0.313457 | val_MRR=0.1906 | R@1=0.100 R@5=0.275\n",
      "[18] train_loss=0.311929 | val_MRR=0.1947 | R@1=0.103 R@5=0.280\n",
      "[19] train_loss=0.310463 | val_MRR=0.1984 | R@1=0.106 R@5=0.285\n",
      "[20] train_loss=0.309080 | val_MRR=0.2029 | R@1=0.110 R@5=0.291\n",
      "[21] train_loss=0.307751 | val_MRR=0.2070 | R@1=0.113 R@5=0.299\n",
      "[22] train_loss=0.306502 | val_MRR=0.2098 | R@1=0.114 R@5=0.302\n",
      "[23] train_loss=0.305328 | val_MRR=0.2132 | R@1=0.117 R@5=0.306\n",
      "[24] train_loss=0.304184 | val_MRR=0.2171 | R@1=0.122 R@5=0.311\n",
      "[25] train_loss=0.303101 | val_MRR=0.2181 | R@1=0.121 R@5=0.313\n",
      "[26] train_loss=0.302055 | val_MRR=0.2224 | R@1=0.125 R@5=0.320\n",
      "[27] train_loss=0.301057 | val_MRR=0.2246 | R@1=0.126 R@5=0.322\n",
      "[28] train_loss=0.300115 | val_MRR=0.2271 | R@1=0.129 R@5=0.324\n",
      "[29] train_loss=0.299189 | val_MRR=0.2284 | R@1=0.130 R@5=0.324\n",
      "[30] train_loss=0.298328 | val_MRR=0.2290 | R@1=0.131 R@5=0.327\n",
      "[best] MRR=0.2290 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos_mse/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos_mse/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# !python runner.py --out_dir mlp1_cls_cos_mse --train 1 --arch mlp1 --pooling CLS --alpha 1 --beta 1 --gamma 0 --align_loss none\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos_mse\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1.0)\n",
    "    p.add_argument(\"--beta\", type=float, default=1.0)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.0)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:33:27.043885Z",
     "iopub.status.busy": "2025-10-26T20:33:27.043205Z",
     "iopub.status.idle": "2025-10-26T20:37:11.256209Z",
     "shell.execute_reply": "2025-10-26T20:37:11.255462Z",
     "shell.execute_reply.started": "2025-10-26T20:33:27.043859Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=mean-patch | align=none | α=1.0 β=1.0 γ=0.0\n",
      "[01] train_loss=0.660932 | val_MRR=0.0333 | R@1=0.009 R@5=0.043\n",
      "[02] train_loss=0.412790 | val_MRR=0.0618 | R@1=0.024 R@5=0.082\n",
      "[03] train_loss=0.380159 | val_MRR=0.0828 | R@1=0.035 R@5=0.111\n",
      "[04] train_loss=0.363856 | val_MRR=0.0970 | R@1=0.042 R@5=0.132\n",
      "[05] train_loss=0.353517 | val_MRR=0.1121 | R@1=0.052 R@5=0.156\n",
      "[06] train_loss=0.346098 | val_MRR=0.1212 | R@1=0.055 R@5=0.173\n",
      "[07] train_loss=0.340426 | val_MRR=0.1313 | R@1=0.061 R@5=0.186\n",
      "[08] train_loss=0.335868 | val_MRR=0.1379 | R@1=0.064 R@5=0.199\n",
      "[09] train_loss=0.332036 | val_MRR=0.1467 | R@1=0.069 R@5=0.213\n",
      "[10] train_loss=0.328716 | val_MRR=0.1541 | R@1=0.074 R@5=0.223\n",
      "[11] train_loss=0.325812 | val_MRR=0.1613 | R@1=0.080 R@5=0.232\n",
      "[12] train_loss=0.323231 | val_MRR=0.1674 | R@1=0.085 R@5=0.240\n",
      "[13] train_loss=0.320927 | val_MRR=0.1739 | R@1=0.089 R@5=0.251\n",
      "[14] train_loss=0.318824 | val_MRR=0.1789 | R@1=0.093 R@5=0.256\n",
      "[15] train_loss=0.316905 | val_MRR=0.1819 | R@1=0.095 R@5=0.261\n",
      "[16] train_loss=0.315126 | val_MRR=0.1881 | R@1=0.099 R@5=0.272\n",
      "[17] train_loss=0.313457 | val_MRR=0.1906 | R@1=0.100 R@5=0.275\n",
      "[18] train_loss=0.311929 | val_MRR=0.1947 | R@1=0.103 R@5=0.280\n",
      "[19] train_loss=0.310463 | val_MRR=0.1984 | R@1=0.106 R@5=0.285\n",
      "[20] train_loss=0.309080 | val_MRR=0.2029 | R@1=0.110 R@5=0.291\n",
      "[21] train_loss=0.307751 | val_MRR=0.2070 | R@1=0.113 R@5=0.299\n",
      "[22] train_loss=0.306502 | val_MRR=0.2098 | R@1=0.114 R@5=0.302\n",
      "[23] train_loss=0.305328 | val_MRR=0.2132 | R@1=0.117 R@5=0.306\n",
      "[24] train_loss=0.304184 | val_MRR=0.2171 | R@1=0.122 R@5=0.311\n",
      "[25] train_loss=0.303101 | val_MRR=0.2181 | R@1=0.121 R@5=0.313\n",
      "[26] train_loss=0.302055 | val_MRR=0.2224 | R@1=0.125 R@5=0.320\n",
      "[27] train_loss=0.301057 | val_MRR=0.2246 | R@1=0.126 R@5=0.322\n",
      "[28] train_loss=0.300115 | val_MRR=0.2271 | R@1=0.129 R@5=0.324\n",
      "[29] train_loss=0.299189 | val_MRR=0.2284 | R@1=0.130 R@5=0.324\n",
      "[30] train_loss=0.298328 | val_MRR=0.2290 | R@1=0.131 R@5=0.327\n",
      "[best] MRR=0.2290 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_patch_cos_mse/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_patch_cos_mse/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp1_patch_cos_mse --pooling mean-patch --n_patches None --alpha 1 --beta 1 --gamma 0 --align_loss none --arch mlp1\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_patch_cos_mse\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"mean-patch\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1.0)\n",
    "    p.add_argument(\"--beta\", type=float, default=1.0)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.0)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we learned:\n",
    "\n",
    "- text_dim=1024 | image_dim=1536 we using the fixed encoders (roberta-large-nli-stsb-mean-tokens and dinov2-giant).\n",
    "-  leakage=False, val split by image id → new validation pipeline is officially aligned with the challenge spec.\n",
    "- Cosine retrieval (F.normalize, dot product) matches the public LB similarity.\n",
    "\n",
    "The LB expects already-normalized embeddings.\n",
    "\n",
    "- Raw outputs distort similarity magnitudes (pred norms ≈ 21 vs image norms ≈ 26 → biased dot products).\n",
    "-  Always normalize before writing the submission.\n",
    "\n",
    "mean||pred|| = 21.213 and mean||image|| = 25.939\n",
    "he LB similarity is cosine on normalized vectors, i.e. sim = (z_pred / ||z_pred||) @ (z_img / ||z_img||).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:37:29.657685Z",
     "iopub.status.busy": "2025-10-26T20:37:29.657124Z",
     "iopub.status.idle": "2025-10-26T20:41:08.103017Z",
     "shell.execute_reply": "2025-10-26T20:41:08.102080Z",
     "shell.execute_reply.started": "2025-10-26T20:37:29.657656Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=none | α=0.5 β=1.5 γ=0.0\n",
      "[01] train_loss=0.609829 | val_MRR=0.0321 | R@1=0.009 R@5=0.040\n",
      "[02] train_loss=0.387240 | val_MRR=0.0599 | R@1=0.023 R@5=0.079\n",
      "[03] train_loss=0.357811 | val_MRR=0.0814 | R@1=0.035 R@5=0.110\n",
      "[04] train_loss=0.342970 | val_MRR=0.0957 | R@1=0.041 R@5=0.131\n",
      "[05] train_loss=0.333531 | val_MRR=0.1105 | R@1=0.050 R@5=0.155\n",
      "[06] train_loss=0.326755 | val_MRR=0.1204 | R@1=0.054 R@5=0.172\n",
      "[07] train_loss=0.321568 | val_MRR=0.1302 | R@1=0.059 R@5=0.186\n",
      "[08] train_loss=0.317397 | val_MRR=0.1376 | R@1=0.064 R@5=0.196\n",
      "[09] train_loss=0.313890 | val_MRR=0.1463 | R@1=0.070 R@5=0.211\n",
      "[10] train_loss=0.310848 | val_MRR=0.1538 | R@1=0.075 R@5=0.221\n",
      "[11] train_loss=0.308186 | val_MRR=0.1608 | R@1=0.079 R@5=0.231\n",
      "[12] train_loss=0.305821 | val_MRR=0.1665 | R@1=0.083 R@5=0.240\n",
      "[13] train_loss=0.303701 | val_MRR=0.1734 | R@1=0.088 R@5=0.249\n",
      "[14] train_loss=0.301760 | val_MRR=0.1781 | R@1=0.092 R@5=0.258\n",
      "[15] train_loss=0.299996 | val_MRR=0.1822 | R@1=0.095 R@5=0.262\n",
      "[16] train_loss=0.298357 | val_MRR=0.1878 | R@1=0.099 R@5=0.272\n",
      "[17] train_loss=0.296822 | val_MRR=0.1916 | R@1=0.102 R@5=0.277\n",
      "[18] train_loss=0.295417 | val_MRR=0.1954 | R@1=0.104 R@5=0.282\n",
      "[19] train_loss=0.294070 | val_MRR=0.1981 | R@1=0.105 R@5=0.284\n",
      "[20] train_loss=0.292797 | val_MRR=0.2026 | R@1=0.109 R@5=0.291\n",
      "[21] train_loss=0.291578 | val_MRR=0.2068 | R@1=0.113 R@5=0.297\n",
      "[22] train_loss=0.290410 | val_MRR=0.2094 | R@1=0.114 R@5=0.301\n",
      "[23] train_loss=0.289296 | val_MRR=0.2126 | R@1=0.117 R@5=0.306\n",
      "[24] train_loss=0.288204 | val_MRR=0.2175 | R@1=0.122 R@5=0.311\n",
      "[25] train_loss=0.287174 | val_MRR=0.2179 | R@1=0.120 R@5=0.313\n",
      "[26] train_loss=0.286177 | val_MRR=0.2229 | R@1=0.125 R@5=0.318\n",
      "[27] train_loss=0.285224 | val_MRR=0.2243 | R@1=0.126 R@5=0.322\n",
      "[28] train_loss=0.284333 | val_MRR=0.2267 | R@1=0.128 R@5=0.325\n",
      "[29] train_loss=0.283455 | val_MRR=0.2284 | R@1=0.129 R@5=0.328\n",
      "[30] train_loss=0.282638 | val_MRR=0.2287 | R@1=0.129 R@5=0.328\n",
      "[best] MRR=0.2287 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos0.5_mse1.5/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos0.5_mse1.5/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp1_cls_cos0.5_mse1.5 --pooling CLS --alpha 0.5 --beta 1.5 --gamma 0 --align_loss none --arch mlp1\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos0.5_mse1.5\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=0.5)\n",
    "    p.add_argument(\"--beta\", type=float, default=1.5)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.0)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:48:25.977835Z",
     "iopub.status.busy": "2025-10-26T20:48:25.977054Z",
     "iopub.status.idle": "2025-10-26T20:52:04.527243Z",
     "shell.execute_reply": "2025-10-26T20:52:04.526264Z",
     "shell.execute_reply.started": "2025-10-26T20:48:25.977805Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=none | α=1.5 β=0.5 γ=0.0\n",
      "[01] train_loss=0.712952 | val_MRR=0.0363 | R@1=0.010 R@5=0.046\n",
      "[02] train_loss=0.438971 | val_MRR=0.0648 | R@1=0.025 R@5=0.088\n",
      "[03] train_loss=0.403020 | val_MRR=0.0858 | R@1=0.037 R@5=0.114\n",
      "[04] train_loss=0.385062 | val_MRR=0.0999 | R@1=0.044 R@5=0.136\n",
      "[05] train_loss=0.373677 | val_MRR=0.1140 | R@1=0.052 R@5=0.158\n",
      "[06] train_loss=0.365519 | val_MRR=0.1241 | R@1=0.058 R@5=0.175\n",
      "[07] train_loss=0.359262 | val_MRR=0.1334 | R@1=0.063 R@5=0.189\n",
      "[08] train_loss=0.354221 | val_MRR=0.1402 | R@1=0.066 R@5=0.201\n",
      "[09] train_loss=0.349983 | val_MRR=0.1489 | R@1=0.072 R@5=0.214\n",
      "[10] train_loss=0.346339 | val_MRR=0.1560 | R@1=0.077 R@5=0.225\n",
      "[11] train_loss=0.343170 | val_MRR=0.1631 | R@1=0.081 R@5=0.233\n",
      "[12] train_loss=0.340354 | val_MRR=0.1674 | R@1=0.083 R@5=0.241\n",
      "[13] train_loss=0.337847 | val_MRR=0.1748 | R@1=0.089 R@5=0.252\n",
      "[14] train_loss=0.335557 | val_MRR=0.1789 | R@1=0.091 R@5=0.259\n",
      "[15] train_loss=0.333478 | val_MRR=0.1818 | R@1=0.092 R@5=0.264\n",
      "[16] train_loss=0.331553 | val_MRR=0.1880 | R@1=0.097 R@5=0.273\n",
      "[17] train_loss=0.329760 | val_MRR=0.1917 | R@1=0.100 R@5=0.278\n",
      "[18] train_loss=0.328116 | val_MRR=0.1961 | R@1=0.104 R@5=0.284\n",
      "[19] train_loss=0.326539 | val_MRR=0.1991 | R@1=0.106 R@5=0.287\n",
      "[20] train_loss=0.325058 | val_MRR=0.2038 | R@1=0.110 R@5=0.295\n",
      "[21] train_loss=0.323631 | val_MRR=0.2081 | R@1=0.113 R@5=0.300\n",
      "[22] train_loss=0.322302 | val_MRR=0.2106 | R@1=0.114 R@5=0.305\n",
      "[23] train_loss=0.321045 | val_MRR=0.2138 | R@1=0.118 R@5=0.308\n",
      "[24] train_loss=0.319827 | val_MRR=0.2172 | R@1=0.120 R@5=0.312\n",
      "[25] train_loss=0.318679 | val_MRR=0.2185 | R@1=0.121 R@5=0.313\n",
      "[26] train_loss=0.317569 | val_MRR=0.2231 | R@1=0.125 R@5=0.319\n",
      "[27] train_loss=0.316524 | val_MRR=0.2259 | R@1=0.128 R@5=0.323\n",
      "[28] train_loss=0.315534 | val_MRR=0.2274 | R@1=0.129 R@5=0.325\n",
      "[29] train_loss=0.314565 | val_MRR=0.2283 | R@1=0.129 R@5=0.325\n",
      "[30] train_loss=0.313665 | val_MRR=0.2287 | R@1=0.130 R@5=0.326\n",
      "[best] MRR=0.2287 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos1.5_mse0.5/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos1.5_mse0.5/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp1_cls_cos1.5_mse0.5 --pooling CLS --alpha 1.5 --beta 0.5 --gamma 0 --align_loss none --arch mlp1\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos1.5_mse0.5\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1.5)\n",
    "    p.add_argument(\"--beta\", type=float, default=0.5)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.0)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:53:16.143281Z",
     "iopub.status.busy": "2025-10-26T20:53:16.142479Z",
     "iopub.status.idle": "2025-10-26T20:56:54.695153Z",
     "shell.execute_reply": "2025-10-26T20:56:54.694202Z",
     "shell.execute_reply.started": "2025-10-26T20:53:16.143249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.0\n",
      "[01] train_loss=0.740650 | val_MRR=0.0504 | R@1=0.017 R@5=0.067\n",
      "[02] train_loss=0.465031 | val_MRR=0.0868 | R@1=0.038 R@5=0.116\n",
      "[03] train_loss=0.426755 | val_MRR=0.1102 | R@1=0.050 R@5=0.150\n",
      "[04] train_loss=0.407163 | val_MRR=0.1248 | R@1=0.057 R@5=0.176\n",
      "[05] train_loss=0.394496 | val_MRR=0.1385 | R@1=0.064 R@5=0.197\n",
      "[06] train_loss=0.385237 | val_MRR=0.1488 | R@1=0.070 R@5=0.211\n",
      "[07] train_loss=0.378039 | val_MRR=0.1587 | R@1=0.075 R@5=0.228\n",
      "[08] train_loss=0.372214 | val_MRR=0.1672 | R@1=0.081 R@5=0.240\n",
      "[09] train_loss=0.367317 | val_MRR=0.1747 | R@1=0.086 R@5=0.252\n",
      "[10] train_loss=0.363102 | val_MRR=0.1818 | R@1=0.092 R@5=0.263\n",
      "[11] train_loss=0.359437 | val_MRR=0.1892 | R@1=0.097 R@5=0.272\n",
      "[12] train_loss=0.356184 | val_MRR=0.1951 | R@1=0.102 R@5=0.282\n",
      "[13] train_loss=0.353258 | val_MRR=0.2016 | R@1=0.107 R@5=0.290\n",
      "[14] train_loss=0.350566 | val_MRR=0.2067 | R@1=0.111 R@5=0.297\n",
      "[15] train_loss=0.348106 | val_MRR=0.2092 | R@1=0.112 R@5=0.300\n",
      "[16] train_loss=0.345823 | val_MRR=0.2156 | R@1=0.117 R@5=0.309\n",
      "[17] train_loss=0.343689 | val_MRR=0.2191 | R@1=0.120 R@5=0.313\n",
      "[18] train_loss=0.341751 | val_MRR=0.2238 | R@1=0.123 R@5=0.319\n",
      "[19] train_loss=0.339929 | val_MRR=0.2277 | R@1=0.126 R@5=0.323\n",
      "[20] train_loss=0.338219 | val_MRR=0.2303 | R@1=0.129 R@5=0.327\n",
      "[21] train_loss=0.336597 | val_MRR=0.2341 | R@1=0.132 R@5=0.333\n",
      "[22] train_loss=0.335087 | val_MRR=0.2367 | R@1=0.133 R@5=0.338\n",
      "[23] train_loss=0.333671 | val_MRR=0.2403 | R@1=0.137 R@5=0.344\n",
      "[24] train_loss=0.332315 | val_MRR=0.2432 | R@1=0.139 R@5=0.347\n",
      "[25] train_loss=0.331034 | val_MRR=0.2448 | R@1=0.140 R@5=0.348\n",
      "[26] train_loss=0.329796 | val_MRR=0.2483 | R@1=0.144 R@5=0.354\n",
      "[27] train_loss=0.328640 | val_MRR=0.2510 | R@1=0.146 R@5=0.356\n",
      "[28] train_loss=0.327536 | val_MRR=0.2532 | R@1=0.148 R@5=0.361\n",
      "[29] train_loss=0.326480 | val_MRR=0.2526 | R@1=0.146 R@5=0.358\n",
      "[30] train_loss=0.325500 | val_MRR=0.2541 | R@1=0.148 R@5=0.361\n",
      "[best] MRR=0.2541 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos+mse+moments/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos+mse+moments/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp1_cls_cos+mse+moments --pooling CLS --alpha 1 --beta 1 --gamma 0 --align_loss moment --arch mlp1\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos+mse+moments\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1)\n",
    "    p.add_argument(\"--beta\", type=float, default=1)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.0)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:57:52.863257Z",
     "iopub.status.busy": "2025-10-26T20:57:52.862678Z",
     "iopub.status.idle": "2025-10-26T21:01:32.588592Z",
     "shell.execute_reply": "2025-10-26T21:01:32.587854Z",
     "shell.execute_reply.started": "2025-10-26T20:57:52.863229Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=normcal | α=1 β=1 γ=0.0\n",
      "[01] train_loss=2.795950 | val_MRR=0.0046 | R@1=0.001 R@5=0.003\n",
      "[02] train_loss=1.281909 | val_MRR=0.0047 | R@1=0.000 R@5=0.004\n",
      "[03] train_loss=0.996945 | val_MRR=0.0055 | R@1=0.001 R@5=0.004\n",
      "[04] train_loss=0.828152 | val_MRR=0.0065 | R@1=0.001 R@5=0.005\n",
      "[05] train_loss=0.748381 | val_MRR=0.0079 | R@1=0.001 R@5=0.006\n",
      "[06] train_loss=0.703146 | val_MRR=0.0096 | R@1=0.002 R@5=0.009\n",
      "[07] train_loss=0.661552 | val_MRR=0.0113 | R@1=0.002 R@5=0.011\n",
      "[08] train_loss=0.625856 | val_MRR=0.0132 | R@1=0.003 R@5=0.014\n",
      "[09] train_loss=0.631494 | val_MRR=0.0155 | R@1=0.004 R@5=0.017\n",
      "[10] train_loss=0.596262 | val_MRR=0.0179 | R@1=0.004 R@5=0.020\n",
      "[11] train_loss=0.585320 | val_MRR=0.0202 | R@1=0.005 R@5=0.023\n",
      "[12] train_loss=0.573368 | val_MRR=0.0227 | R@1=0.006 R@5=0.026\n",
      "[13] train_loss=0.557340 | val_MRR=0.0255 | R@1=0.008 R@5=0.030\n",
      "[14] train_loss=0.541786 | val_MRR=0.0278 | R@1=0.008 R@5=0.033\n",
      "[15] train_loss=0.541319 | val_MRR=0.0314 | R@1=0.010 R@5=0.038\n",
      "[16] train_loss=0.541412 | val_MRR=0.0338 | R@1=0.010 R@5=0.042\n",
      "[17] train_loss=0.529126 | val_MRR=0.0366 | R@1=0.012 R@5=0.046\n",
      "[18] train_loss=0.530570 | val_MRR=0.0395 | R@1=0.013 R@5=0.050\n",
      "[19] train_loss=0.517997 | val_MRR=0.0420 | R@1=0.015 R@5=0.053\n",
      "[20] train_loss=0.504706 | val_MRR=0.0444 | R@1=0.016 R@5=0.056\n",
      "[21] train_loss=0.504576 | val_MRR=0.0482 | R@1=0.018 R@5=0.061\n",
      "[22] train_loss=0.499347 | val_MRR=0.0503 | R@1=0.019 R@5=0.063\n",
      "[23] train_loss=0.494783 | val_MRR=0.0527 | R@1=0.020 R@5=0.066\n",
      "[24] train_loss=0.476123 | val_MRR=0.0549 | R@1=0.022 R@5=0.068\n",
      "[25] train_loss=0.479874 | val_MRR=0.0575 | R@1=0.023 R@5=0.072\n",
      "[26] train_loss=0.467404 | val_MRR=0.0595 | R@1=0.024 R@5=0.075\n",
      "[27] train_loss=0.469203 | val_MRR=0.0617 | R@1=0.025 R@5=0.079\n",
      "[28] train_loss=0.466118 | val_MRR=0.0636 | R@1=0.026 R@5=0.081\n",
      "[29] train_loss=0.467986 | val_MRR=0.0658 | R@1=0.027 R@5=0.084\n",
      "[30] train_loss=0.467743 | val_MRR=0.0682 | R@1=0.029 R@5=0.090\n",
      "[best] MRR=0.0682 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos+mse+normcal/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos+mse+normcal/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp1_cls_cos+mse+normcal --pooling CLS --alpha 1 --beta 1 --gamma 0 --align_loss normcal --arch mlp1\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos+mse+normcal\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1)\n",
    "    p.add_argument(\"--beta\", type=float, default=1)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.0)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"normcal\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T21:03:05.615080Z",
     "iopub.status.busy": "2025-10-26T21:03:05.614241Z",
     "iopub.status.idle": "2025-10-26T21:06:40.038429Z",
     "shell.execute_reply": "2025-10-26T21:06:40.037630Z",
     "shell.execute_reply.started": "2025-10-26T21:03:05.615047Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp2 | params=2,362,368 (~9.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.0\n",
      "[01] train_loss=0.636256 | val_MRR=0.0449 | R@1=0.014 R@5=0.057\n",
      "[02] train_loss=0.438947 | val_MRR=0.0828 | R@1=0.032 R@5=0.115\n",
      "[03] train_loss=0.406235 | val_MRR=0.1096 | R@1=0.046 R@5=0.154\n",
      "[04] train_loss=0.389227 | val_MRR=0.1285 | R@1=0.056 R@5=0.181\n",
      "[05] train_loss=0.377987 | val_MRR=0.1440 | R@1=0.066 R@5=0.207\n",
      "[06] train_loss=0.369644 | val_MRR=0.1560 | R@1=0.073 R@5=0.229\n",
      "[07] train_loss=0.363055 | val_MRR=0.1688 | R@1=0.081 R@5=0.247\n",
      "[08] train_loss=0.357602 | val_MRR=0.1773 | R@1=0.087 R@5=0.259\n",
      "[09] train_loss=0.353023 | val_MRR=0.1858 | R@1=0.092 R@5=0.273\n",
      "[10] train_loss=0.348982 | val_MRR=0.1918 | R@1=0.096 R@5=0.281\n",
      "[11] train_loss=0.345339 | val_MRR=0.1993 | R@1=0.103 R@5=0.291\n",
      "[12] train_loss=0.341988 | val_MRR=0.2051 | R@1=0.108 R@5=0.296\n",
      "[13] train_loss=0.338930 | val_MRR=0.2127 | R@1=0.113 R@5=0.310\n",
      "[14] train_loss=0.336059 | val_MRR=0.2169 | R@1=0.116 R@5=0.317\n",
      "[15] train_loss=0.333389 | val_MRR=0.2221 | R@1=0.122 R@5=0.320\n",
      "[16] train_loss=0.330802 | val_MRR=0.2255 | R@1=0.124 R@5=0.324\n",
      "[17] train_loss=0.328334 | val_MRR=0.2307 | R@1=0.128 R@5=0.330\n",
      "[18] train_loss=0.326082 | val_MRR=0.2337 | R@1=0.131 R@5=0.335\n",
      "[19] train_loss=0.323883 | val_MRR=0.2359 | R@1=0.133 R@5=0.338\n",
      "[20] train_loss=0.321776 | val_MRR=0.2434 | R@1=0.140 R@5=0.347\n",
      "[21] train_loss=0.319802 | val_MRR=0.2426 | R@1=0.138 R@5=0.346\n",
      "[22] train_loss=0.317865 | val_MRR=0.2467 | R@1=0.142 R@5=0.352\n",
      "[23] train_loss=0.316039 | val_MRR=0.2486 | R@1=0.144 R@5=0.353\n",
      "[24] train_loss=0.314229 | val_MRR=0.2496 | R@1=0.146 R@5=0.354\n",
      "[25] train_loss=0.312527 | val_MRR=0.2533 | R@1=0.149 R@5=0.356\n",
      "[26] train_loss=0.310822 | val_MRR=0.2538 | R@1=0.150 R@5=0.359\n",
      "[27] train_loss=0.309195 | val_MRR=0.2552 | R@1=0.151 R@5=0.360\n",
      "[28] train_loss=0.307605 | val_MRR=0.2555 | R@1=0.151 R@5=0.358\n",
      "[29] train_loss=0.306055 | val_MRR=0.2591 | R@1=0.153 R@5=0.367\n",
      "[30] train_loss=0.304544 | val_MRR=0.2612 | R@1=0.155 R@5=0.369\n",
      "[best] MRR=0.2612 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp2_cls_cos+mse/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp2_cls_cos+mse/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp2_cls_cos+mse --pooling CLS --alpha 1 --beta 1 --gamma 0 --align_loss none --arch mlp2\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp2_cls_cos+mse\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1)\n",
    "    p.add_argument(\"--beta\", type=float, default=1)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.0)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp2\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T23:14:57.656371Z",
     "iopub.status.busy": "2025-10-26T23:14:57.655797Z",
     "iopub.status.idle": "2025-10-26T23:18:38.723945Z",
     "shell.execute_reply": "2025-10-26T23:18:38.722997Z",
     "shell.execute_reply.started": "2025-10-26T23:14:57.656341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=none | α=1 β=1 γ=0.1\n",
      "[01] train_loss=1.280466 | val_MRR=0.0384 | R@1=0.012 R@5=0.049\n",
      "[02] train_loss=1.027822 | val_MRR=0.0682 | R@1=0.028 R@5=0.092\n",
      "[03] train_loss=0.993354 | val_MRR=0.0901 | R@1=0.039 R@5=0.122\n",
      "[04] train_loss=0.976056 | val_MRR=0.1044 | R@1=0.046 R@5=0.143\n",
      "[05] train_loss=0.965049 | val_MRR=0.1202 | R@1=0.056 R@5=0.169\n",
      "[06] train_loss=0.957130 | val_MRR=0.1304 | R@1=0.061 R@5=0.185\n",
      "[07] train_loss=0.951046 | val_MRR=0.1404 | R@1=0.066 R@5=0.200\n",
      "[08] train_loss=0.946120 | val_MRR=0.1482 | R@1=0.071 R@5=0.214\n",
      "[09] train_loss=0.941967 | val_MRR=0.1561 | R@1=0.075 R@5=0.226\n",
      "[10] train_loss=0.938371 | val_MRR=0.1637 | R@1=0.081 R@5=0.235\n",
      "[11] train_loss=0.935229 | val_MRR=0.1720 | R@1=0.087 R@5=0.247\n",
      "[12] train_loss=0.932428 | val_MRR=0.1769 | R@1=0.091 R@5=0.254\n",
      "[13] train_loss=0.929919 | val_MRR=0.1842 | R@1=0.096 R@5=0.265\n",
      "[14] train_loss=0.927631 | val_MRR=0.1885 | R@1=0.099 R@5=0.272\n",
      "[15] train_loss=0.925544 | val_MRR=0.1910 | R@1=0.099 R@5=0.277\n",
      "[16] train_loss=0.923608 | val_MRR=0.1980 | R@1=0.106 R@5=0.285\n",
      "[17] train_loss=0.921790 | val_MRR=0.2007 | R@1=0.108 R@5=0.289\n",
      "[18] train_loss=0.920116 | val_MRR=0.2045 | R@1=0.110 R@5=0.295\n",
      "[19] train_loss=0.918501 | val_MRR=0.2098 | R@1=0.115 R@5=0.301\n",
      "[20] train_loss=0.916963 | val_MRR=0.2137 | R@1=0.118 R@5=0.308\n",
      "[21] train_loss=0.915489 | val_MRR=0.2177 | R@1=0.122 R@5=0.314\n",
      "[22] train_loss=0.914110 | val_MRR=0.2202 | R@1=0.122 R@5=0.316\n",
      "[23] train_loss=0.912819 | val_MRR=0.2231 | R@1=0.124 R@5=0.322\n",
      "[24] train_loss=0.911572 | val_MRR=0.2278 | R@1=0.129 R@5=0.325\n",
      "[25] train_loss=0.910402 | val_MRR=0.2294 | R@1=0.131 R@5=0.327\n",
      "[26] train_loss=0.909284 | val_MRR=0.2336 | R@1=0.133 R@5=0.333\n",
      "[27] train_loss=0.908220 | val_MRR=0.2355 | R@1=0.135 R@5=0.335\n",
      "[28] train_loss=0.907224 | val_MRR=0.2382 | R@1=0.138 R@5=0.338\n",
      "[29] train_loss=0.906249 | val_MRR=0.2385 | R@1=0.138 R@5=0.337\n",
      "[30] train_loss=0.905338 | val_MRR=0.2388 | R@1=0.137 R@5=0.340\n",
      "[best] MRR=0.2388 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_cls_cos+mse+infoNCE/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_cls_cos+mse+infoNCE/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp1_cls_cos+mse+infoNCE --pooling CLS --alpha 1 --beta 1 --gamma 0.1 --align_loss none --arch mlp1\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_cls_cos+mse+infoNCE\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1)\n",
    "    p.add_argument(\"--beta\", type=float, default=1)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.1)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T21:52:39.543423Z",
     "iopub.status.busy": "2025-10-26T21:52:39.542638Z",
     "iopub.status.idle": "2025-10-26T21:56:12.933536Z",
     "shell.execute_reply": "2025-10-26T21:56:12.932719Z",
     "shell.execute_reply.started": "2025-10-26T21:52:39.543396Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n",
      "[01] train_loss=1.554588 | val_MRR=0.0285 | R@1=0.008 R@5=0.034\n",
      "[02] train_loss=1.149325 | val_MRR=0.0571 | R@1=0.021 R@5=0.075\n",
      "[03] train_loss=1.089582 | val_MRR=0.0791 | R@1=0.033 R@5=0.105\n",
      "[04] train_loss=1.059996 | val_MRR=0.0957 | R@1=0.042 R@5=0.130\n",
      "[05] train_loss=1.041193 | val_MRR=0.1090 | R@1=0.050 R@5=0.148\n",
      "[06] train_loss=1.027914 | val_MRR=0.1190 | R@1=0.054 R@5=0.163\n",
      "[07] train_loss=1.017830 | val_MRR=0.1276 | R@1=0.058 R@5=0.178\n",
      "[08] train_loss=1.009741 | val_MRR=0.1349 | R@1=0.062 R@5=0.191\n",
      "[09] train_loss=1.003019 | val_MRR=0.1420 | R@1=0.066 R@5=0.200\n",
      "[10] train_loss=0.997265 | val_MRR=0.1487 | R@1=0.070 R@5=0.210\n",
      "[11] train_loss=0.992285 | val_MRR=0.1552 | R@1=0.074 R@5=0.222\n",
      "[12] train_loss=0.987915 | val_MRR=0.1594 | R@1=0.075 R@5=0.230\n",
      "[13] train_loss=0.984024 | val_MRR=0.1658 | R@1=0.080 R@5=0.239\n",
      "[14] train_loss=0.980513 | val_MRR=0.1707 | R@1=0.084 R@5=0.247\n",
      "[15] train_loss=0.977328 | val_MRR=0.1748 | R@1=0.086 R@5=0.254\n",
      "[16] train_loss=0.974423 | val_MRR=0.1802 | R@1=0.090 R@5=0.262\n",
      "[17] train_loss=0.971703 | val_MRR=0.1843 | R@1=0.093 R@5=0.267\n",
      "[18] train_loss=0.969221 | val_MRR=0.1891 | R@1=0.097 R@5=0.274\n",
      "[19] train_loss=0.966895 | val_MRR=0.1933 | R@1=0.100 R@5=0.281\n",
      "[20] train_loss=0.964707 | val_MRR=0.1967 | R@1=0.103 R@5=0.284\n",
      "[21] train_loss=0.962656 | val_MRR=0.2011 | R@1=0.107 R@5=0.290\n",
      "[22] train_loss=0.960720 | val_MRR=0.2044 | R@1=0.109 R@5=0.294\n",
      "[23] train_loss=0.958913 | val_MRR=0.2083 | R@1=0.112 R@5=0.300\n",
      "[24] train_loss=0.957193 | val_MRR=0.2118 | R@1=0.114 R@5=0.304\n",
      "[25] train_loss=0.955552 | val_MRR=0.2133 | R@1=0.115 R@5=0.309\n",
      "[26] train_loss=0.953995 | val_MRR=0.2170 | R@1=0.118 R@5=0.312\n",
      "[27] train_loss=0.952523 | val_MRR=0.2198 | R@1=0.120 R@5=0.316\n",
      "[28] train_loss=0.951132 | val_MRR=0.2221 | R@1=0.122 R@5=0.320\n",
      "[29] train_loss=0.949784 | val_MRR=0.2240 | R@1=0.123 R@5=0.321\n",
      "[30] train_loss=0.948511 | val_MRR=0.2257 | R@1=0.125 R@5=0.324\n",
      "[best] MRR=0.2257 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_lr5e5_moment01/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_lr5e5_moment01/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp1_cls_cos+mse+infoNCE --pooling CLS --lr 5e-5 --alpha 1 --beta 1 --gamma 0.1 --align_loss moment --arch mlp1\n",
    "\n",
    "# smaller LR stabilizes combo losses\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_lr5e5_moment01\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=5e-5)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1)\n",
    "    p.add_argument(\"--beta\", type=float, default=1)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.1)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T22:50:39.312745Z",
     "iopub.status.busy": "2025-10-26T22:50:39.312033Z",
     "iopub.status.idle": "2025-10-26T22:54:15.976023Z",
     "shell.execute_reply": "2025-10-26T22:54:15.975110Z",
     "shell.execute_reply.started": "2025-10-26T22:50:39.312714Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n",
      "[01] train_loss=1.227705 | val_MRR=0.0838 | R@1=0.035 R@5=0.113\n",
      "[02] train_loss=1.030644 | val_MRR=0.1229 | R@1=0.056 R@5=0.171\n",
      "[03] train_loss=1.001965 | val_MRR=0.1477 | R@1=0.069 R@5=0.211\n",
      "[04] train_loss=0.986564 | val_MRR=0.1646 | R@1=0.079 R@5=0.237\n",
      "[05] train_loss=0.976255 | val_MRR=0.1809 | R@1=0.090 R@5=0.261\n",
      "[06] train_loss=0.968573 | val_MRR=0.1918 | R@1=0.099 R@5=0.276\n",
      "[07] train_loss=0.962537 | val_MRR=0.2036 | R@1=0.107 R@5=0.295\n",
      "[08] train_loss=0.957577 | val_MRR=0.2120 | R@1=0.115 R@5=0.304\n",
      "[09] train_loss=0.953321 | val_MRR=0.2189 | R@1=0.120 R@5=0.313\n",
      "[10] train_loss=0.949557 | val_MRR=0.2258 | R@1=0.125 R@5=0.324\n",
      "[11] train_loss=0.946282 | val_MRR=0.2343 | R@1=0.133 R@5=0.335\n",
      "[12] train_loss=0.943318 | val_MRR=0.2376 | R@1=0.134 R@5=0.338\n",
      "[13] train_loss=0.940671 | val_MRR=0.2444 | R@1=0.141 R@5=0.347\n",
      "[14] train_loss=0.938257 | val_MRR=0.2475 | R@1=0.142 R@5=0.352\n",
      "[15] train_loss=0.936025 | val_MRR=0.2490 | R@1=0.144 R@5=0.351\n",
      "[16] train_loss=0.933938 | val_MRR=0.2548 | R@1=0.149 R@5=0.361\n",
      "[17] train_loss=0.931984 | val_MRR=0.2595 | R@1=0.153 R@5=0.364\n",
      "[18] train_loss=0.930230 | val_MRR=0.2613 | R@1=0.153 R@5=0.370\n",
      "[19] train_loss=0.928557 | val_MRR=0.2639 | R@1=0.157 R@5=0.373\n",
      "[20] train_loss=0.927021 | val_MRR=0.2644 | R@1=0.157 R@5=0.372\n",
      "[21] train_loss=0.925553 | val_MRR=0.2683 | R@1=0.160 R@5=0.377\n",
      "[22] train_loss=0.924201 | val_MRR=0.2701 | R@1=0.161 R@5=0.380\n",
      "[23] train_loss=0.922936 | val_MRR=0.2716 | R@1=0.162 R@5=0.386\n",
      "[24] train_loss=0.921727 | val_MRR=0.2747 | R@1=0.165 R@5=0.386\n",
      "[25] train_loss=0.920625 | val_MRR=0.2738 | R@1=0.165 R@5=0.386\n",
      "[26] train_loss=0.919546 | val_MRR=0.2750 | R@1=0.165 R@5=0.388\n",
      "[27] train_loss=0.918536 | val_MRR=0.2775 | R@1=0.167 R@5=0.390\n",
      "[28] train_loss=0.917578 | val_MRR=0.2783 | R@1=0.168 R@5=0.390\n",
      "[29] train_loss=0.916662 | val_MRR=0.2758 | R@1=0.165 R@5=0.391\n",
      "[30] train_loss=0.915806 | val_MRR=0.2778 | R@1=0.168 R@5=0.390\n",
      "[best] MRR=0.2783 @ epoch 28\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_lr2e4_moment01/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_lr2e4_moment01/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp2_moment_infonce01 --arch mlp2 --gamma 0.1 --align_loss moment --lr 2e-4\n",
    "# If underfitting, higher LR helps\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_lr2e4_moment01\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=2e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1)\n",
    "    p.add_argument(\"--beta\", type=float, default=1)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.1)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T22:30:27.450875Z",
     "iopub.status.busy": "2025-10-26T22:30:27.450538Z",
     "iopub.status.idle": "2025-10-26T22:34:08.170362Z",
     "shell.execute_reply": "2025-10-26T22:34:08.169323Z",
     "shell.execute_reply.started": "2025-10-26T22:30:27.450848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n",
      "[01] train_loss=1.358940 | val_MRR=0.0541 | R@1=0.019 R@5=0.072\n",
      "[02] train_loss=1.077363 | val_MRR=0.0915 | R@1=0.040 R@5=0.123\n",
      "[03] train_loss=1.037254 | val_MRR=0.1146 | R@1=0.052 R@5=0.158\n",
      "[04] train_loss=1.016725 | val_MRR=0.1294 | R@1=0.059 R@5=0.181\n",
      "[05] train_loss=1.003400 | val_MRR=0.1438 | R@1=0.067 R@5=0.204\n",
      "[06] train_loss=0.993644 | val_MRR=0.1539 | R@1=0.072 R@5=0.222\n",
      "[07] train_loss=0.986059 | val_MRR=0.1641 | R@1=0.079 R@5=0.238\n",
      "[08] train_loss=0.979914 | val_MRR=0.1723 | R@1=0.084 R@5=0.249\n",
      "[09] train_loss=0.974755 | val_MRR=0.1802 | R@1=0.089 R@5=0.262\n",
      "[10] train_loss=0.970305 | val_MRR=0.1876 | R@1=0.096 R@5=0.270\n",
      "[11] train_loss=0.966435 | val_MRR=0.1949 | R@1=0.102 R@5=0.281\n",
      "[12] train_loss=0.962991 | val_MRR=0.2001 | R@1=0.105 R@5=0.289\n",
      "[13] train_loss=0.959890 | val_MRR=0.2073 | R@1=0.110 R@5=0.299\n",
      "[14] train_loss=0.957038 | val_MRR=0.2125 | R@1=0.115 R@5=0.304\n",
      "[15] train_loss=0.954436 | val_MRR=0.2151 | R@1=0.116 R@5=0.308\n",
      "[16] train_loss=0.952024 | val_MRR=0.2208 | R@1=0.120 R@5=0.317\n",
      "[17] train_loss=0.949761 | val_MRR=0.2245 | R@1=0.124 R@5=0.320\n",
      "[18] train_loss=0.947707 | val_MRR=0.2287 | R@1=0.127 R@5=0.328\n",
      "[19] train_loss=0.945776 | val_MRR=0.2334 | R@1=0.131 R@5=0.333\n",
      "[20] train_loss=0.943962 | val_MRR=0.2357 | R@1=0.133 R@5=0.335\n",
      "[21] train_loss=0.942242 | val_MRR=0.2400 | R@1=0.137 R@5=0.342\n",
      "[22] train_loss=0.940637 | val_MRR=0.2429 | R@1=0.139 R@5=0.346\n",
      "[23] train_loss=0.939130 | val_MRR=0.2461 | R@1=0.142 R@5=0.351\n",
      "[24] train_loss=0.937686 | val_MRR=0.2493 | R@1=0.144 R@5=0.354\n",
      "[25] train_loss=0.936323 | val_MRR=0.2512 | R@1=0.146 R@5=0.357\n",
      "[26] train_loss=0.935009 | val_MRR=0.2541 | R@1=0.149 R@5=0.360\n",
      "[27] train_loss=0.933780 | val_MRR=0.2567 | R@1=0.151 R@5=0.364\n",
      "[28] train_loss=0.932612 | val_MRR=0.2587 | R@1=0.152 R@5=0.368\n",
      "[29] train_loss=0.931497 | val_MRR=0.2587 | R@1=0.152 R@5=0.367\n",
      "[30] train_loss=0.930464 | val_MRR=0.2595 | R@1=0.152 R@5=0.368\n",
      "[best] MRR=0.2595 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_wd5e4_moment01/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_wd5e4_moment01/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp2_wd5e4_moment01 --arch mlp2 --wd 1e-5 --gamma 0.1 --align_loss moment\n",
    "\n",
    "# too much WD can hurt alignment; so we relax it\n",
    "if __name__==\"__main__\": \n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_wd5e4_moment01\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-5)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1)\n",
    "    p.add_argument(\"--beta\", type=float, default=1)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.1)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T22:36:43.322546Z",
     "iopub.status.busy": "2025-10-26T22:36:43.321938Z",
     "iopub.status.idle": "2025-10-26T22:40:21.226272Z",
     "shell.execute_reply": "2025-10-26T22:40:21.225325Z",
     "shell.execute_reply.started": "2025-10-26T22:36:43.322522Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n",
      "[01] train_loss=1.358938 | val_MRR=0.0541 | R@1=0.019 R@5=0.072\n",
      "[02] train_loss=1.077359 | val_MRR=0.0915 | R@1=0.040 R@5=0.123\n",
      "[03] train_loss=1.037249 | val_MRR=0.1146 | R@1=0.052 R@5=0.158\n",
      "[04] train_loss=1.016719 | val_MRR=0.1294 | R@1=0.059 R@5=0.181\n",
      "[05] train_loss=1.003395 | val_MRR=0.1438 | R@1=0.067 R@5=0.204\n",
      "[06] train_loss=0.993638 | val_MRR=0.1540 | R@1=0.072 R@5=0.221\n",
      "[07] train_loss=0.986053 | val_MRR=0.1641 | R@1=0.079 R@5=0.238\n",
      "[08] train_loss=0.979908 | val_MRR=0.1724 | R@1=0.084 R@5=0.248\n",
      "[09] train_loss=0.974748 | val_MRR=0.1801 | R@1=0.089 R@5=0.262\n",
      "[10] train_loss=0.970300 | val_MRR=0.1875 | R@1=0.095 R@5=0.270\n",
      "[11] train_loss=0.966431 | val_MRR=0.1949 | R@1=0.102 R@5=0.281\n",
      "[12] train_loss=0.962989 | val_MRR=0.2002 | R@1=0.105 R@5=0.290\n",
      "[13] train_loss=0.959889 | val_MRR=0.2071 | R@1=0.110 R@5=0.299\n",
      "[14] train_loss=0.957037 | val_MRR=0.2125 | R@1=0.115 R@5=0.304\n",
      "[15] train_loss=0.954434 | val_MRR=0.2151 | R@1=0.116 R@5=0.308\n",
      "[16] train_loss=0.952022 | val_MRR=0.2209 | R@1=0.120 R@5=0.316\n",
      "[17] train_loss=0.949761 | val_MRR=0.2244 | R@1=0.124 R@5=0.320\n",
      "[18] train_loss=0.947708 | val_MRR=0.2287 | R@1=0.127 R@5=0.328\n",
      "[19] train_loss=0.945777 | val_MRR=0.2335 | R@1=0.131 R@5=0.333\n",
      "[20] train_loss=0.943963 | val_MRR=0.2357 | R@1=0.133 R@5=0.335\n",
      "[21] train_loss=0.942241 | val_MRR=0.2399 | R@1=0.137 R@5=0.343\n",
      "[22] train_loss=0.940635 | val_MRR=0.2426 | R@1=0.138 R@5=0.346\n",
      "[23] train_loss=0.939129 | val_MRR=0.2462 | R@1=0.142 R@5=0.351\n",
      "[24] train_loss=0.937685 | val_MRR=0.2493 | R@1=0.144 R@5=0.354\n",
      "[25] train_loss=0.936323 | val_MRR=0.2507 | R@1=0.145 R@5=0.357\n",
      "[26] train_loss=0.935009 | val_MRR=0.2538 | R@1=0.148 R@5=0.360\n",
      "[27] train_loss=0.933781 | val_MRR=0.2566 | R@1=0.151 R@5=0.364\n",
      "[28] train_loss=0.932614 | val_MRR=0.2587 | R@1=0.152 R@5=0.368\n",
      "[29] train_loss=0.931500 | val_MRR=0.2589 | R@1=0.152 R@5=0.367\n",
      "[30] train_loss=0.930469 | val_MRR=0.2594 | R@1=0.152 R@5=0.368\n",
      "[best] MRR=0.2594 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_wd5e4_moment01_vero/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_wd5e4_moment01_vero/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp2_wd5e4_moment01 --arch mlp2 --wd 5e-4 --gamma 0.1 --align_loss moment\n",
    "\n",
    "# if overfitting, stronger WD may help.\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_wd5e4_moment01_vero\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=5e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1)\n",
    "    p.add_argument(\"--beta\", type=float, default=1)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.1)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T22:44:42.033397Z",
     "iopub.status.busy": "2025-10-26T22:44:42.032735Z",
     "iopub.status.idle": "2025-10-26T22:48:47.397731Z",
     "shell.execute_reply": "2025-10-26T22:48:47.396862Z",
     "shell.execute_reply.started": "2025-10-26T22:44:42.033369Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n",
      "[01] train_loss=1.161027 | val_MRR=0.0819 | R@1=0.033 R@5=0.109\n",
      "[02] train_loss=0.967359 | val_MRR=0.1204 | R@1=0.055 R@5=0.166\n",
      "[03] train_loss=0.937974 | val_MRR=0.1434 | R@1=0.067 R@5=0.205\n",
      "[04] train_loss=0.921858 | val_MRR=0.1607 | R@1=0.077 R@5=0.230\n",
      "[05] train_loss=0.910998 | val_MRR=0.1756 | R@1=0.086 R@5=0.255\n",
      "[06] train_loss=0.902919 | val_MRR=0.1878 | R@1=0.096 R@5=0.273\n",
      "[07] train_loss=0.896514 | val_MRR=0.2001 | R@1=0.105 R@5=0.289\n",
      "[08] train_loss=0.891194 | val_MRR=0.2069 | R@1=0.109 R@5=0.299\n",
      "[09] train_loss=0.886670 | val_MRR=0.2169 | R@1=0.118 R@5=0.311\n",
      "[10] train_loss=0.882740 | val_MRR=0.2237 | R@1=0.123 R@5=0.320\n",
      "[11] train_loss=0.879313 | val_MRR=0.2327 | R@1=0.131 R@5=0.332\n",
      "[12] train_loss=0.876230 | val_MRR=0.2368 | R@1=0.134 R@5=0.337\n",
      "[13] train_loss=0.873493 | val_MRR=0.2432 | R@1=0.139 R@5=0.344\n",
      "[14] train_loss=0.871009 | val_MRR=0.2470 | R@1=0.142 R@5=0.351\n",
      "[15] train_loss=0.868734 | val_MRR=0.2487 | R@1=0.144 R@5=0.352\n",
      "[16] train_loss=0.866720 | val_MRR=0.2537 | R@1=0.149 R@5=0.358\n",
      "[17] train_loss=0.864882 | val_MRR=0.2586 | R@1=0.152 R@5=0.366\n",
      "[18] train_loss=0.863204 | val_MRR=0.2601 | R@1=0.152 R@5=0.371\n",
      "[19] train_loss=0.861694 | val_MRR=0.2623 | R@1=0.155 R@5=0.372\n",
      "[20] train_loss=0.860295 | val_MRR=0.2629 | R@1=0.156 R@5=0.372\n",
      "[21] train_loss=0.859007 | val_MRR=0.2663 | R@1=0.158 R@5=0.375\n",
      "[22] train_loss=0.857782 | val_MRR=0.2691 | R@1=0.161 R@5=0.380\n",
      "[23] train_loss=0.856671 | val_MRR=0.2690 | R@1=0.160 R@5=0.383\n",
      "[24] train_loss=0.855621 | val_MRR=0.2722 | R@1=0.163 R@5=0.384\n",
      "[25] train_loss=0.854643 | val_MRR=0.2721 | R@1=0.163 R@5=0.383\n",
      "[26] train_loss=0.853680 | val_MRR=0.2738 | R@1=0.164 R@5=0.385\n",
      "[27] train_loss=0.852790 | val_MRR=0.2749 | R@1=0.165 R@5=0.388\n",
      "[28] train_loss=0.851961 | val_MRR=0.2760 | R@1=0.167 R@5=0.390\n",
      "[29] train_loss=0.851154 | val_MRR=0.2750 | R@1=0.164 R@5=0.389\n",
      "[30] train_loss=0.850379 | val_MRR=0.2753 | R@1=0.165 R@5=0.387\n",
      "[best] MRR=0.2760 @ epoch 28\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_bs256_moment01/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_bs256_moment01/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp2_bs256_moment01 --arch mlp2 --batch 256 --gamma 0.1 --align_loss moment\n",
    "\n",
    "# more gradient noise can improve generalization\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_bs256_moment01\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=256)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1)\n",
    "    p.add_argument(\"--beta\", type=float, default=1)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.1)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T23:04:08.852287Z",
     "iopub.status.busy": "2025-10-26T23:04:08.851416Z",
     "iopub.status.idle": "2025-10-26T23:07:47.661947Z",
     "shell.execute_reply": "2025-10-26T23:07:47.660960Z",
     "shell.execute_reply.started": "2025-10-26T23:04:08.852256Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=moment | α=1 β=1 γ=0.1\n",
      "[01] train_loss=1.625906 | val_MRR=0.0281 | R@1=0.008 R@5=0.033\n",
      "[02] train_loss=1.212432 | val_MRR=0.0584 | R@1=0.022 R@5=0.077\n",
      "[03] train_loss=1.153054 | val_MRR=0.0812 | R@1=0.034 R@5=0.108\n",
      "[04] train_loss=1.123816 | val_MRR=0.0984 | R@1=0.044 R@5=0.135\n",
      "[05] train_loss=1.105431 | val_MRR=0.1119 | R@1=0.051 R@5=0.153\n",
      "[06] train_loss=1.092532 | val_MRR=0.1224 | R@1=0.056 R@5=0.168\n",
      "[07] train_loss=1.082776 | val_MRR=0.1311 | R@1=0.060 R@5=0.183\n",
      "[08] train_loss=1.075003 | val_MRR=0.1383 | R@1=0.064 R@5=0.196\n",
      "[09] train_loss=1.068588 | val_MRR=0.1455 | R@1=0.068 R@5=0.206\n",
      "[10] train_loss=1.063140 | val_MRR=0.1517 | R@1=0.071 R@5=0.216\n",
      "[11] train_loss=1.058438 | val_MRR=0.1585 | R@1=0.076 R@5=0.227\n",
      "[12] train_loss=1.054333 | val_MRR=0.1637 | R@1=0.079 R@5=0.235\n",
      "[13] train_loss=1.050660 | val_MRR=0.1691 | R@1=0.083 R@5=0.243\n",
      "[14] train_loss=1.047374 | val_MRR=0.1744 | R@1=0.087 R@5=0.251\n",
      "[15] train_loss=1.044392 | val_MRR=0.1784 | R@1=0.089 R@5=0.257\n",
      "[16] train_loss=1.041662 | val_MRR=0.1826 | R@1=0.091 R@5=0.264\n",
      "[17] train_loss=1.039139 | val_MRR=0.1877 | R@1=0.096 R@5=0.271\n",
      "[18] train_loss=1.036833 | val_MRR=0.1916 | R@1=0.099 R@5=0.277\n",
      "[19] train_loss=1.034664 | val_MRR=0.1940 | R@1=0.100 R@5=0.281\n",
      "[20] train_loss=1.032639 | val_MRR=0.1979 | R@1=0.103 R@5=0.286\n",
      "[21] train_loss=1.030742 | val_MRR=0.2016 | R@1=0.107 R@5=0.291\n",
      "[22] train_loss=1.028955 | val_MRR=0.2050 | R@1=0.109 R@5=0.295\n",
      "[23] train_loss=1.027276 | val_MRR=0.2085 | R@1=0.112 R@5=0.299\n",
      "[24] train_loss=1.025668 | val_MRR=0.2118 | R@1=0.114 R@5=0.305\n",
      "[25] train_loss=1.024103 | val_MRR=0.2132 | R@1=0.115 R@5=0.306\n",
      "[26] train_loss=1.022632 | val_MRR=0.2175 | R@1=0.118 R@5=0.310\n",
      "[27] train_loss=1.021212 | val_MRR=0.2201 | R@1=0.121 R@5=0.313\n",
      "[28] train_loss=1.019893 | val_MRR=0.2217 | R@1=0.121 R@5=0.318\n",
      "[29] train_loss=1.018586 | val_MRR=0.2248 | R@1=0.125 R@5=0.319\n",
      "[30] train_loss=1.017337 | val_MRR=0.2259 | R@1=0.125 R@5=0.323\n",
      "[best] MRR=0.2259 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_bs1024_moment01/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_bs1024_moment01/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp2_bs1024_moment01 --arch mlp2 --batch 1024 --gamma 0.1 --align_loss moment\n",
    "\n",
    "# more gradient noise can improve generalization\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_bs1024_moment01\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=1024)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1)\n",
    "    p.add_argument(\"--beta\", type=float, default=1)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.1)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"moment\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T23:08:39.870116Z",
     "iopub.status.busy": "2025-10-26T23:08:39.869660Z",
     "iopub.status.idle": "2025-10-26T23:12:17.213795Z",
     "shell.execute_reply": "2025-10-26T23:12:17.212863Z",
     "shell.execute_reply.started": "2025-10-26T23:08:39.870095Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] mlp1 | params=1,312,768 (~5.01 MB) | pooling=CLS | align=none | α=1 β=1 γ=0.2\n",
      "[01] train_loss=1.899691 | val_MRR=0.0433 | R@1=0.015 R@5=0.056\n",
      "[02] train_loss=1.642304 | val_MRR=0.0746 | R@1=0.031 R@5=0.101\n",
      "[03] train_loss=1.605984 | val_MRR=0.0969 | R@1=0.042 R@5=0.133\n",
      "[04] train_loss=1.587693 | val_MRR=0.1122 | R@1=0.050 R@5=0.156\n",
      "[05] train_loss=1.575995 | val_MRR=0.1278 | R@1=0.060 R@5=0.181\n",
      "[06] train_loss=1.567547 | val_MRR=0.1381 | R@1=0.065 R@5=0.198\n",
      "[07] train_loss=1.561022 | val_MRR=0.1484 | R@1=0.071 R@5=0.212\n",
      "[08] train_loss=1.555711 | val_MRR=0.1556 | R@1=0.075 R@5=0.225\n",
      "[09] train_loss=1.551231 | val_MRR=0.1649 | R@1=0.080 R@5=0.239\n",
      "[10] train_loss=1.547342 | val_MRR=0.1725 | R@1=0.086 R@5=0.250\n",
      "[11] train_loss=1.543942 | val_MRR=0.1813 | R@1=0.094 R@5=0.260\n",
      "[12] train_loss=1.540911 | val_MRR=0.1858 | R@1=0.096 R@5=0.270\n",
      "[13] train_loss=1.538198 | val_MRR=0.1929 | R@1=0.101 R@5=0.280\n",
      "[14] train_loss=1.535719 | val_MRR=0.1980 | R@1=0.105 R@5=0.285\n",
      "[15] train_loss=1.533460 | val_MRR=0.2002 | R@1=0.106 R@5=0.289\n",
      "[16] train_loss=1.531355 | val_MRR=0.2065 | R@1=0.111 R@5=0.300\n",
      "[17] train_loss=1.529380 | val_MRR=0.2090 | R@1=0.112 R@5=0.303\n",
      "[18] train_loss=1.527562 | val_MRR=0.2143 | R@1=0.116 R@5=0.310\n",
      "[19] train_loss=1.525814 | val_MRR=0.2184 | R@1=0.120 R@5=0.315\n",
      "[20] train_loss=1.524167 | val_MRR=0.2233 | R@1=0.125 R@5=0.320\n",
      "[21] train_loss=1.522602 | val_MRR=0.2264 | R@1=0.127 R@5=0.323\n",
      "[22] train_loss=1.521141 | val_MRR=0.2292 | R@1=0.129 R@5=0.328\n",
      "[23] train_loss=1.519771 | val_MRR=0.2325 | R@1=0.131 R@5=0.332\n",
      "[24] train_loss=1.518447 | val_MRR=0.2361 | R@1=0.135 R@5=0.335\n",
      "[25] train_loss=1.517208 | val_MRR=0.2373 | R@1=0.136 R@5=0.338\n",
      "[26] train_loss=1.516011 | val_MRR=0.2419 | R@1=0.140 R@5=0.343\n",
      "[27] train_loss=1.514874 | val_MRR=0.2433 | R@1=0.140 R@5=0.346\n",
      "[28] train_loss=1.513811 | val_MRR=0.2464 | R@1=0.144 R@5=0.350\n",
      "[29] train_loss=1.512773 | val_MRR=0.2470 | R@1=0.144 R@5=0.349\n",
      "[30] train_loss=1.511804 | val_MRR=0.2478 | R@1=0.146 R@5=0.352\n",
      "[best] MRR=0.2478 @ epoch 30\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/mlp1_moment02_loss_none/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/mlp1_moment02_loss_none/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# python runner.py --out_dir mlp2__infonce02 --arch mlp2 --gamma 0.2 --align_loss none\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    p=argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"mlp1_moment02_loss_none\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\",\"mean-patch\"])\n",
    "    p.add_argument(\"--n_patches\", type=int, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=1)\n",
    "    p.add_argument(\"--beta\", type=float, default=1)\n",
    "    p.add_argument(\"--gamma\", type=float, default=0.2)\n",
    "    p.add_argument(\"--align_loss\", type=str, default=\"none\", choices=[\"none\",\"moment\",\"normcal\"])\n",
    "    p.add_argument(\"--arch\", type=str, default=\"mlp1\", choices=[\"auto\",\"linear\",\"mlp1\",\"mlp2\"])\n",
    "    p.add_argument(\"--train\", type=int, default=1)\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.1)\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(**vars(args))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14220991,
     "sourceId": 117959,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
